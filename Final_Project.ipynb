{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hawa1983/DATA-612/blob/main/Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Purpose**\n",
        "\n",
        "The purpose of this script is to enrich the MovieLens movie dataset (`movies.dat`) with detailed movie metadata from The Movie Database (TMDB) API. This metadata includes movie overviews, genres, poster and backdrop image URLs, cast and director information, keywords, user ratings, and trailer links. The enriched dataset will serve as the foundation for building content-based, collaborative, and hybrid recommender systems.\n",
        "\n",
        "### **Methodology**\n",
        "\n",
        "1. **Load MovieLens Movie Data**\n",
        "   The script loads the `movies.dat` file, which contains basic movie information including `movieId`, `title`, and `genres`.\n",
        "\n",
        "2. **Clean Titles and Extract Years**\n",
        "   It processes the movie titles to remove the year from the title string and separately extracts the release year to improve search accuracy when querying TMDB.\n",
        "\n",
        "3. **Query TMDB API**\n",
        "   For each movie, it sends a search request to TMDB using the cleaned title and release year. If a match is found, it retrieves the movie’s TMDB ID.\n",
        "\n",
        "4. **Retrieve Detailed Metadata**\n",
        "   Using the TMDB ID, the script fetches:\n",
        "\n",
        "   * Overview (plot summary)\n",
        "   * Poster and backdrop image paths\n",
        "   * Genre IDs, which are then mapped to readable genre names\n",
        "   * Top 3 cast members\n",
        "   * Director(s)\n",
        "   * Associated keywords\n",
        "   * YouTube trailer link (if available)\n",
        "\n",
        "5. **Construct and Save Enriched Dataset**\n",
        "   All metadata is compiled into a structured format and merged with the original MovieLens data. The final dataset is saved as `movies_enriched_full.csv` for downstream use in recommendation models.\n"
      ],
      "metadata": {
        "id": "OptAJ12iBc8G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "7qJ0maYGaxtJ",
        "outputId": "2cab814c-7502-488a-f415-fd6922272d72"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'movies.dat'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2-494969615.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Load movies.dat - format: MovieID::Title::Genres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mmovies_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"movies.dat\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"::\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'python'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"movieId\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"title\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"genres\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"latin-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# ---------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'movies.dat'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "# ---------------------------------------\n",
        "# CONFIG\n",
        "# ---------------------------------------\n",
        "BASE_URL = \"https://api.themoviedb.org/3\"\n",
        "IMAGE_BASE = \"https://image.tmdb.org/t/p/w500\"\n",
        "\n",
        "# Use your TMDB Bearer Token (v4)\n",
        "HEADERS = {\n",
        "    \"Authorization\": \"Bearer eyJhbGciOiJIUzI1NiJ9.eyJhdWQiOiIyZGZlNjMwMGMzYjIzMjc2NzExNjQ0N2JhNzhiMjM5MyIsIm5iZiI6MTc1MTkyMjA3Ni4xMzUsInN1YiI6IjY4NmMzNTljMzc4NjllOGEyNDUxZTM0OSIsInNjb3BlcyI6WyJhcGlfcmVhZCJdLCJ2ZXJzaW9uIjoxfQ.S773ddH3FiIHtokPW4sYpJog0mXWS1o4OPov1KZneUw\"\n",
        "}\n",
        "\n",
        "# TMDB genre ID to name mapping\n",
        "GENRE_ID_TO_NAME = {\n",
        "    28: \"Action\", 12: \"Adventure\", 16: \"Animation\", 35: \"Comedy\", 80: \"Crime\",\n",
        "    99: \"Documentary\", 18: \"Drama\", 10751: \"Family\", 14: \"Fantasy\", 36: \"History\",\n",
        "    27: \"Horror\", 10402: \"Music\", 9648: \"Mystery\", 10749: \"Romance\", 878: \"Science Fiction\",\n",
        "    10770: \"TV Movie\", 53: \"Thriller\", 10752: \"War\", 37: \"Western\"\n",
        "}\n",
        "\n",
        "# ---------------------------------------\n",
        "# STEP 1: Load MovieLens .dat Files\n",
        "# ---------------------------------------\n",
        "\n",
        "# Load movies.dat - format: MovieID::Title::Genres\n",
        "movies_df = pd.read_csv(\"movies.dat\", sep=\"::\", engine='python', header=None, names=[\"movieId\", \"title\", \"genres\"], encoding=\"latin-1\")\n",
        "\n",
        "# ---------------------------------------\n",
        "# STEP 2: Clean Movie Titles and Extract Year\n",
        "# ---------------------------------------\n",
        "\n",
        "def extract_year(title):\n",
        "    if \"(\" in title:\n",
        "        try:\n",
        "            return int(title.strip()[-5:-1])\n",
        "        except:\n",
        "            return None\n",
        "    return None\n",
        "\n",
        "def clean_title(title):\n",
        "    if \"(\" in title:\n",
        "        return title[:title.rfind(\"(\")].strip()\n",
        "    return title.strip()\n",
        "\n",
        "movies_df[\"year\"] = movies_df[\"title\"].apply(extract_year)\n",
        "movies_df[\"clean_title\"] = movies_df[\"title\"].apply(clean_title)\n",
        "\n",
        "# ---------------------------------------\n",
        "# STEP 3: TMDB Metadata Functions\n",
        "# ---------------------------------------\n",
        "\n",
        "# Search for movie in TMDB\n",
        "def search_tmdb(title, year):\n",
        "    url = f\"{BASE_URL}/search/movie\"\n",
        "    params = {\"query\": title, \"year\": year}\n",
        "    response = requests.get(url, headers=HEADERS, params=params)\n",
        "    r = response.json()\n",
        "    if r.get(\"results\"):\n",
        "        return r[\"results\"][0]\n",
        "    return None\n",
        "\n",
        "# Get full metadata from TMDB\n",
        "def get_full_tmdb_metadata(tmdb_id):\n",
        "    metadata = {}\n",
        "\n",
        "    # Credits (cast, crew)\n",
        "    credits = requests.get(f\"{BASE_URL}/movie/{tmdb_id}/credits\", headers=HEADERS).json()\n",
        "    cast = [c[\"name\"] for c in credits.get(\"cast\", [])[:3]]\n",
        "    directors = [c[\"name\"] for c in credits.get(\"crew\", []) if c.get(\"job\") == \"Director\"]\n",
        "\n",
        "    # Keywords\n",
        "    keywords = requests.get(f\"{BASE_URL}/movie/{tmdb_id}/keywords\", headers=HEADERS).json()\n",
        "    keyword_list = [k[\"name\"] for k in keywords.get(\"keywords\", [])]\n",
        "\n",
        "    # Videos (trailers)\n",
        "    videos = requests.get(f\"{BASE_URL}/movie/{tmdb_id}/videos\", headers=HEADERS).json()\n",
        "    trailer_links = [\n",
        "        f\"https://www.youtube.com/watch?v={v['key']}\"\n",
        "        for v in videos.get(\"results\", [])\n",
        "        if v[\"site\"] == \"YouTube\" and v[\"type\"] == \"Trailer\"\n",
        "    ]\n",
        "\n",
        "    # Final metadata dictionary\n",
        "    metadata[\"top_3_cast\"] = \", \".join(cast)\n",
        "    metadata[\"directors\"] = \", \".join(directors)\n",
        "    metadata[\"keywords\"] = \", \".join(keyword_list)\n",
        "    metadata[\"trailer_link\"] = trailer_links[0] if trailer_links else None\n",
        "\n",
        "    return metadata\n",
        "\n",
        "# ---------------------------------------\n",
        "# STEP 4: Enrich Movie Data\n",
        "# ---------------------------------------\n",
        "\n",
        "enriched = []\n",
        "\n",
        "for _, row in tqdm(movies_df.iterrows(), total=len(movies_df)):\n",
        "    movie_data = search_tmdb(row[\"clean_title\"], row[\"year\"])\n",
        "\n",
        "    if movie_data:\n",
        "        tmdb_id = movie_data[\"id\"]\n",
        "        extra = get_full_tmdb_metadata(tmdb_id)\n",
        "\n",
        "        genre_ids = movie_data.get(\"genre_ids\", [])\n",
        "        genre_names = [GENRE_ID_TO_NAME.get(gid, str(gid)) for gid in genre_ids]\n",
        "\n",
        "        enriched.append({\n",
        "            \"tmdb_id\": tmdb_id,\n",
        "            \"overview\": movie_data.get(\"overview\", \"\"),\n",
        "            \"poster_path\": IMAGE_BASE + movie_data.get(\"poster_path\", \"\") if movie_data.get(\"poster_path\") else None,\n",
        "            \"backdrop_path\": IMAGE_BASE + movie_data.get(\"backdrop_path\", \"\") if movie_data.get(\"backdrop_path\") else None,\n",
        "            \"vote_average\": movie_data.get(\"vote_average\", None),\n",
        "            \"vote_count\": movie_data.get(\"vote_count\", None),\n",
        "            \"tmdb_genres\": \", \".join(genre_names),\n",
        "            **extra\n",
        "        })\n",
        "    else:\n",
        "        enriched.append({\n",
        "            \"tmdb_id\": None,\n",
        "            \"overview\": None,\n",
        "            \"poster_path\": None,\n",
        "            \"backdrop_path\": None,\n",
        "            \"vote_average\": None,\n",
        "            \"vote_count\": None,\n",
        "            \"tmdb_genres\": None,\n",
        "            \"top_3_cast\": None,\n",
        "            \"directors\": None,\n",
        "            \"keywords\": None,\n",
        "            \"trailer_link\": None\n",
        "        })\n",
        "\n",
        "    time.sleep(0.25)  # Respect TMDB API rate limits\n",
        "\n",
        "# ---------------------------------------\n",
        "# STEP 5: Save Final Dataset\n",
        "# ---------------------------------------\n",
        "\n",
        "enriched_df = pd.DataFrame(enriched)\n",
        "final_df = pd.concat([movies_df, enriched_df], axis=1)\n",
        "final_df.to_csv(\"movies_enriched_full.csv\", index=False)\n",
        "\n",
        "print(\"DONE: Saved as 'movies_enriched_full.csv'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Personalized Content-Based Movie Recommendation System**\n",
        "\n",
        "This Python script implements a **Content-Based Filtering (CBF)** system enhanced with **personalized recommendations** using user-specific rating profiles. Built using the MovieLens 1M dataset and enriched metadata, the pipeline performs vectorization, similarity computation, and profile-based predictions.\n",
        "\n",
        "**What This Script Does**\n",
        "\n",
        "* **Module 1–2**: Load essential libraries and enriched movie data.\n",
        "* **Module 3**: Load user ratings and demographics.\n",
        "* **Module 4**: Engineer features combining genres, cast, crew, keywords, and movie overviews.\n",
        "* **Module 5**: Transform content into TF-IDF, Count, or Binary vectors, and compute pairwise similarities using Cosine or Jaccard metrics.\n",
        "* **Module 6**: Construct a weighted content profile per user based on past ratings.\n",
        "* **Module 7**: Recommend top-N movies similar to the user profile, excluding already seen titles.\n",
        "\n",
        "**Techniques Used**\n",
        "\n",
        "* **Text Vectorization**: TF-IDF, CountVectorizer, Binary Count\n",
        "* **Similarity Metrics**: Cosine Similarity, Jaccard Similarity\n",
        "* **Personalization**: Weighted vector averaging based on each user’s rated items\n",
        "* **Parallelization**: Speeds up Jaccard similarity computation using joblib\n",
        "\n",
        "**Use Cases**\n",
        "\n",
        "* Personalized recommendations for new users with a few ratings (cold-start)\n",
        "* Improving diversity and relevance in suggested movies\n",
        "* Generating fallback content suggestions in hybrid recommender systems"
      ],
      "metadata": {
        "id": "c7KNZkOThu7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "9GeB2GWMyfPL",
        "outputId": "bcc397cf-6fc4-4a49-cdc4-8cd3d9d27d2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (1.26.4)\n",
            "Requirement already satisfied: pandas==2.2.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (2.2.2)\n",
            "Requirement already satisfied: scikit-surprise==1.1.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (1.1.4)\n",
            "Requirement already satisfied: scikit-learn==1.4.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (1.4.2)\n",
            "Requirement already satisfied: matplotlib==3.8.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (3.8.4)\n",
            "Requirement already satisfied: seaborn==0.13.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (0.13.2)\n",
            "Requirement already satisfied: tqdm==4.66.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (4.66.4)\n",
            "Requirement already satisfied: joblib==1.5.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (1.5.1)\n",
            "Requirement already satisfied: pyspark==3.5.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (0.10.9.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2->-r requirements.txt (line 2)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2->-r requirements.txt (line 2)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2->-r requirements.txt (line 2)) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise==1.1.4->-r requirements.txt (line 3)) (1.15.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.4.2->-r requirements.txt (line 4)) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.4->-r requirements.txt (line 5)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.4->-r requirements.txt (line 5)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.4->-r requirements.txt (line 5)) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.4->-r requirements.txt (line 5)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.4->-r requirements.txt (line 5)) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.4->-r requirements.txt (line 5)) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.4->-r requirements.txt (line 5)) (3.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.2->-r requirements.txt (line 2)) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# Module 1: Imports & Configuration\n",
        "# ==============================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from joblib import Parallel, delayed\n",
        "from tqdm import tqdm\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# ==============================\n",
        "# Module 2: Load Movie Data\n",
        "# ==============================\n",
        "def load_movie_data(filepath):\n",
        "    df = pd.read_csv(filepath)\n",
        "    print(f\"Loaded {len(df)} movies.\")\n",
        "    return df\n",
        "\n",
        "# ==============================\n",
        "# Module 3: Load User Ratings and Demographics\n",
        "# ==============================\n",
        "def load_user_data(ratings_path, users_path):\n",
        "    ratings = pd.read_csv(ratings_path, sep=\"::\", engine=\"python\",\n",
        "                          names=[\"userId\", \"movieId\", \"rating\", \"timestamp\"])\n",
        "    users = pd.read_csv(users_path, sep=\"::\", engine=\"python\",\n",
        "                        names=[\"userId\", \"gender\", \"age\", \"occupation\", \"zip\"])\n",
        "    print(f\"Loaded {len(ratings)} ratings and {len(users)} users.\")\n",
        "    return ratings, users\n",
        "\n",
        "# ==============================\n",
        "# Module 4: Feature Engineering\n",
        "# ==============================\n",
        "def create_feature_string(df):\n",
        "    def split_and_clean(col, delimiter='|'):\n",
        "        return col.fillna('').str.replace(r'\\s+', '', regex=True).str.split(delimiter)\n",
        "\n",
        "    genre_list_1 = split_and_clean(df['genres'], delimiter='|')\n",
        "    genre_list_2 = split_and_clean(df['tmdb_genres'], delimiter=',')\n",
        "    merged_genres = [\n",
        "        ' '.join(sorted(set(g1 or []) | set(g2 or [])))\n",
        "        for g1, g2 in zip(genre_list_1, genre_list_2)\n",
        "    ]\n",
        "\n",
        "    def clean_text(col):\n",
        "        return col.fillna('').str.replace(r'\\s+', '', regex=True).str.replace(',', ' ')\n",
        "\n",
        "    overview_clean = df['overview'].fillna('').str.lower().str.replace('[^\\w\\s]', '', regex=True)\n",
        "    year_str = df['year'].astype(str).fillna('')\n",
        "\n",
        "    df['cbf_features'] = (\n",
        "        pd.Series(merged_genres) + ' ' +\n",
        "        clean_text(df['keywords']) + ' ' +\n",
        "        clean_text(df['top_3_cast']) + ' ' +\n",
        "        clean_text(df['directors']) + ' ' +\n",
        "        overview_clean + ' ' +\n",
        "        year_str\n",
        "    )\n",
        "\n",
        "    return df[['movieId', 'title', 'cbf_features']]\n",
        "\n",
        "# ==============================\n",
        "# Module 5: Vectorization & Similarity\n",
        "# ==============================\n",
        "def vectorize_features(text_series, method='tfidf'):\n",
        "    if method == 'tfidf':\n",
        "        vectorizer = TfidfVectorizer(stop_words='english')\n",
        "    elif method == 'count':\n",
        "        vectorizer = CountVectorizer(stop_words='english')\n",
        "    else:\n",
        "        raise ValueError(\"Method must be 'tfidf' or 'count'\")\n",
        "    matrix = vectorizer.fit_transform(text_series)\n",
        "    print(f\"{method.upper()} vectorization complete. Shape: {matrix.shape}\")\n",
        "    return matrix, vectorizer\n",
        "\n",
        "def binary_vectorize(text_series):\n",
        "    vectorizer = CountVectorizer(binary=True, stop_words='english')\n",
        "    matrix = vectorizer.fit_transform(text_series)\n",
        "    print(f\"Binary Count vectorization complete. Shape: {matrix.shape}\")\n",
        "    return matrix.toarray(), vectorizer\n",
        "\n",
        "def compute_cosine_similarity(matrix):\n",
        "    sim = cosine_similarity(matrix)\n",
        "    print(\"Cosine similarity computed.\")\n",
        "    return sim\n",
        "\n",
        "def jaccard_pairwise_parallel(matrix):\n",
        "    n = matrix.shape[0]\n",
        "    sim_matrix = np.zeros((n, n))\n",
        "\n",
        "    def jaccard_row(i):\n",
        "        a = matrix[i]\n",
        "        row_sim = np.zeros(n)\n",
        "        for j in range(i, n):\n",
        "            b = matrix[j]\n",
        "            intersection = np.logical_and(a, b).sum()\n",
        "            union = np.logical_or(a, b).sum()\n",
        "            score = intersection / union if union > 0 else 0.0\n",
        "            row_sim[j] = score\n",
        "        return i, row_sim\n",
        "\n",
        "    results = Parallel(n_jobs=-1)(\n",
        "        delayed(jaccard_row)(i) for i in tqdm(range(n), desc=\"Jaccard Similarity\")\n",
        "    )\n",
        "\n",
        "    for i, row in results:\n",
        "        sim_matrix[i, i:] = row[i:]\n",
        "        sim_matrix[i:, i] = row[i:]\n",
        "\n",
        "    print(\"Jaccard similarity matrix built.\")\n",
        "    return sim_matrix\n",
        "\n",
        "def save_matrix(matrix, filename):\n",
        "    with open(filename, 'wb') as f:\n",
        "        pickle.dump(matrix, f)\n",
        "    print(f\"Saved similarity matrix to: {filename}\")\n",
        "\n",
        "# ==============================\n",
        "# Module 6: Build User Profile\n",
        "# ==============================\n",
        "def build_user_profile(user_id, ratings, tfidf_matrix, movie_df):\n",
        "    user_ratings = ratings[ratings['userId'] == user_id]\n",
        "    rated_movies = movie_df[movie_df['movieId'].isin(user_ratings['movieId'])]\n",
        "    indices = rated_movies.index.tolist()\n",
        "    weights = user_ratings.set_index('movieId').loc[rated_movies['movieId']]['rating'].values\n",
        "    profile = np.average(tfidf_matrix[indices].toarray(), axis=0, weights=weights)\n",
        "    return profile.reshape(1, -1)\n",
        "\n",
        "# ==============================\n",
        "# Module 7: Personalized Recommendation\n",
        "# ==============================\n",
        "def recommend_movies(user_id, ratings, tfidf_matrix, movie_df, top_n=50):\n",
        "    user_profile = build_user_profile(user_id, ratings, tfidf_matrix, movie_df)\n",
        "    sims = cosine_similarity(user_profile, tfidf_matrix).flatten()\n",
        "    user_seen = ratings[ratings['userId'] == user_id]['movieId'].tolist()\n",
        "    unseen_indices = movie_df[~movie_df['movieId'].isin(user_seen)].index\n",
        "    top_indices = unseen_indices[np.argsort(sims[unseen_indices])[-top_n:][::-1]]\n",
        "    return movie_df.iloc[top_indices][['movieId', 'title', 'year']], sims[top_indices]\n"
      ],
      "metadata": {
        "id": "3T-K1RtG-IUk"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Content-Based Similarity Recommendations***\n",
        "\n",
        "Purpose:\n",
        "Generate item recommendations using multiple content-based similarity strategies. Each set of recommendations is labeled by model type for downstream evaluation and comparison.\n",
        "\n",
        "Methodology:\n",
        "1. Load enriched movie metadata and user ratings.\n",
        "2. Create combined feature strings using genres, keywords, cast, directors, and overview.\n",
        "3. Vectorize the features using three methods: TF-IDF, Count, and Binary.\n",
        "4. Compute pairwise similarity:\n",
        "   - Cosine similarity for TF-IDF and Count vectors\n",
        "   - Jaccard similarity for binary vectors\n",
        "5. For a given user, identify previously seen movies and score unseen ones based on average similarity to the seen set.\n",
        "6. Return top-N recommendations as labeled DataFrames including: movieId, title, predicted score, and model name.\n",
        "\n"
      ],
      "metadata": {
        "id": "vj82RTA_ldyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# Module 8: Content-Based Similarity Recommendations (Multi-Model)\n",
        "# ==============================\n",
        "\n",
        "# ==============================\n",
        "# Step 1: Load Movie & User Data\n",
        "# ==============================\n",
        "\n",
        "movie_df = load_movie_data(\"movies_enriched_full.csv\")\n",
        "ratings, users = load_user_data(\"ratings.dat\", \"users.dat\")\n",
        "\n",
        "# Recreate CBF Features\n",
        "movie_df = create_feature_string(movie_df)\n",
        "\n",
        "# ==============================\n",
        "# Step 2: Vectorize & Compute Similarities\n",
        "# ==============================\n",
        "\n",
        "# --- TF-IDF + Cosine ---\n",
        "tfidf_matrix_tfidf, vectorizer_tfidf = vectorize_features(movie_df['cbf_features'], method='tfidf')\n",
        "sim_matrix_tfidf_cosine = compute_cosine_similarity(tfidf_matrix_tfidf)\n",
        "\n",
        "# --- Count + Cosine ---\n",
        "count_matrix_count, vectorizer_count = vectorize_features(movie_df['cbf_features'], method='count')\n",
        "sim_matrix_count_cosine = compute_cosine_similarity(count_matrix_count)\n",
        "\n",
        "# --- Binary + Jaccard ---\n",
        "binary_matrix_binary, vectorizer_binary = binary_vectorize(movie_df['cbf_features'])\n",
        "sim_matrix_binary_jaccard = jaccard_pairwise_parallel(binary_matrix_binary)\n",
        "\n",
        "# ==============================\n",
        "# Step 3: Recommendation Functions\n",
        "# ==============================\n",
        "\n",
        "def recommend_from_similarity_matrix(user_id, ratings, sim_matrix, movie_df, model_label, top_n=50):\n",
        "    \"\"\"\n",
        "    Purpose: Recommend top-N movies using a precomputed item-item similarity matrix.\n",
        "    \"\"\"\n",
        "    seen_movie_ids = ratings[ratings['userId'] == user_id]['movieId'].tolist()\n",
        "    seen_indices = movie_df[movie_df['movieId'].isin(seen_movie_ids)].index.tolist()\n",
        "    unseen_indices = movie_df[~movie_df['movieId'].isin(seen_movie_ids)].index.tolist()\n",
        "\n",
        "    if not seen_indices:\n",
        "        print(f\"No ratings found for user {user_id}.\")\n",
        "        return pd.DataFrame(columns=['movieId', 'title', 'score', 'model'])\n",
        "\n",
        "    mean_sims = sim_matrix[unseen_indices][:, seen_indices].mean(axis=1)\n",
        "    top_indices = np.argsort(mean_sims)[-top_n:][::-1]\n",
        "    top_movie_indices = np.array(unseen_indices)[top_indices]\n",
        "\n",
        "    return pd.DataFrame({\n",
        "        'movieId': movie_df.iloc[top_movie_indices]['movieId'].values,\n",
        "        'title': movie_df.iloc[top_movie_indices]['title'].values,\n",
        "        'score': mean_sims[top_indices],\n",
        "        'model': model_label\n",
        "    })\n",
        "\n",
        "def recommend_from_profile(user_id, ratings, tfidf_matrix, movie_df, model_label, top_n=50):\n",
        "    \"\"\"\n",
        "    Purpose: Recommend top-N movies using a user profile vector and similarity to TF-IDF matrix.\n",
        "    \"\"\"\n",
        "    user_profile = build_user_profile(user_id, ratings, tfidf_matrix, movie_df)\n",
        "    sims = cosine_similarity(user_profile, tfidf_matrix).flatten()\n",
        "    user_seen = ratings[ratings['userId'] == user_id]['movieId'].tolist()\n",
        "    unseen_indices = movie_df[~movie_df['movieId'].isin(user_seen)].index\n",
        "    top_indices = unseen_indices[np.argsort(sims[unseen_indices])[-top_n:][::-1]]\n",
        "\n",
        "    return pd.DataFrame({\n",
        "        'movieId': movie_df.iloc[top_indices]['movieId'].values,\n",
        "        'title': movie_df.iloc[top_indices]['title'].values,\n",
        "        'score': sims[top_indices],\n",
        "        'model': model_label\n",
        "    })\n",
        "\n",
        "# ==============================\n",
        "# Step 4: Generate Recommendations (Labeled Outputs)\n",
        "# ==============================\n",
        "\n",
        "user_id = 5549\n",
        "\n",
        "# --- TF-IDF + Cosine ---\n",
        "df_tfidf_cosine = recommend_from_profile(\n",
        "    user_id=user_id,\n",
        "    ratings=ratings,\n",
        "    tfidf_matrix=tfidf_matrix_tfidf,\n",
        "    movie_df=movie_df,\n",
        "    model_label='TF-IDF + Cosine',\n",
        "    top_n=50\n",
        ")\n",
        "\n",
        "# --- Count + Cosine ---\n",
        "df_count_cosine = recommend_from_profile(\n",
        "    user_id=user_id,\n",
        "    ratings=ratings,\n",
        "    tfidf_matrix=count_matrix_count,\n",
        "    movie_df=movie_df,\n",
        "    model_label='Count + Cosine',\n",
        "    top_n=50\n",
        ")\n",
        "\n",
        "# --- Binary + Jaccard ---\n",
        "df_binary_jaccard = recommend_from_similarity_matrix(\n",
        "    user_id=user_id,\n",
        "    ratings=ratings,\n",
        "    sim_matrix=sim_matrix_binary_jaccard,\n",
        "    movie_df=movie_df,\n",
        "    model_label='Binary + Jaccard',\n",
        "    top_n=50\n",
        ")\n",
        "\n",
        "# ==============================\n",
        "# Step 5: Combine All Model Outputs\n",
        "# ==============================\n",
        "\n",
        "all_recommendations_combined = pd.concat([\n",
        "    df_tfidf_cosine,\n",
        "    df_count_cosine,\n",
        "    df_binary_jaccard\n",
        "], ignore_index=True)\n",
        "\n",
        "print(\"Recommendation generation complete. Combined shape:\", all_recommendations_combined.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClwOydOIOtnH",
        "outputId": "3bd59c62-2266-4aab-c5d8-3eb5a97fef1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 3883 movies.\n",
            "Loaded 1000209 ratings and 6040 users.\n",
            "TFIDF vectorization complete. Shape: (3883, 33433)\n",
            "Cosine similarity computed.\n",
            "COUNT vectorization complete. Shape: (3883, 33433)\n",
            "Cosine similarity computed.\n",
            "Binary Count vectorization complete. Shape: (3883, 33433)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Jaccard Similarity:  90%|█████████ | 3500/3883 [19:35<00:21, 18.11it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Memory-based collaborative filtering module (UBCF, IBCF)**\n",
        "\n",
        "***Purpose:***\n",
        "\n",
        "This module implements **memory-based collaborative filtering** using **user-user** or **item-item** similarity. It addresses **user bias** by normalizing ratings through mean-centering and optionally **rescaling predictions** to the original rating scale for interpretability.\n",
        "\n",
        "***Methodology:***\n",
        "\n",
        "1. **Rating Matrix Construction**:\n",
        "\n",
        "   * A user-item matrix is built from raw MovieLens-style ratings data.\n",
        "   * For `kind='user'`, ratings are mean-centered per user to reduce bias from lenient or strict raters.\n",
        "   * For `kind='item'`, raw ratings are used directly (no normalization), as the algorithm focuses on item similarities based on a single user's input.\n",
        "\n",
        "2. **Similarity Computation**:\n",
        "\n",
        "   * Cosine similarity is computed either:\n",
        "\n",
        "     * **Across users** for user-based CF (`kind='user'`)\n",
        "     * **Across items** for item-based CF (`kind='item'`)\n",
        "   * `sklearn.metrics.pairwise_distances` is used to derive similarity as `1 - cosine_distance`.\n",
        "\n",
        "3. **Prediction Generation**:\n",
        "\n",
        "   * For **user-based CF**:\n",
        "\n",
        "     * Ratings from similar users are weighted by similarity and averaged.\n",
        "     * The user’s mean rating is **added back** to restore predictions to the original scale (e.g., 1–5).\n",
        "   * For **item-based CF**:\n",
        "\n",
        "     * A user’s own ratings are used to compute scores for similar items.\n",
        "     * No mean is added back, since predictions are already on the correct scale.\n",
        "\n",
        "4. **Top-N Recommendations**:\n",
        "\n",
        "   * The system filters out movies the user has already rated.\n",
        "   * It ranks unseen movies by predicted score and returns the top-N recommendations.\n",
        "   * Each recommendation is labeled with the model type (`User-Based CF` or `Item-Based CF`) for downstream tracking."
      ],
      "metadata": {
        "id": "omg4Y6k5XmSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# Module 8: Memory-Based Collaborative Filtering (Bias-Normalized)\n",
        "# ==============================\n",
        "# Purpose: Compute user-user or item-item similarity from the rating matrix.\n",
        "# Application: Real-time, interpretable recommendations with optional bias correction.\n",
        "\n",
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# --- Create Mean-Centered User-Item Matrix ---\n",
        "def create_normalized_user_item_matrix(ratings):\n",
        "    \"\"\"\n",
        "    Purpose: Create a user-item matrix with ratings mean-centered per user.\n",
        "    Application: Reduces bias from generous or harsh raters.\n",
        "    \"\"\"\n",
        "    matrix = ratings.pivot(index='userId', columns='movieId', values='rating')\n",
        "    user_means = matrix.mean(axis=1)\n",
        "    return matrix.sub(user_means, axis=0).fillna(0), user_means\n",
        "\n",
        "# --- Compute Cosine Similarity ---\n",
        "def compute_similarity(matrix, kind='user'):\n",
        "    \"\"\"\n",
        "    Purpose: Compute pairwise cosine similarity between users or items.\n",
        "    Application: Support for User-User or Item-Item collaborative filtering.\n",
        "    \"\"\"\n",
        "    if kind == 'user':\n",
        "        sim = 1 - pairwise_distances(matrix, metric='cosine')\n",
        "    elif kind == 'item':\n",
        "        sim = 1 - pairwise_distances(matrix.T, metric='cosine')\n",
        "    else:\n",
        "        raise ValueError(\"kind must be 'user' or 'item'\")\n",
        "\n",
        "    print(f\"{kind.title()}-based similarity computed. Shape: {sim.shape}\")\n",
        "    return sim\n",
        "\n",
        "# --- Generate Top-N Recommendations with Rescaled Predictions ---\n",
        "def recommend_memory_based(user_id, user_item_matrix, user_means, similarity_matrix, kind='user', top_n=50):\n",
        "    \"\"\"\n",
        "    Purpose: Recommend items using normalized ratings and return predictions on original scale.\n",
        "    Application: User-User or Item-Item CF with appropriate bias handling.\n",
        "    \"\"\"\n",
        "    model_label = f\"{kind.title()}-Based CF\"\n",
        "\n",
        "    if kind == 'user':\n",
        "        # User-based: normalize ratings and add back mean after prediction\n",
        "        user_sim_scores = similarity_matrix[user_id - 1]\n",
        "        normalized_ratings = user_item_matrix.values\n",
        "\n",
        "        weighted_scores = user_sim_scores @ normalized_ratings\n",
        "        sum_weights = np.abs(user_sim_scores).sum()\n",
        "\n",
        "        if sum_weights == 0:\n",
        "            print(\"No similar users found.\")\n",
        "            return pd.DataFrame(columns=['movieId', 'score', 'model'])\n",
        "\n",
        "        predicted_ratings = weighted_scores / sum_weights\n",
        "        user_seen = user_item_matrix.loc[user_id]\n",
        "        unseen_mask = user_seen == 0\n",
        "        recs = pd.Series(predicted_ratings, index=user_item_matrix.columns)[unseen_mask]\\\n",
        "            .sort_values(ascending=False).head(top_n)\n",
        "\n",
        "        # Re-center predictions to original scale\n",
        "        recs += user_means.loc[user_id]\n",
        "\n",
        "    elif kind == 'item':\n",
        "        # Item-based: do NOT add back user mean\n",
        "        user_ratings = user_item_matrix.loc[user_id]\n",
        "        scores = user_ratings @ similarity_matrix\n",
        "        sum_weights = (user_ratings != 0) @ np.abs(similarity_matrix)\n",
        "\n",
        "        with np.errstate(divide='ignore', invalid='ignore'):\n",
        "            predicted_ratings = np.true_divide(scores, sum_weights)\n",
        "            predicted_ratings[sum_weights == 0] = 0\n",
        "\n",
        "        unseen_mask = user_ratings == 0\n",
        "        recs = pd.Series(predicted_ratings, index=user_item_matrix.columns)[unseen_mask]\\\n",
        "            .sort_values(ascending=False).head(top_n)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"kind must be 'user' or 'item'\")\n",
        "\n",
        "    return pd.DataFrame({\n",
        "        'movieId': recs.index,\n",
        "        'score': recs.values,\n",
        "        'model': model_label\n",
        "    })\n"
      ],
      "metadata": {
        "id": "_vJLkUYeXmnv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Application of UBCF and IBCF***"
      ],
      "metadata": {
        "id": "FFUDwqVQXqC4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Create bias-normalized matrix\n",
        "user_item_matrix, user_means = create_normalized_user_item_matrix(ratings)\n",
        "\n",
        "# Step 2: Compute similarity matrices\n",
        "user_sim_matrix = compute_similarity(user_item_matrix, kind='user')\n",
        "item_sim_matrix = compute_similarity(user_item_matrix, kind='item')\n",
        "\n",
        "# Step 3: Generate recommendations\n",
        "user_cf_recs = recommend_memory_based(5549, user_item_matrix, user_means, user_sim_matrix, kind='user', top_n=50)\n",
        "item_cf_recs = recommend_memory_based(5549, user_item_matrix, user_means, item_sim_matrix, kind='item', top_n=50)\n",
        "\n",
        "\n",
        "# --- Optional: Join with movie metadata ---\n",
        "movies = pd.read_csv(\"movies_enriched_full.csv\")  # Assuming this has poster_path, etc.\n",
        "top_50_pd = top_50_pd.merge(movies, on=\"movieId\", how=\"left\")\n",
        "\n",
        "# --- Drop unwanted columns ---\n",
        "columns_to_hide = ['poster_path', 'backdrop_path', 'vote_average', 'vote_count']\n",
        "top_50_display = top_50_pd.drop(columns=columns_to_hide, errors='ignore')\n",
        "\n",
        "# --- Output ---\n",
        "print(\"\\nTop 50 Recommendations for User 5549 (Metadata Cleaned):\")\n",
        "print(top_50_display.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbI1OXxcXqfv",
        "outputId": "069bacbf-2d88-49c1-84c3-c55a356afb5e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User-based similarity computed. Shape: (6040, 6040)\n",
            "Item-based similarity computed. Shape: (3706, 3706)\n",
            "\n",
            "Top 50 Recommendations for User 5549 (Metadata Cleaned):\n",
            "   userId  movieId  pred_rating          model  \\\n",
            "0    5549      572     5.177515  ALS (PySpark)   \n",
            "1    5549     2129     4.888362  ALS (PySpark)   \n",
            "2    5549     2760     4.703132  ALS (PySpark)   \n",
            "3    5549      811     4.691999  ALS (PySpark)   \n",
            "4    5549     1471     4.496437  ALS (PySpark)   \n",
            "\n",
            "                             title       genres  year  \\\n",
            "0           Foreign Student (1994)        Drama  1994   \n",
            "1     Saltmen of Tibet, The (1997)  Documentary  1997   \n",
            "2  Gambler, The (A Játékos) (1997)        Drama  1997   \n",
            "3         Bewegte Mann, Der (1994)       Comedy  1994   \n",
            "4               Boys Life 2 (1997)        Drama  1997   \n",
            "\n",
            "                clean_title   tmdb_id  \\\n",
            "0           Foreign Student   95743.0   \n",
            "1     Saltmen of Tibet, The   48894.0   \n",
            "2  Gambler, The (A Játékos)  197239.0   \n",
            "3         Bewegte Mann, Der     159.0   \n",
            "4               Boys Life 2   50091.0   \n",
            "\n",
            "                                                                                                                                                                                                                                                                                                                                                                                     overview  \\\n",
            "0                                                                                                                                                                                                                                                                                                                                   A French football playing exchange student falls in love.   \n",
            "1  Four men from a nomadic Tibetan tribe undertake their annual, ritualistic pilgrimage to a sacred salt lake. Salt gathered in this traditional fashion will be sold to provide the economic livelihood of the tribe for the coming year. The journey, necessary for the group's survival, also incorporates a number of rituals necessary for their culture to survive in the modern world.   \n",
            "2                                                           Under pressure from his publisher, Russian novelist Fyodor Dostoyevsky gets work on his latest piece, 'Rouletenberg'. In the 27 days it takes for him to complete the novel reality and fiction become blurred; in this feverish atmosphere of excess Dostoyevsky's characters come to life as he struggles to complete his work.   \n",
            "3                                                                                                            The heterosexual man Axel is thrown out of his girlfriends home for cheating and ends up moving in with a gay man. Axel learns the advantages of living with gay men even though they are attracted to him and when his girlfriend wants him back he must make a tough decision.   \n",
            "4                                                                                                                                                                                                                                                      Compilation of four short films, \"Must Be the Music\", \"Nunzio's Second Cousin\", \"Alkali, Iowa\", and \"The Dadshuttle\", of gay interest.   \n",
            "\n",
            "      tmdb_genres                                        top_3_cast  \\\n",
            "0  Drama, Romance  Robin Givens, Marco Hofschneider, Charlotte Ross   \n",
            "1     Documentary                             Margen, Pargen, Zopon   \n",
            "2  Drama, Romance           Michael Gambon, Jodhi May, Polly Walker   \n",
            "3   Comedy, Drama        Til Schweiger, Katja Riemann, Joachim Król   \n",
            "4  Drama, Romance   Milo Ventimiglia, Michael Saucedo, Justin Urich   \n",
            "\n",
            "                                                      directors  \\\n",
            "0                                                    Eva Sereny   \n",
            "1                                                   Ulrike Koch   \n",
            "2                                                   Károly Makk   \n",
            "3                                                Sönke Wortmann   \n",
            "4  Mark Christopher, Nickolas Perry, Tom DeCerchio, Tom Donaghy   \n",
            "\n",
            "                                                                                                                      keywords  \\\n",
            "0                                                                                                                          NaN   \n",
            "1                                                                 buddhist monk, mountain lake, tibet, pilgrimage, nomad, salt   \n",
            "2                                                                                                                          NaN   \n",
            "3  sexual identity, infidelity, friendship, waitress, transvestism, cologne, germany, drag queen, support group, diashow, lgbt   \n",
            "4                                                     anthology, male homosexuality, lgbt, short compilation, 1990s, gay theme   \n",
            "\n",
            "                                  trailer_link  \n",
            "0                                          NaN  \n",
            "1                                          NaN  \n",
            "2                                          NaN  \n",
            "3  https://www.youtube.com/watch?v=BzoHTJdzniQ  \n",
            "4                                          NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(movie_df.head())\n"
      ],
      "metadata": {
        "id": "hZu-I11_Fu5y",
        "outputId": "77cf972d-ec6e-435d-86d0-5470798b3c2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   movieId                               title                        genres  \\\n",
            "0        1                    Toy Story (1995)   Animation|Children's|Comedy   \n",
            "1        2                      Jumanji (1995)  Adventure|Children's|Fantasy   \n",
            "2        3             Grumpier Old Men (1995)                Comedy|Romance   \n",
            "3        4            Waiting to Exhale (1995)                  Comedy|Drama   \n",
            "4        5  Father of the Bride Part II (1995)                        Comedy   \n",
            "\n",
            "   year                  clean_title  tmdb_id  \\\n",
            "0  1995                    Toy Story    862.0   \n",
            "1  1995                      Jumanji   8844.0   \n",
            "2  1995             Grumpier Old Men  15602.0   \n",
            "3  1995            Waiting to Exhale  31357.0   \n",
            "4  1995  Father of the Bride Part II  11862.0   \n",
            "\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                      overview  \\\n",
            "0                                                                                              Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences.   \n",
            "1  When siblings Judy and Peter discover an enchanted board game that opens the door to a magical world, they unwittingly invite Alan -- an adult who's been trapped inside the game for 26 years -- into their living room. Alan's only hope for freedom is to finish the game, which proves risky as all three find themselves running from giant rhinoceroses, evil monkeys and other terrifying creatures.   \n",
            "2                                                                      A family wedding reignites the ancient feud between next-door neighbors and fishing buddies John and Max. Meanwhile, a sultry Italian divorcée opens a restaurant at the local bait shop, alarming the locals who worry she'll scare the fish away. But she's less interested in seafood than she is in cooking up a hot time with Max.   \n",
            "3                                                                                                                               Cheated on, mistreated and stepped on, the women are holding their breath, waiting for the elusive \"good man\" to break a string of less-than-stellar lovers. Friends and confidants Vannah, Bernie, Glo and Robin talk it all out, determined to find a better way to breathe.   \n",
            "4                                                                                            Just when George Banks has recovered from his daughter's wedding, he receives the news that she's pregnant ... and that George's wife is expecting too. He was planning on selling their home, but that's a plan that—like George—will have to change with the arrival of both a grandchild and a kid of his own.   \n",
            "\n",
            "                                                       poster_path  \\\n",
            "0  https://image.tmdb.org/t/p/w500/uXDfjJbdP4ijW5hWSBrPrlKpxab.jpg   \n",
            "1  https://image.tmdb.org/t/p/w500/p67m5dzwyxWd46a6of2c9IVfQz7.jpg   \n",
            "2  https://image.tmdb.org/t/p/w500/1FSXpj5e8l4KH6nVFO5SPUeraOt.jpg   \n",
            "3  https://image.tmdb.org/t/p/w500/qJU6rfil5xLVb5HpJsmmfeSK254.jpg   \n",
            "4  https://image.tmdb.org/t/p/w500/rj4LBtwQ0uGrpBnCELr716Qo3mw.jpg   \n",
            "\n",
            "                                                     backdrop_path  \\\n",
            "0  https://image.tmdb.org/t/p/w500/3Rfvhy1Nl6sSGJwyjb0QiZzZYlB.jpg   \n",
            "1  https://image.tmdb.org/t/p/w500/pYw10zrqfkdm3yD9JTO6vEGQhKy.jpg   \n",
            "2  https://image.tmdb.org/t/p/w500/1o4vuCHpmd4DXofMYDUwpnhKiuy.jpg   \n",
            "3  https://image.tmdb.org/t/p/w500/jZjoEKXMTDoZAGdkjhAdJaKtXSN.jpg   \n",
            "4  https://image.tmdb.org/t/p/w500/lEsjVrGU21BeJjF5AF9EWsihDpw.jpg   \n",
            "\n",
            "   vote_average  vote_count                           tmdb_genres  \\\n",
            "0         8.000     18939.0  Animation, Adventure, Family, Comedy   \n",
            "1         7.238     10806.0            Adventure, Fantasy, Family   \n",
            "2         6.461       399.0                       Romance, Comedy   \n",
            "3         6.300       173.0                Comedy, Drama, Romance   \n",
            "4         6.200       755.0                        Comedy, Family   \n",
            "\n",
            "                                        top_3_cast        directors  \\\n",
            "0                Tom Hanks, Tim Allen, Don Rickles    John Lasseter   \n",
            "1    Robin Williams, Kirsten Dunst, Bradley Pierce     Joe Johnston   \n",
            "2         Walter Matthau, Jack Lemmon, Ann-Margret    Howard Deutch   \n",
            "3  Whitney Houston, Angela Bassett, Loretta Devine  Forest Whitaker   \n",
            "4         Steve Martin, Diane Keaton, Martin Short    Charles Shyer   \n",
            "\n",
            "                                                                                                                                                                                                                                            keywords  \\\n",
            "0  rescue, friendship, mission, jealousy, villain, bullying, elementary school, rivalry, anthropomorphism, friends, computer animation, buddy, walkie talkie, toy car, boy next door, new toy, neighborhood, toy comes to life, resourcefulness, toy   \n",
            "1                                                                                                                                   giant insect, board game, disappearance, jungle, recluse, stampede, based on young adult novel, jumanji universe   \n",
            "2                                                                                                                                      fishing, sequel, old man, best friend, wedding, italian restaurant, old friends, duringcreditsstinger, pranks   \n",
            "3                                                             based on novel or book, single mother, divorce, anxious, friendship between women, cautionary, adoring, celebratory, comforting, african american romance, african american friendship   \n",
            "4                                                            daughter, baby, parent child relationship, midlife crisis, pregnancy, confidence, aging, sequel, remake, los angeles, california, pregnant woman, contraception, gynecologist, pregnant   \n",
            "\n",
            "                                  trailer_link  \n",
            "0  https://www.youtube.com/watch?v=CxwTLktovTU  \n",
            "1  https://www.youtube.com/watch?v=veszTagaXik  \n",
            "2  https://www.youtube.com/watch?v=rEnOoWs3FuA  \n",
            "3  https://www.youtube.com/watch?v=j9xml1CxgXI  \n",
            "4  https://www.youtube.com/watch?v=yCg8WNQwe0A  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model-Based Filtering:**\n",
        "\n",
        "  * *SVD (Surprise)*: Learns latent features from the rating matrix.\n",
        "  * *ALS (PySpark)*: Scalable factorization method for large datasets.\n"
      ],
      "metadata": {
        "id": "R6d3SP0OolH0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Module 9: Model-Based Collaborative Filtering (SVD using Surprise)**\n",
        "\n",
        "**Purpose:**\n",
        "Use matrix factorization (SVD) to learn latent user/item features from the rating matrix.\n",
        "\n",
        "**Application:**\n",
        "- Accurate, scalable recommendations for sparse datasets using user/item embeddings.\n",
        "- Suitable for small to medium datasets.\n",
        "- Optimized via `GridSearchCV` for hyperparameter tuning.\n",
        "- Good interpretability of latent factors per user and item.\n",
        "\n"
      ],
      "metadata": {
        "id": "4dCPxrNMnQkh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# Module 9: Model-Based Collaborative Filtering (SVD using Surprise)\n",
        "# ==============================\n",
        "# Purpose: Use matrix factorization (SVD) to learn latent user/item features from the rating matrix.\n",
        "# Application: Accurate, scalable recommendations for sparse datasets using user/item embeddings.\n",
        "\n",
        "# ==============================\n",
        "# Imports\n",
        "# ==============================\n",
        "\n",
        "from surprise import Dataset, Reader, SVD\n",
        "from surprise.model_selection import train_test_split, GridSearchCV\n",
        "from surprise.accuracy import rmse\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ==============================\n",
        "# Prepare Surprise Dataset\n",
        "# ==============================\n",
        "\n",
        "def prepare_surprise_data(ratings):\n",
        "    reader = Reader(rating_scale=(0.5, 5.0))\n",
        "    return Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
        "\n",
        "# ==============================\n",
        "# Tune SVD Model with Grid Search + Progress Bar\n",
        "# ==============================\n",
        "\n",
        "def tune_svd_model(data):\n",
        "    param_grid = {\n",
        "        'n_factors': [50, 100],\n",
        "        'lr_all': [0.005, 0.01],\n",
        "        'reg_all': [0.02, 0.1]\n",
        "    }\n",
        "    print(\"Tuning SVD model with GridSearchCV...\")\n",
        "    gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3, joblib_verbose=0)\n",
        "\n",
        "    with tqdm(total=1, desc=\"GridSearchCV\") as pbar:\n",
        "        gs.fit(data)\n",
        "        pbar.update(1)\n",
        "\n",
        "    print(f\"Best RMSE: {gs.best_score['rmse']} with params: {gs.best_params['rmse']}\")\n",
        "    return gs.best_estimator['rmse']\n",
        "\n",
        "# ==============================\n",
        "# Train and Evaluate SVD with Prediction Progress Bar\n",
        "# ==============================\n",
        "\n",
        "def evaluate_svd(model, data, model_label='SVD (Surprise)'):\n",
        "    trainset, testset = train_test_split(data, test_size=0.2)\n",
        "    model.fit(trainset)\n",
        "\n",
        "    print(\"Making predictions...\")\n",
        "    predictions = []\n",
        "    for item in tqdm(testset, desc=\"Predicting\"):\n",
        "        predictions.append(model.predict(item[0], item[1], r_ui=item[2]))\n",
        "\n",
        "    score = rmse(predictions)\n",
        "\n",
        "    pred_df = pd.DataFrame(predictions, columns=['uid', 'iid', 'rui', 'est', 'details'])\n",
        "    pred_df = pred_df.rename(columns={'uid': 'userId', 'iid': 'movieId', 'rui': 'true_rating', 'est': 'pred_rating'})\n",
        "    pred_df['model'] = model_label\n",
        "    return pred_df[['userId', 'movieId', 'true_rating', 'pred_rating', 'model']], score\n",
        "\n",
        "# ==============================\n",
        "# Main Execution\n",
        "# ==============================\n",
        "\n",
        "# Step 1: Load ratings data\n",
        "ratings = pd.read_csv(\"ratings.dat\", sep=\"::\", engine=\"python\",\n",
        "                      names=[\"userId\", \"movieId\", \"rating\", \"timestamp\"])\n",
        "\n",
        "# Step 2: Prepare data\n",
        "data = prepare_surprise_data(ratings)\n",
        "\n",
        "# Step 3: Tune SVD model\n",
        "best_svd_model = tune_svd_model(data)\n",
        "\n",
        "# Step 4: Evaluate SVD model\n",
        "pred_df, rmse_score = evaluate_svd(best_svd_model, data)\n",
        "\n",
        "# Step 5: Output\n",
        "print(pred_df.head())\n",
        "print(f\"Final RMSE: {rmse_score:.4f}\")\n",
        "\n",
        "# Step 6: Top-50 Predictions for User 5549\n",
        "target_user = 5549\n",
        "\n",
        "# Get all movieIds\n",
        "all_movie_ids = ratings['movieId'].unique()\n",
        "\n",
        "# Get movies already rated by user 5549\n",
        "rated_movie_ids = ratings[ratings['userId'] == target_user]['movieId'].unique()\n",
        "\n",
        "# Get movies not rated by user 5549\n",
        "unrated_movie_ids = [mid for mid in all_movie_ids if mid not in rated_movie_ids]\n",
        "\n",
        "# Predict ratings for all unrated movies\n",
        "print(f\"\\nGenerating predictions for User {target_user}...\")\n",
        "top_preds = []\n",
        "for movie_id in tqdm(unrated_movie_ids, desc=\"Predicting for user\"):\n",
        "    pred = best_svd_model.predict(target_user, movie_id)\n",
        "    top_preds.append((movie_id, pred.est))\n",
        "\n",
        "# Convert to DataFrame and get Top-50\n",
        "top_50_df = pd.DataFrame(top_preds, columns=['movieId', 'pred_rating'])\n",
        "top_50_df = top_50_df.sort_values(by='pred_rating', ascending=False).head(50)\n",
        "top_50_df['userId'] = target_user\n",
        "top_50_df['model'] = 'SVD (Surprise)'\n",
        "top_50_df = top_50_df[['userId', 'movieId', 'pred_rating', 'model']]\n",
        "\n",
        "# Output Top-50\n",
        "print(\"\\nTop 50 Recommendations for User 5549:\")\n",
        "print(top_50_df.head(10))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0JR9B0YokAB",
        "outputId": "9e06c9a2-7697-45ff-b48a-a6ca06471bf9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tuning SVD model with GridSearchCV...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "GridSearchCV: 100%|██████████| 1/1 [07:53<00:00, 473.67s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best RMSE: 0.8831859988005499 with params: {'n_factors': 50, 'lr_all': 0.005, 'reg_all': 0.02}\n",
            "Making predictions...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting: 100%|██████████| 200042/200042 [00:02<00:00, 81840.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.8707\n",
            "   userId  movieId  true_rating  pred_rating           model\n",
            "0    3163     3793          4.0     3.848221  SVD (Surprise)\n",
            "1    2627     2088          1.0     2.167200  SVD (Surprise)\n",
            "2    2195      239          1.0     2.906026  SVD (Surprise)\n",
            "3    5096     2134          4.0     3.183477  SVD (Surprise)\n",
            "4    1018     2006          5.0     4.031776  SVD (Surprise)\n",
            "Final RMSE: 0.8707\n",
            "\n",
            "Generating predictions for User 5549...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting for user: 100%|██████████| 3673/3673 [00:00<00:00, 58432.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 50 Recommendations for User 5549:\n",
            "      userId  movieId  pred_rating           model\n",
            "2584    5549     2905     4.386488  SVD (Surprise)\n",
            "1067    5549     2019     4.170154  SVD (Surprise)\n",
            "2148    5549     2357     4.110042  SVD (Surprise)\n",
            "1609    5549     3091     4.106795  SVD (Surprise)\n",
            "2479    5549     1111     4.071434  SVD (Surprise)\n",
            "1209    5549     1189     4.060767  SVD (Surprise)\n",
            "82      5549     3147     4.054602  SVD (Surprise)\n",
            "1259    5549      556     4.049997  SVD (Surprise)\n",
            "520     5549     1148     4.046659  SVD (Surprise)\n",
            "2440    5549      668     4.044830  SVD (Surprise)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model-Based Collaborative Filtering (ALS using PySpark)**\n",
        "\n",
        "**Purpose:**\n",
        "Use Alternating Least Squares (ALS) to learn latent user/item features at scale.\n",
        "\n",
        "**Application:**\n",
        "- Distributed recommendation system for large-scale datasets.\n",
        "- Runs on Apache Spark for horizontal scalability.\n",
        "- Handles sparsity well using factorization.\n",
        "- Suited for real-time, production-level systems with massive data.\n"
      ],
      "metadata": {
        "id": "DeCmPC_DnZip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# Module 10: Model-Based Collaborative Filtering (ALS using PySpark)\n",
        "# ==============================\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.sql import Row\n",
        "\n",
        "# --- Start Spark Session ---\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"ALSModel\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# --- Load Ratings ---\n",
        "import pandas as pd\n",
        "ratings = pd.read_csv(\"ratings.dat\", sep=\"::\", engine=\"python\",\n",
        "                      names=[\"userId\", \"movieId\", \"rating\", \"timestamp\"])\n",
        "ratings_df = spark.createDataFrame(ratings[['userId', 'movieId', 'rating']])\n",
        "\n",
        "# --- Train ALS Model ---\n",
        "als = ALS(\n",
        "    userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",\n",
        "    rank=10, maxIter=10, regParam=0.1,\n",
        "    coldStartStrategy=\"drop\", nonnegative=True\n",
        ")\n",
        "als_model = als.fit(ratings_df)\n",
        "\n",
        "# --- Evaluate ALS Model ---\n",
        "predictions = als_model.transform(ratings_df)\n",
        "pred_pd = predictions.select('userId', 'movieId', 'rating', 'prediction').toPandas()\n",
        "pred_pd = pred_pd.rename(columns={'rating': 'true_rating', 'prediction': 'pred_rating'})\n",
        "pred_pd['model'] = 'ALS (PySpark)'\n",
        "\n",
        "# --- Evaluate ALS Model ---\n",
        "evaluator = RegressionEvaluator(\n",
        "    metricName='rmse',\n",
        "    labelCol='rating',\n",
        "    predictionCol='prediction'\n",
        ")\n",
        "rmse_score = evaluator.evaluate(predictions)\n",
        "\n",
        "# --- Output ---\n",
        "print(pred_pd[['userId', 'movieId', 'true_rating', 'pred_rating', 'model']].head())\n",
        "print(f\"\\nFinal RMSE: {rmse_score}\")\n",
        "\n",
        "# Step 6: Top-50 Predictions for User 5549\n",
        "target_user = 5549\n",
        "\n",
        "# Get list of all movies\n",
        "all_movie_ids = ratings['movieId'].unique()\n",
        "\n",
        "# Get movies already rated by target user\n",
        "rated_movie_ids = ratings[ratings['userId'] == target_user]['movieId'].unique()\n",
        "\n",
        "# Get unrated movies\n",
        "unrated_movie_ids = list(set(all_movie_ids) - set(rated_movie_ids))\n",
        "\n",
        "# Create Spark DataFrame of userId + unrated movieId pairs\n",
        "user_unrated_pairs = spark.createDataFrame([Row(userId=target_user, movieId=int(mid)) for mid in unrated_movie_ids])\n",
        "\n",
        "# Predict ratings using ALS model\n",
        "print(f\"\\nGenerating Top-50 recommendations for User {target_user}...\")\n",
        "top_preds_df = als_model.transform(user_unrated_pairs).dropna()\n",
        "\n",
        "# Get top-50 highest predicted ratings\n",
        "top_50_preds = top_preds_df.orderBy(col(\"prediction\").desc()).limit(50)\n",
        "top_50_pd = top_50_preds.select(\"userId\", \"movieId\", \"prediction\").toPandas()\n",
        "top_50_pd['model'] = \"ALS (PySpark)\"\n",
        "top_50_pd = top_50_pd.rename(columns={'prediction': 'pred_rating'})\n",
        "\n",
        "# --- Output ---\n",
        "print(\"\\nTop 50 Recommendations for User 5549:\")\n",
        "print(top_50_pd[['userId', 'movieId', 'pred_rating', 'model']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLtk_Rsuom7R",
        "outputId": "9a4f8c95-6ef9-4697-b75e-7859be799acb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   userId  movieId  true_rating  pred_rating          model\n",
            "0     148     2122            4     2.666267  ALS (PySpark)\n",
            "1     148     2142            4     3.382977  ALS (PySpark)\n",
            "2     148     2366            5     3.561895  ALS (PySpark)\n",
            "3     148     3175            5     3.874321  ALS (PySpark)\n",
            "4     148     1580            4     4.025066  ALS (PySpark)\n",
            "\n",
            "Final RMSE: 0.8362631422841943\n",
            "\n",
            "Generating Top-50 recommendations for User 5549...\n",
            "\n",
            "Top 50 Recommendations for User 5549:\n",
            "   userId  movieId  pred_rating          model\n",
            "0    5549      572     5.177515  ALS (PySpark)\n",
            "1    5549     2129     4.888362  ALS (PySpark)\n",
            "2    5549     2760     4.703132  ALS (PySpark)\n",
            "3    5549      811     4.691999  ALS (PySpark)\n",
            "4    5549     1471     4.496437  ALS (PySpark)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ls6RqljaolUG"
      }
    }
  ]
}