{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOxHlUA5nCNx72a4ikUhFvz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hawa1983/DATA-612/blob/main/Research_Discussion_Assignment_2_Fomba_Kassoh.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Research Discussion Assignment 2: Fomba Kassoh\n",
        "\n",
        "* **Title:** *Music Recommendations at Scale with Spark*\n",
        "* **Presenter:** Christopher Johnson\n",
        "* **GitHub Notebook:**\n",
        "\n",
        "### Summary and Key Insights\n",
        "\n",
        "In this engaging Spark Summit presentation, the speaker, a machine learning engineer at Spotify, delves into the dual challenge of *building effective recommendation systems* and *scaling them across massive datasets*. The first half of the talk walks through the mathematical foundations of recommendation algorithms, while the second half explores the engineering hurdles of implementing these systems in production using Spark.\n",
        "\n",
        "### Part 1: Mathematical Foundations\n",
        "\n",
        "1. **Collaborative Filtering & Matrix Factorization:**\n",
        "\n",
        "   * The speaker explains how Spotify utilizes *implicit feedback* rather than explicit ratings. Instead of 1–5 star scores, user interactions (song plays) are used.\n",
        "   * The recommendation problem is framed as a *matrix factorization* task, decomposing the user-item interaction matrix into two lower-dimensional latent matrices.\n",
        "   * A loss function incorporating confidence weights is used, giving more importance to frequently played songs.\n",
        "\n",
        "2. **Alternating Least Squares (ALS):**\n",
        "\n",
        "   * ALS is used to iteratively solve for user and item factors by fixing one and solving the other via *weighted Ridge regression*.\n",
        "   * This method supports distributed parallel computation, making it suitable for big data environments.\n",
        "\n",
        "### Part 2: Industrial-Scale Engineering with Spark\n",
        "\n",
        "1. **Transition from Hadoop to Spark:**\n",
        "\n",
        "   * Hadoop-based matrix factorization required multiple disk reads and writes per iteration—a severe performance bottleneck.\n",
        "   * Spark, by enabling *in-memory caching*, dramatically reduces I/O overhead, accelerating iterative computation.\n",
        "\n",
        "2. **Three Optimization Attempts in Spark:**\n",
        "\n",
        "   * **Attempt 1 – Full Broadcast:**\n",
        "     Every executor receives all item vectors. It works but incurs *heavy network overhead* and no caching.\n",
        "\n",
        "   * **Attempt 2 – Full Gridify:**\n",
        "     The ratings matrix is blocked into submatrices (user × item blocks), and only required vectors are sent to each block. Ratings are cached—improving performance.\n",
        "\n",
        "   * **Attempt 3 – Half Gridify (used by MLlib):**\n",
        "     Each block holds all ratings for a set of users. This approach reduces shuffling by grouping ratings with users. However, it may demand *high memory* if users collectively interact with all items.\n",
        "\n",
        "3. **Performance Results:**\n",
        "\n",
        "   * The *Half Gridify* method outperformed others on a dataset with 4M users and 500K artists, using Spark with 200 executors.\n",
        "   * Compared to Hadoop, Spark offered up to a *10x speedup*.\n",
        "\n",
        "### Lessons Learned & Practical Considerations\n",
        "\n",
        "* **Serialization Matters:** Cryo serialization is much faster than Java’s default, but it often requires *custom serializers*.\n",
        "* **Memory Management:** Running on full datasets sometimes led to *executor failures* due to resource constraints.\n",
        "* **Not Yet Production Ready:** At the time, Spotify still relied on Hadoop for production, using Spark mainly for experimentation due to tuning difficulties and instability with large-scale runs.\n",
        "\n",
        "### Reflection\n",
        "\n",
        "This talk elegantly demonstrates the balance between *theoretical machine learning* and *practical system design*. The speaker's candid discussion of failed attempts, memory bottlenecks, and tuning frustrations gives real-world insight into deploying ML at scale. Particularly interesting was how Spark’s abstraction simplifies iterative matrix factorization, making it far more feasible than the disk-heavy Hadoop model.\n",
        "\n",
        "For practitioners, this case study underscores:\n",
        "\n",
        "* The importance of algorithm choice when dealing with implicit feedback.\n",
        "* Why caching, partitioning, and minimizing data shuffling are crucial in large-scale ML pipelines.\n",
        "* That \"correct\" algorithms often require just as much *engineering finesse* as mathematical rigor to become viable in production."
      ],
      "metadata": {
        "id": "jVxGWcva5i4B"
      }
    }
  ]
}