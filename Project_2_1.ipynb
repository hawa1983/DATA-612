{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hawa1983/DATA-612/blob/main/Project_2_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Import Required Libraries"
      ],
      "metadata": {
        "id": "_A_qwFq-455m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This section imports all necessary libraries for data processing, similarity computation, evaluation, and visualization.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity, pairwise_distances\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import normalize\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "H3xCaUKr4y-Q"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Load and Preprocess Data\n",
        "\n",
        "- Downloads smaller, pre-filtered versions of the ratings and movies datasets from GitHub.\n",
        "- These files contain fewer rows and are easier to work with in Colab (won’t crash memory).\n",
        "- pd.read_csv() loads them into DataFrames named ratings and movies."
      ],
      "metadata": {
        "id": "Oo2YhHtz5CFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load subset datasets\n",
        "!wget -q https://raw.githubusercontent.com/hawa1983/DATA-612/refs/heads/main/movies_subset.csv\n",
        "!wget -q https://raw.githubusercontent.com/hawa1983/DATA-612/refs/heads/main/ratings_subset.csv\n",
        "\n",
        "ratings = pd.read_csv(\"ratings_subset.csv\")\n",
        "movies = pd.read_csv(\"movies_subset.csv\")\n",
        "\n",
        "# Step 2: Convert genres to multi-hot encoded format\n",
        "# This block prepares genre data for content-based filtering.\n",
        "# genres_list: Converts the genre string (e.g., 'Action|Adventure') into a Python list.\n",
        "# all_genres: Builds a sorted list of all unique genres in the dataset.\n",
        "# The loop creates a new column for each genre (multi-hot encoding):\n",
        "# If a movie has that genre, it gets a 1, else 0.\n",
        "\n",
        "movies['genres'] = movies['genres'].fillna('')\n",
        "movies['genres_list'] = movies['genres'].apply(lambda x: x.split('|'))\n",
        "\n",
        "all_genres = sorted(set(genre for sublist in movies['genres_list'] for genre in sublist))\n",
        "for genre in all_genres:\n",
        "    movies[genre] = movies['genres_list'].apply(lambda x: 1 if genre in x else 0)\n",
        "\n",
        "# Step 3: Merge movie features with ratings\n",
        "# Merges the processed movies DataFrame (now with genre vectors) with ratings.\n",
        "# This results in movie_data, a dataset where each row contains:\n",
        "    ## The user ID\n",
        "    ## The movie's genre indicators (1s and 0s)\n",
        "    ## The rating the user gave that movie\n",
        "\n",
        "movie_data = pd.merge(movies.drop(columns=['genres_list']), ratings, on='movieId')\n",
        "\n",
        "print(\"Shape of merged dataset:\", movie_data.shape)\n",
        "print(movie_data.head())\n"
      ],
      "metadata": {
        "id": "KfMpudFf5HrG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7876c850-de19-407c-b34a-116f524adc5a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of merged dataset: (100000, 26)\n",
            "   movieId             title                                       genres  \\\n",
            "0        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
            "1        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
            "2        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
            "3        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
            "4        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
            "\n",
            "   (no genres listed)  Action  Adventure  Animation  Children  Comedy  Crime  \\\n",
            "0                   0       0          1          1         1       1      0   \n",
            "1                   0       0          1          1         1       1      0   \n",
            "2                   0       0          1          1         1       1      0   \n",
            "3                   0       0          1          1         1       1      0   \n",
            "4                   0       0          1          1         1       1      0   \n",
            "\n",
            "   ...  Musical  Mystery  Romance  Sci-Fi  Thriller  War  Western  userId  \\\n",
            "0  ...        0        0        0       0         0    0        0   84906   \n",
            "1  ...        0        0        0       0         0    0        0  179275   \n",
            "2  ...        0        0        0       0         0    0        0  177578   \n",
            "3  ...        0        0        0       0         0    0        0   56009   \n",
            "4  ...        0        0        0       0         0    0        0  141567   \n",
            "\n",
            "   rating   timestamp  \n",
            "0     5.0   846267205  \n",
            "1     3.5  1222031839  \n",
            "2     4.5  1326414799  \n",
            "3     3.0  1633110299  \n",
            "4     4.0  1696811851  \n",
            "\n",
            "[5 rows x 26 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Content-Based Filtering Using Genre Vectors and Cosine Similarity\n",
        "\n",
        "This code implements a **content-based recommender system** using movie genres. Each movie is represented as a binary (multi-hot) vector based on its associated genres (e.g., Action, Comedy, Drama). The steps include:\n",
        "\n",
        "* Normalizing the genre vectors using **L2 norm** so that each vector has unit length.\n",
        "* Calculating **cosine similarity** between movie vectors to measure how similar their genre compositions are.\n",
        "* Creating a function that, given a movie title, returns the top-N most similar movies (excluding itself) based purely on genre similarity.\n",
        "\n",
        "This technique does not rely on user ratings — instead, it recommends items that are similar in content (genre) to a given movie.\n"
      ],
      "metadata": {
        "id": "KD0olH695T2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports tools for normalizing feature vectors and computing similarity between them.\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Use only unique movie rows for similarity matrix\n",
        "# Copies the movies DataFrame and resets the index to ensure each movie is uniquely indexed.\n",
        "unique_movies = movies.copy().reset_index(drop=True)\n",
        "\n",
        "# Normalize genre matrix\n",
        "# Extracts the genre vectors for each movie (multi-hot encoded).\n",
        "# Applies L2 normalization so that all genre vectors have a length of 1 (helps with cosine similarity).\n",
        "genre_cols = all_genres\n",
        "genre_matrix = unique_movies[genre_cols].values\n",
        "genre_matrix_normalized = normalize(genre_matrix, norm='l2')\n",
        "\n",
        "# Create title-to-index map for unique movies\n",
        "# Creates a dictionary-like mapping from movie titles to their corresponding row index — used to look up vector positions.\n",
        "movie_idx = pd.Series(unique_movies.index, index=unique_movies['title']).drop_duplicates()\n",
        "\n",
        "# Define function to get recommendations\n",
        "# Defines a function that takes a movie title and returns the top N most similar movies.\n",
        "def get_recommendations(title, topN=10):\n",
        "    if title not in movie_idx:\n",
        "        return f\"Movie '{title}' not found in dataset.\" # Returns an error message if the title is not in the dataset.\n",
        "\n",
        "    # Retrieves the normalized genre vector for the given title and compares it to all other movie vectors using cosine similarity.\n",
        "    idx = movie_idx[title]\n",
        "    query_vector = genre_matrix_normalized[idx].reshape(1, -1)\n",
        "    sim_scores = cosine_similarity(query_vector, genre_matrix_normalized)[0]\n",
        "\n",
        "    # Sorts similarity scores in descending order and skips the movie itself (which will always have a similarity of 1).\n",
        "    sim_scores = list(enumerate(sim_scores))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:topN+1]\n",
        "\n",
        "    # Retrieves the titles of the top-N similar movies and returns them as recommendations.\n",
        "    movie_indices = [i[0] for i in sim_scores]\n",
        "    return unique_movies['title'].iloc[movie_indices]\n",
        "\n",
        "# Sample 10 titles from the dataset to explore\n",
        "print(\"Available sample titles:\")\n",
        "print(unique_movies['title'].sample(10, random_state=42).to_list())\n",
        "\n",
        "# Get recommendations based on genre similarity to 'Heat (1995)'\n",
        "print(\"\\nContent-based Recommendations for 'Heat (1995)':\")\n",
        "print(get_recommendations('Heat (1995)'))\n"
      ],
      "metadata": {
        "id": "-H_FaMjJ5WPM",
        "outputId": "54343484-c18e-4789-e17f-c7c273135762",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available sample titles:\n",
            "['Murder on the Orient Express (2017)', 'Rhapsody in August (Hachi-gatsu no kyôshikyoku) (1991)', 'First Position (2011)', 'Wait Until Dark (1967)', 'Coffy (1973)', 'The Philadelphia Experiment (2012)', 'Vampires (1998)', 'Mr. Nobody (2009)', 'Live by Night (2017)', 'Paterson']\n",
            "\n",
            "Content-based Recommendations for 'Heat (1995)':\n",
            "22                       Assassins (1995)\n",
            "142     Die Hard: With a Vengeance (1995)\n",
            "158                       Net, The (1995)\n",
            "249           Natural Born Killers (1994)\n",
            "410                 Judgment Night (1993)\n",
            "503                         Batman (1989)\n",
            "804                       Die Hard (1988)\n",
            "1314                     Hard Rain (1998)\n",
            "1324      Replacement Killers, The (1998)\n",
            "1334                 U.S. Marshals (1998)\n",
            "Name: title, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hybrid Content-Based Rating Prediction Using Genre Similarity, User Behavior, and Fallback Handling\n",
        "\n",
        "This code demonstrates a *hybrid recommendation system* that combines **content-based filtering using genre similarity** with **collaborative filtering using user-specific ratings**. The objective is to predict how much a user will like a movie they've never seen, based on the genres of that movie and their past rating behavior.\n",
        "\n",
        "The prediction process incorporates a **fallback mechanism** and **debug printouts** to gracefully handle edge cases where standard hybrid predictions aren’t possible. These cases include users with no rating history, movies not present in the similarity matrix, or when no meaningful similarity is found.\n",
        "\n",
        "#### How it Works:\n",
        "\n",
        "1. **Genre Vector Normalization**:\n",
        "\n",
        "   * The genre columns are multi-hot encoded (e.g., Action, Comedy, etc.).\n",
        "   * Each movie’s genre vector is normalized using L2 norm so that cosine similarity is well-defined and scale-invariant.\n",
        "\n",
        "2. **Genre-Based Similarity Matrix**:\n",
        "\n",
        "   * Cosine similarity is computed between all pairs of movies based on genre vectors.\n",
        "\n",
        "3. **Mapping Setup**:\n",
        "\n",
        "   * The code builds lookup maps between `movieId` and its corresponding row index in the genre matrix to allow fast access.\n",
        "\n",
        "4. **Hybrid Prediction Function**:\n",
        "\n",
        "   * For a given `user_id` and `movie_id`, the function:\n",
        "\n",
        "     * Retrieves all movies rated by the user.\n",
        "     * Finds the top-K rated movies that are most genre-similar to the target movie.\n",
        "     * Computes a **weighted average of the ratings**, where the weights are the genre similarity scores.\n",
        "     * **If no such ratings or similarities are available**, the function **falls back to the global average rating of the movie**.\n",
        "     * Each fallback trigger is logged with a `[Debug]` message.\n",
        "\n",
        "5. **Application**:\n",
        "\n",
        "   * The model is tested on a sample user and generates predicted ratings for movies that are most similar in genre to a reference movie (e.g., *Heat (1995)*).\n",
        "\n",
        "This hybrid approach offers:\n",
        "\n",
        "* Personalization from collaborative filtering.\n",
        "* Interpretability from content-based features (genres).\n",
        "* Robustness from fallback logic to handle cold-starts or sparse data situations.\n"
      ],
      "metadata": {
        "id": "p6o2lnQkoljT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Required Libraries ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# --- Step 1: Normalize Genre Matrix ---\n",
        "# Make a clean copy of the movie list and normalize genre vectors\n",
        "unique_movies = movies.copy().reset_index(drop=True)\n",
        "genre_cols = all_genres\n",
        "genre_matrix = unique_movies[genre_cols].values\n",
        "genre_matrix_normalized = normalize(genre_matrix, norm='l2')\n",
        "\n",
        "# --- Step 2: Create Mapping Between movieId and genre_matrix Index ---\n",
        "movieId_to_index = dict(zip(unique_movies['movieId'], unique_movies.index))\n",
        "index_to_movieId = dict(zip(unique_movies.index, unique_movies['movieId']))\n",
        "movie_idx = pd.Series(unique_movies.index, index=unique_movies['title']).drop_duplicates()\n",
        "\n",
        "# --- Step 3: Compute Cosine Similarity Between Movies ---\n",
        "genre_sim_matrix = cosine_similarity(genre_matrix_normalized)\n",
        "\n",
        "# --- Step 4: Define Hybrid Prediction Function with Fallback ---\n",
        "def predict_rating_genre_weighted(user_id, target_movie_id, k=10):\n",
        "    \"\"\"\n",
        "    Predicts a user's rating for a given movie using a hybrid method combining\n",
        "    genre similarity and past user ratings. Falls back to the movie's global\n",
        "    average rating if no valid prediction is possible.\n",
        "    \"\"\"\n",
        "\n",
        "    # Check if user and movie exist in the dataset\n",
        "    if user_id not in user_movie_matrix.index or target_movie_id not in movieId_to_index:\n",
        "        print(f\"[Debug] Invalid user_id {user_id} or movie_id {target_movie_id}. Returning NaN.\")\n",
        "        return np.nan\n",
        "\n",
        "    # Get user's past ratings\n",
        "    user_ratings = user_movie_matrix.loc[user_id].dropna()\n",
        "    if user_ratings.empty:\n",
        "        print(f\"[Fallback 1] User {user_id} has no ratings. Using global average for movieId {target_movie_id}.\")\n",
        "        return movie_data[movie_data['movieId'] == target_movie_id]['rating'].mean()\n",
        "\n",
        "    # Get the index of the target movie\n",
        "    target_idx = movieId_to_index[target_movie_id]\n",
        "\n",
        "    # Find indices for rated movies that exist in the similarity matrix\n",
        "    rated_movie_indices = [movieId_to_index[mid] for mid in user_ratings.index if mid in movieId_to_index]\n",
        "    if not rated_movie_indices:\n",
        "        print(f\"[Fallback 2] User {user_id} rated movies not found in genre matrix. Using global average for movieId {target_movie_id}.\")\n",
        "        return movie_data[movie_data['movieId'] == target_movie_id]['rating'].mean()\n",
        "\n",
        "    # Compute similarity scores between target movie and rated movies\n",
        "    sims = genre_sim_matrix[target_idx, rated_movie_indices]\n",
        "    sims_series = pd.Series(sims, index=[index_to_movieId[i] for i in rated_movie_indices])\n",
        "\n",
        "    # Take top-k most similar rated movies\n",
        "    top_similar = sims_series.sort_values(ascending=False).head(k)\n",
        "    top_ratings = user_ratings[top_similar.index]\n",
        "\n",
        "    # Compute weighted prediction\n",
        "    weighted_sum = np.dot(top_similar.values, top_ratings.values)\n",
        "    normalization = np.sum(top_similar.values)\n",
        "\n",
        "    if normalization > 0:\n",
        "        return weighted_sum / normalization\n",
        "    else:\n",
        "        print(f\"[Fallback 3] No similarity found for user {user_id} and movieId {target_movie_id}. Using global average.\")\n",
        "        return movie_data[movie_data['movieId'] == target_movie_id]['rating'].mean()\n",
        "\n",
        "# --- Step 5: Predict Ratings for Similar Movies to \"Heat (1995)\" ---\n",
        "\n",
        "# Choose the target movie\n",
        "target_movie = 'Heat (1995)'\n",
        "\n",
        "# Print a few sample titles\n",
        "print(\"Available sample titles:\")\n",
        "print(unique_movies['title'].sample(10, random_state=42).to_list())\n",
        "\n",
        "# Get top 10 similar movies by genre (cosine similarity)\n",
        "idx = movie_idx[target_movie]\n",
        "sim_scores = cosine_similarity(genre_matrix_normalized[idx].reshape(1, -1), genre_matrix_normalized)[0]\n",
        "sim_indices = np.argsort(sim_scores)[::-1][1:11]  # exclude the target movie itself\n",
        "top_similar_movie_ids = unique_movies.loc[sim_indices, 'movieId']\n",
        "top_similar_titles = unique_movies.loc[sim_indices, 'title']\n",
        "\n",
        "# Display top similar movies\n",
        "print(f\"\\nTop 10 Genre-Similar Movies to '{target_movie}':\")\n",
        "print(top_similar_titles)\n",
        "\n",
        "# Pick a sample user\n",
        "user_id = 1\n",
        "print(f\"\\nPredicted Ratings for User {user_id} Using Genre-Weighted Hybrid Model with Fallback:\\n\")\n",
        "\n",
        "# Predict and print the ratings\n",
        "for movie_id, title in zip(top_similar_movie_ids, top_similar_titles):\n",
        "    pred = predict_rating_genre_weighted(user_id=user_id, target_movie_id=movie_id, k=100)\n",
        "    print(f\"{title:<45} Predicted Rating: {pred:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ay97PBzanpoF",
        "outputId": "41ea2014-7595-4543-e154-00c77b10701e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available sample titles:\n",
            "['Murder on the Orient Express (2017)', 'Rhapsody in August (Hachi-gatsu no kyôshikyoku) (1991)', 'First Position (2011)', 'Wait Until Dark (1967)', 'Coffy (1973)', 'The Philadelphia Experiment (2012)', 'Vampires (1998)', 'Mr. Nobody (2009)', 'Live by Night (2017)', 'Paterson']\n",
            "\n",
            "Top 10 Genre-Similar Movies to 'Heat (1995)':\n",
            "22                          Assassins (1995)\n",
            "158                          Net, The (1995)\n",
            "8497     Sin City: A Dame to Kill For (2014)\n",
            "4758                         Trespass (1992)\n",
            "9732           John Wick: Chapter Two (2017)\n",
            "4822                    Punisher, The (2004)\n",
            "3868                              xXx (2002)\n",
            "10009          Brawl in Cell Block 99 (2017)\n",
            "3817                   Gangster No. 1 (2000)\n",
            "5850                    Transporter 2 (2005)\n",
            "Name: title, dtype: object\n",
            "\n",
            "Predicted Ratings for User 1 Using Genre-Weighted Hybrid Model with Fallback:\n",
            "\n",
            "[Debug] Invalid user_id 1 or movie_id 23. Returning NaN.\n",
            "Assassins (1995)                              Predicted Rating: nan\n",
            "[Debug] Invalid user_id 1 or movie_id 185. Returning NaN.\n",
            "Net, The (1995)                               Predicted Rating: nan\n",
            "[Debug] Invalid user_id 1 or movie_id 113573. Returning NaN.\n",
            "Sin City: A Dame to Kill For (2014)           Predicted Rating: nan\n",
            "[Debug] Invalid user_id 1 or movie_id 7284. Returning NaN.\n",
            "Trespass (1992)                               Predicted Rating: nan\n",
            "[Debug] Invalid user_id 1 or movie_id 168248. Returning NaN.\n",
            "John Wick: Chapter Two (2017)                 Predicted Rating: nan\n",
            "[Debug] Invalid user_id 1 or movie_id 7439. Returning NaN.\n",
            "Punisher, The (2004)                          Predicted Rating: nan\n",
            "[Debug] Invalid user_id 1 or movie_id 5507. Returning NaN.\n",
            "xXx (2002)                                    Predicted Rating: nan\n",
            "[Debug] Invalid user_id 1 or movie_id 179221. Returning NaN.\n",
            "Brawl in Cell Block 99 (2017)                 Predicted Rating: nan\n",
            "[Debug] Invalid user_id 1 or movie_id 5423. Returning NaN.\n",
            "Gangster No. 1 (2000)                         Predicted Rating: nan\n",
            "[Debug] Invalid user_id 1 or movie_id 36519. Returning NaN.\n",
            "Transporter 2 (2005)                          Predicted Rating: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparison of Overlapping and Divergent Recommendations\n",
        "\n",
        "Both methods returned several overlapping recommendations, but also differed in meaningful ways:\n",
        "\n",
        "#### Similar Recommendations from Both Methods\n",
        "\n",
        "* **Assassins (1995)**\n",
        "* **Net, The (1995)**\n",
        "\n",
        "These consistent suggestions indicate that both the pure content-based and hybrid genre-weighted models identify core genre traits effectively.\n",
        "\n",
        "#### Recommendations Unique to Each Method\n",
        "\n",
        "**Only in Content-Based (Cosine Genre Similarity):**\n",
        "\n",
        "* *Die Hard (1988)*\n",
        "* *Batman (1989)*\n",
        "* *U.S. Marshals (1998)*\n",
        "\n",
        "**Only in Hybrid Model (Genre + Ratings Fallback):**\n",
        "\n",
        "* *Sin City: A Dame to Kill For (2014)*\n",
        "* *John Wick: Chapter Two (2017)*\n",
        "* *Transporter 2 (2005)*\n",
        "\n",
        "These differences show that the hybrid method is able to introduce newer or slightly more nuanced genre matches, even when rating data for a specific user is missing and fallback mechanisms are triggered.\n"
      ],
      "metadata": {
        "id": "Z6_Z7TyTwAhl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Block: Optimized Jaccard Similarity for Content-Based Filtering\n",
        "\n",
        "This block introduces a more efficient method for computing **Jaccard similarity** between movies based on their genre information. Unlike the traditional nested-loop approach, this implementation uses the `pdist()` function from `scipy.spatial.distance` to compute all pairwise Jaccard distances in a **fully vectorized** manner. The result is a symmetric similarity matrix, which is then used to identify the most similar movies to a given title. This optimization drastically reduces computation time and is highly recommended for medium-to-large datasets.\n",
        "\n",
        "using `scipy.spatial.distance.pdist()` **does calculate all pairwise similarities**, but it does so much more efficiently than a manual loop.\n",
        "\n",
        "Here’s how it works:\n",
        "\n",
        "* `pdist(binary_matrix, metric='jaccard')` computes the **Jaccard distance** (which is `1 - Jaccard similarity`) between **all unique pairs** of rows (i.e., movies) in the binary genre matrix.\n",
        "* The output is a **condensed distance matrix** — a flat array containing the upper triangle of the full pairwise distance matrix.\n",
        "* This condensed matrix is converted back into a full square **symmetric matrix** using `squareform()`, giving us the distance between all pairs.\n",
        "* We then compute similarity as `1 - distance`.\n",
        "\n",
        "Every possible movie-to-movie similarity is calculated — but with optimized vectorized operations under the hood, which is much faster than nested Python loops.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZK-ho_H6hrOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial.distance import pdist, squareform\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Prepare genre binary matrix\n",
        "unique_movies = movies.copy().reset_index(drop=True)\n",
        "genre_cols = all_genres\n",
        "genre_matrix = unique_movies[genre_cols].astype(bool).astype(int).values  # ensure binary format\n",
        "\n",
        "# Step 2: Compute Jaccard distance (1 - similarity)\n",
        "# pdist returns a condensed distance matrix; squareform converts it to square form\n",
        "jaccard_distance = pdist(genre_matrix, metric='jaccard')  # returns 1 - Jaccard similarity\n",
        "jaccard_sim_matrix = 1 - squareform(jaccard_distance)      # convert to full similarity matrix\n",
        "\n",
        "# Step 3: Create mapping from title to matrix index\n",
        "movie_idx = pd.Series(unique_movies.index, index=unique_movies['title']).drop_duplicates()\n",
        "\n",
        "# Step 4: Define recommendation function\n",
        "def get_recommendations_jaccard(title, topN=10):\n",
        "    if title not in movie_idx:\n",
        "        return f\"Movie '{title}' not found in dataset.\"\n",
        "\n",
        "    idx = movie_idx[title]\n",
        "    sim_scores = list(enumerate(jaccard_sim_matrix[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:topN+1]  # exclude self\n",
        "    top_indices = [i[0] for i in sim_scores]\n",
        "    return unique_movies['title'].iloc[top_indices]\n",
        "\n",
        "# Step 5: Try a sample movie\n",
        "print(\"Sample titles:\", unique_movies['title'].sample(5, random_state=42).to_list())\n",
        "print(\"\\nJaccard Recommendations for 'Heat (1995)':\")\n",
        "print(get_recommendations_jaccard(\"Heat (1995)\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8l-M-JJekRl-",
        "outputId": "8c5fc0cd-a1ad-48b0-fecb-642cd54d5c4d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample titles: ['Murder on the Orient Express (2017)', 'Rhapsody in August (Hachi-gatsu no kyôshikyoku) (1991)', 'First Position (2011)', 'Wait Until Dark (1967)', 'Coffy (1973)']\n",
            "\n",
            "Jaccard Recommendations for 'Heat (1995)':\n",
            "22                       Assassins (1995)\n",
            "142     Die Hard: With a Vengeance (1995)\n",
            "158                       Net, The (1995)\n",
            "249           Natural Born Killers (1994)\n",
            "410                 Judgment Night (1993)\n",
            "503                         Batman (1989)\n",
            "804                       Die Hard (1988)\n",
            "1314                     Hard Rain (1998)\n",
            "1324      Replacement Killers, The (1998)\n",
            "1334                 U.S. Marshals (1998)\n",
            "Name: title, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparison of Content-Based Recommendations: Cosine vs. Jaccard Similarity\n",
        "\n",
        "Both the **cosine similarity** and **Jaccard similarity** methods returned *identical top-10 movie recommendations* for the query movie **\"Heat (1995)\"**. This indicates that in the context of the MovieLens genre-based content filtering:\n",
        "\n",
        "* **Both methods effectively captured the same neighborhood of similar films**.\n",
        "* The movies recommended (e.g., *Assassins*, *Die Hard*, *The Net*, *Natural Born Killers*) suggest that the genre combinations for these titles closely match those of *Heat (1995)*.\n",
        "* While **cosine similarity** operates on normalized multi-hot vectors and measures angular proximity,\n",
        "  **Jaccard similarity** measures the overlap in genre tags directly.\n",
        "\n",
        "### Key Takeaway:\n",
        "\n",
        "Despite their different mathematical underpinnings, both methods **produced the same results** because:\n",
        "\n",
        "* The genre vectors are binary (multi-hot encoded), where normalization (in cosine) doesn’t distort information significantly.\n",
        "* The dominant factor influencing similarity is the **overlap of genre labels**, which both metrics capture well.\n",
        "\n",
        "However:\n",
        "\n",
        "* **Cosine similarity is computationally faster** and more scalable.\n",
        "* **Jaccard similarity is slower** when computed pairwise using loops, though vectorized solutions like `pdist()` improve it significantly.\n",
        "\n",
        "You can safely use either in this binary genre context, but for large-scale systems, cosine is typically preferred for efficiency.\n"
      ],
      "metadata": {
        "id": "RLrKOSN4mnK0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. User-User Collaborative Filtering with Cosine Similarity (Memory-Efficient Version)\n",
        "\n",
        "This block implements **User-User Collaborative Filtering** while addressing memory constraints in Google Colab. It includes two major optimizations:\n",
        "\n",
        "* Limits the dataset to users with `userId <= 50,000` to keep the similarity matrix size manageable.\n",
        "* Uses **cosine similarity** (instead of Pearson correlation), which is more memory-efficient and suitable for sparse rating data.\n",
        "\n",
        "The code builds a **mean-centered user-item matrix**, computes cosine similarity between users, and defines a prediction function based on the top-k most similar users who rated a given movie. This approach estimates a target user’s rating by combining how similar users rated the same item, adjusted for their own average rating.\n"
      ],
      "metadata": {
        "id": "BY76gdFX5cQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Option 1: Reduce number of users to avoid excessive memory usage\n",
        "# This line limits the dataset to users with IDs up to 50,000.\n",
        "# It keeps the similarity matrix manageable in size (<= 50,000x50,000).\n",
        "ratings_small = ratings[ratings['userId'] <= 50000]\n",
        "\n",
        "# Create a user-item matrix and normalize ratings\n",
        "# Creates a matrix where:\n",
        "# Rows = users\n",
        "# Columns = movies\n",
        "# Cells = user ratings\n",
        "# If a user hasn't rated a movie, the cell will be NaN.\n",
        "user_movie_matrix = ratings_small.pivot(index='userId', columns='movieId', values='rating')\n",
        "\n",
        "# Computes the average rating per user.\n",
        "# This is used to center each user’s ratings around their personal mean.\n",
        "user_means = user_movie_matrix.mean(axis=1)\n",
        "\n",
        "# Subtracts the user’s mean from their ratings → i.e., mean-centering.\n",
        "# Replaces missing ratings (NaN) with 0 (so they don't contribute to similarity).\n",
        "user_movie_centered = user_movie_matrix.sub(user_means, axis=0).fillna(0)\n",
        "\n",
        "# Option 3: Compute cosine similarity instead of Pearson correlation\n",
        "# Cosine similarity handles sparse matrices more efficiently than correlation\n",
        "# and is more memory-efficient for user-user comparisons.\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Compute cosine similarity between users\n",
        "user_similarity = cosine_similarity(user_movie_centered)\n",
        "# Stores the similarity scores in a DataFrame, where:\n",
        "# Rows and columns = userId\n",
        "# Cell (i, j) = similarity between user i and user j\n",
        "user_sim_df = pd.DataFrame(user_similarity, index=user_movie_matrix.index, columns=user_movie_matrix.index)\n",
        "\n",
        "# Define prediction function\n",
        "# Predicts how much user_id would rate movie_id using k nearest neighbors (top-k similar users).\n",
        "def predict_user_user(user_id, movie_id, k=10):\n",
        "    if movie_id not in user_movie_matrix.columns:  # If the movie doesn't exist in the matrix, return NaN.\n",
        "        return np.nan\n",
        "\n",
        "    # Get the similarity scores for the target user to all other users (excluding themselves).\n",
        "    sims = user_sim_df[user_id].drop(user_id)\n",
        "    # Find which users actually rated the target movie.\n",
        "    rated_users = user_movie_matrix[movie_id].dropna()\n",
        "    # Keep only similarities for users who rated the movie.\n",
        "    sims = sims[rated_users.index]\n",
        "    # Select the top-k most similar users.\n",
        "    top_users = sims.sort_values(ascending=False).head(k)\n",
        "    # Get those users’ ratings for the target movie, centered around their mean.\n",
        "    top_ratings = user_movie_matrix.loc[top_users.index, movie_id] - user_means[top_users.index]\n",
        "\n",
        "    # Final prediction:\n",
        "    ## Adds the weighted average of the top users' deviations back to the target user’s mean.\n",
        "    ## This estimates how the target user would rate the movie.\n",
        "    prediction = user_means[user_id] + np.dot(top_users, top_ratings) / top_users.sum() if top_users.sum() > 0 else np.nan\n",
        "    return prediction\n"
      ],
      "metadata": {
        "id": "KnCFYzFuW-nc"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Item-Item Collaborative Filtering with Adjusted Cosine Similarity\n",
        "\n",
        "This code implements **item-item collaborative filtering** using **adjusted cosine similarity**, which accounts for differences in users’ individual rating scales. The steps include:\n",
        "\n",
        "* **Transposing** the user-item matrix so that movies are represented as rows.\n",
        "* **Centering** each movie's vector by subtracting each user's mean rating — this adjustment ensures that the similarity metric reflects agreement in rating patterns, not absolute values.\n",
        "* **Computing cosine similarity** between movie vectors to identify similar items.\n",
        "* Defining a **prediction function** that estimates how a user would rate a target movie by aggregating their ratings for similar movies (weighted by similarity).\n",
        "\n",
        "This memory-efficient approach allows personalized movie recommendations by looking at how similar a target movie is to other movies the user has already rated."
      ],
      "metadata": {
        "id": "VP1qrga55qpZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create user-movie matrix (assumes user_movie_matrix is already defined earlier)\n",
        "\n",
        "# Transpose and center by user mean\n",
        "# Transposes the matrix so that:\n",
        "# Rows = movies (items)\n",
        "# Columns = users\n",
        "# This format is needed to compute item-item similarity.\n",
        "movie_user_matrix = user_movie_matrix.T\n",
        "\n",
        "# Center each row (movie) by subtracting the mean rating given by each user.\n",
        "# This is known as adjusted cosine similarity — it accounts for differences in user rating scales.\n",
        "movie_user_centered = movie_user_matrix.sub(user_movie_matrix.mean(axis=1), axis=1).fillna(0)\n",
        "\n",
        "# Compute cosine similarity between items (movies)\n",
        "# Cosine similarity is computed between each pair of movie vectors.\n",
        "# The result is a similarity matrix where:\n",
        "# Rows and columns = movieId\n",
        "# Cell (i, j) = similarity between movie i and movie j\n",
        "from sklearn.metrics import pairwise_distances\n",
        "item_similarity = 1 - pairwise_distances(movie_user_centered, metric='cosine')\n",
        "item_sim_df = pd.DataFrame(item_similarity, index=movie_user_matrix.index, columns=movie_user_matrix.index)\n",
        "\n",
        "# Define prediction function\n",
        "# Predicts how much user_id would rate movie_id using k nearest neighbors (top-k similar items).\n",
        "def predict_item_item(user_id, movie_id, k=10):\n",
        "    # If the movie is not in the matrix, return NaN\n",
        "    if movie_id not in user_movie_matrix.columns:\n",
        "        return np.nan\n",
        "\n",
        "    # Get all movies that this user has rated\n",
        "    user_ratings = user_movie_matrix.loc[user_id].dropna()\n",
        "\n",
        "    # If user has not rated any other movies, return NaN\n",
        "    if user_ratings.empty:\n",
        "        return np.nan\n",
        "\n",
        "    # Get similarity scores between the target movie and all movies the user has rated\n",
        "    sims = item_sim_df.loc[movie_id, user_ratings.index]\n",
        "\n",
        "    # Select the top-k most similar items\n",
        "    top_items = sims.sort_values(ascending=False).head(k)\n",
        "\n",
        "    # Get the user’s ratings for those items\n",
        "    top_ratings = user_ratings[top_items.index]\n",
        "\n",
        "    # Compute the weighted average rating, weighted by item similarity\n",
        "    prediction = np.dot(top_items, top_ratings) / top_items.sum() if top_items.sum() > 0 else np.nan\n",
        "    return prediction\n"
      ],
      "metadata": {
        "id": "Mc-sDJ-M5t53"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Item-Item Collaborative Filtering using Jaccard Similarity\n",
        "\n",
        "This code implements item-item collaborative filtering by measuring the similarity between movies using the Jaccard index. Jaccard similarity is a metric that compares the similarity of two sets by dividing the size of their intersection by the size of their union. In this context, it is used to compare movies based on whether users have rated them or not—ignoring the actual rating values.\n",
        "\n",
        "To apply Jaccard similarity:\n",
        "\n",
        "1. The user-item ratings matrix is converted into a binary format (1 if a user rated a movie, 0 otherwise).\n",
        "2. Each pair of movies is compared using Jaccard similarity, which is computed as the ratio of the number of users who rated both movies to the number of users who rated either movie.\n",
        "3. A prediction function is defined to estimate how much a user would rate a given movie, based on the user’s ratings for the most similar movies, weighted by Jaccard similarity.\n",
        "\n",
        "This method is particularly useful when the presence or absence of a rating is more important than the rating value itself. It also tends to be more memory-efficient in sparse datasets where many entries are missing."
      ],
      "metadata": {
        "id": "xcgIjUatbXCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Required library for Jaccard similarity\n",
        "from sklearn.metrics import jaccard_score\n",
        "\n",
        "# ---- SUBSET THE DATASET TO AVOID MEMORY ISSUES ----\n",
        "\n",
        "# Reduce to users with userId ≤ 50,000 for memory-efficient computation\n",
        "ratings_small = ratings[ratings['userId'] <= 10000]\n",
        "\n",
        "# Create user-movie matrix: rows = users, columns = movies, values = ratings\n",
        "user_movie_matrix = ratings_small.pivot(index='userId', columns='movieId', values='rating')\n",
        "\n",
        "# Step 1: Convert to Binary Rating Matrix\n",
        "# Convert to binary: 1 if user rated a movie, 0 otherwise\n",
        "# Transpose so that rows = movies, columns = users\n",
        "movie_user_binary = user_movie_matrix.notna().astype(int).T\n",
        "\n",
        "# Step 2: Compute Jaccard Similarity Matrix Between Movies\n",
        "# Initialize empty DataFrame to store Jaccard similarities\n",
        "movie_ids = movie_user_binary.index.tolist()\n",
        "jaccard_sim_df = pd.DataFrame(index=movie_ids, columns=movie_ids, dtype=float)\n",
        "\n",
        "# Compute Jaccard similarity for each pair of movies\n",
        "# This may take time depending on how many movies are present\n",
        "for i in range(len(movie_ids)):\n",
        "    for j in range(i, len(movie_ids)):\n",
        "        movie_i = movie_user_binary.loc[movie_ids[i]].values\n",
        "        movie_j = movie_user_binary.loc[movie_ids[j]].values\n",
        "        sim = jaccard_score(movie_i, movie_j)\n",
        "        jaccard_sim_df.iloc[i, j] = sim\n",
        "        jaccard_sim_df.iloc[j, i] = sim  # Ensure symmetry\n",
        "\n",
        "# Step 3: Define Prediction Function Using Jaccard Similarity\n",
        "# Predict rating for a given user and movie using top-k similar movies\n",
        "def predict_item_item_jaccard(user_id, movie_id, k=10):\n",
        "    # Check if movie exists in the matrix\n",
        "    if movie_id not in user_movie_matrix.columns:\n",
        "        return np.nan\n",
        "\n",
        "    # Get movies the user has rated\n",
        "    user_ratings = user_movie_matrix.loc[user_id].dropna()\n",
        "    if user_ratings.empty:\n",
        "        return np.nan\n",
        "\n",
        "    # Get Jaccard similarity between target movie and movies the user has rated\n",
        "    sims = jaccard_sim_df.loc[movie_id, user_ratings.index]\n",
        "\n",
        "    # Select top-k similar movies\n",
        "    top_items = sims.sort_values(ascending=False).head(k)\n",
        "    top_ratings = user_ratings[top_items.index]\n",
        "\n",
        "    # Weighted average of ratings using Jaccard similarity as weights\n",
        "    prediction = np.dot(top_items, top_ratings) / top_items.sum() if top_items.sum() > 0 else np.nan\n",
        "    return prediction\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "0e18Ov_xbka9",
        "outputId": "ff470935-abe5-4652-c004-8a0d3021491a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-3792502014>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mmovie_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmovie_user_binary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmovie_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mmovie_j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmovie_user_binary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmovie_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjaccard_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovie_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmovie_j\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mjaccard_sim_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mjaccard_sim_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msim\u001b[0m  \u001b[0;31m# Ensure symmetry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mfunc_sig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0;31m# Map *args/**kwargs to the function signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/inspect.py\u001b[0m in \u001b[0;36msignature\u001b[0;34m(obj, follow_wrapped, globals, locals, eval_str)\u001b[0m\n\u001b[1;32m   3261\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_wrapped\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3262\u001b[0m     \u001b[0;34m\"\"\"Get a signature object for the passed callable.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3263\u001b[0;31m     return Signature.from_callable(obj, follow_wrapped=follow_wrapped,\n\u001b[0m\u001b[1;32m   3264\u001b[0m                                    globals=globals, locals=locals, eval_str=eval_str)\n\u001b[1;32m   3265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/inspect.py\u001b[0m in \u001b[0;36mfrom_callable\u001b[0;34m(cls, obj, follow_wrapped, globals, locals, eval_str)\u001b[0m\n\u001b[1;32m   3009\u001b[0m                       follow_wrapped=True, globals=None, locals=None, eval_str=False):\n\u001b[1;32m   3010\u001b[0m         \u001b[0;34m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3011\u001b[0;31m         return _signature_from_callable(obj, sigcls=cls,\n\u001b[0m\u001b[1;32m   3012\u001b[0m                                         \u001b[0mfollow_wrapper_chains\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_wrapped\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3013\u001b[0m                                         globals=globals, locals=locals, eval_str=eval_str)\n",
            "\u001b[0;32m/usr/lib/python3.11/inspect.py\u001b[0m in \u001b[0;36m_signature_from_callable\u001b[0;34m(obj, follow_wrapper_chains, skip_bound_arg, globals, locals, eval_str, sigcls)\u001b[0m\n\u001b[1;32m   2521\u001b[0m         \u001b[0;31m# If it's a pure Python function, or an object that is duck type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2522\u001b[0m         \u001b[0;31m# of a Python function (Cython functions, for instance), then:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2523\u001b[0;31m         return _signature_from_function(sigcls, obj,\n\u001b[0m\u001b[1;32m   2524\u001b[0m                                         \u001b[0mskip_bound_arg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_bound_arg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2525\u001b[0m                                         globals=globals, locals=locals, eval_str=eval_str)\n",
            "\u001b[0;32m/usr/lib/python3.11/inspect.py\u001b[0m in \u001b[0;36m_signature_from_function\u001b[0;34m(cls, func, skip_bound_arg, globals, locals, eval_str)\u001b[0m\n\u001b[1;32m   2403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2404\u001b[0m         \u001b[0mannotation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_empty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2405\u001b[0;31m         parameters.append(Parameter(name, annotation=annotation,\n\u001b[0m\u001b[1;32m   2406\u001b[0m                                     \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_KEYWORD_ONLY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2407\u001b[0m                                     default=default))\n",
            "\u001b[0;32m/usr/lib/python3.11/inspect.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, kind, default, annotation)\u001b[0m\n\u001b[1;32m   2669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_empty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_empty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2670\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2671\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ParameterKind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2672\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'value {kind!r} is not a valid Parameter.kind'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Evaluation: RMSE Comparison"
      ],
      "metadata": {
        "id": "B31CO5UG5xCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data for evaluation\n",
        "train, test = train_test_split(ratings, test_size=0.2, random_state=42)\n",
        "\n",
        "# Predict ratings using both collaborative methods\n",
        "user_preds = test.apply(lambda row: predict_user_user(row['userId'], row['movieId']), axis=1)\n",
        "item_preds = test.apply(lambda row: predict_item_item(row['userId'], row['movieId']), axis=1)\n",
        "\n",
        "# Calculate RMSE\n",
        "user_rmse = np.sqrt(mean_squared_error(test['rating'].dropna(), user_preds.dropna()))\n",
        "item_rmse = np.sqrt(mean_squared_error(test['rating'].dropna(), item_preds.dropna()))\n",
        "\n",
        "# Plot RMSE comparison\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.bar(['User-User (Pearson)', 'Item-Item (Adjusted Cosine)'], [user_rmse, item_rmse], color=['blue', 'green'])\n",
        "plt.title(\"RMSE Comparison of Collaborative Filtering Models\")\n",
        "plt.ylabel(\"RMSE\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2KIVFVMX51_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Summary Output"
      ],
      "metadata": {
        "id": "2PLdfswj55KE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Summary ---\")\n",
        "print(f\"User-User RMSE (Pearson): {user_rmse:.4f}\")\n",
        "print(f\"Item-Item RMSE (Adjusted Cosine): {item_rmse:.4f}\")\n",
        "print(\"Content-Based filtering used L2-normalized cosine similarity on genre vectors.\")\n",
        "print(\"User-user filtering used Pearson correlation and centered ratings.\")\n",
        "print(\"Item-item filtering used adjusted cosine similarity with user-centered item vectors.\")\n"
      ],
      "metadata": {
        "id": "SCyM-ObK590E"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}