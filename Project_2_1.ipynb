{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hawa1983/DATA-612/blob/main/Project_2_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Import Required Libraries"
      ],
      "metadata": {
        "id": "_A_qwFq-455m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This section imports all necessary libraries for data processing, similarity computation, evaluation, and visualization.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity, pairwise_distances\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import normalize\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "H3xCaUKr4y-Q"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Required Libraries ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import jaccard_score\n",
        "from sklearn.preprocessing import normalize\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- Step 1: Load datasets ---\n",
        "ratings = pd.read_csv(\"https://raw.githubusercontent.com/hawa1983/DATA-612/refs/heads/main/ratings_subset.csv\")\n",
        "movies = pd.read_csv(\"https://raw.githubusercontent.com/hawa1983/DATA-612/refs/heads/main/movies_subset.csv\")\n",
        "print(f\"Loaded {ratings['userId'].nunique()} users, {ratings['movieId'].nunique()} movies.\")\n",
        "\n",
        "# --- Step 2: Sample 10,000 users and save ratings ---\n",
        "sampled_user_ids = ratings['userId'].drop_duplicates().sample(n=10000, random_state=42)\n",
        "ratings_sampled = ratings[ratings['userId'].isin(sampled_user_ids)]\n",
        "ratings_sampled.to_csv(\"ratings_sampled.csv\", index=False)\n",
        "\n",
        "# --- Step 3: Create user-movie matrix ---\n",
        "user_movie_matrix = ratings_sampled.pivot(index='userId', columns='movieId', values='rating')\n",
        "user_ids = user_movie_matrix.index.tolist()\n",
        "user_means = user_movie_matrix.mean(axis=1)\n",
        "\n",
        "# --- Step 4a: Cosine Similarity (User-Based) ---\n",
        "user_movie_centered = user_movie_matrix.sub(user_means, axis=0).fillna(0)\n",
        "cosine_sim_matrix = cosine_similarity(user_movie_centered.values)\n",
        "cosine_sim_df = pd.DataFrame(cosine_sim_matrix, index=user_ids, columns=user_ids)\n",
        "cosine_sim_df.to_csv(\"cosine_user_similarity_sampled.csv\")\n",
        "print(\"Saved cosine user-user similarity matrix.\")\n",
        "\n",
        "# --- Step 4b: Jaccard Similarity (User-Based) ---\n",
        "user_movie_binary = user_movie_matrix.notna().astype(int)\n",
        "jaccard_sim_matrix = np.zeros((len(user_ids), len(user_ids)))\n",
        "print(\"Computing Jaccard user-user similarity matrix...\")\n",
        "\n",
        "for i, user_i in enumerate(tqdm(user_ids)):\n",
        "    for j in range(i, len(user_ids)):\n",
        "        user_j = user_ids[j]\n",
        "        sim = jaccard_score(user_movie_binary.loc[user_i], user_movie_binary.loc[user_j])\n",
        "        jaccard_sim_matrix[i, j] = sim\n",
        "        jaccard_sim_matrix[j, i] = sim\n",
        "\n",
        "jaccard_sim_df = pd.DataFrame(jaccard_sim_matrix, index=user_ids, columns=user_ids)\n",
        "jaccard_sim_df.to_csv(\"jaccard_user_similarity_sampled.csv\")\n",
        "print(\"Saved Jaccard user-user similarity matrix.\")\n",
        "\n",
        "# --- Step 5: Content-Based Similarity using Genre ---\n",
        "\n",
        "# Identify genre columns (all one-hot columns after 'title' and 'movieId')\n",
        "genre_cols = [col for col in movies.columns if col not in ['movieId', 'title']]\n",
        "unique_movies = movies.copy().reset_index(drop=True)\n",
        "movie_ids = unique_movies['movieId'].tolist()\n",
        "\n",
        "# Normalize genre matrix for cosine similarity\n",
        "genre_matrix = unique_movies[genre_cols].values\n",
        "genre_matrix_normalized = normalize(genre_matrix, norm='l2')\n",
        "\n",
        "# --- Step 5a: Cosine Similarity (Content-Based) ---\n",
        "cosine_content_sim = cosine_similarity(genre_matrix_normalized)\n",
        "cosine_content_df = pd.DataFrame(cosine_content_sim, index=movie_ids, columns=movie_ids)\n",
        "cosine_content_df.to_csv(\"cosine_content_similarity.csv\")\n",
        "print(\"Saved cosine content-based similarity matrix.\")\n",
        "\n",
        "# --- Step 5b: Jaccard Similarity (Content-Based) ---\n",
        "jaccard_content_matrix = np.zeros((len(movie_ids), len(movie_ids)))\n",
        "print(\"Computing Jaccard content-based similarity matrix...\")\n",
        "\n",
        "for i in tqdm(range(len(movie_ids))):\n",
        "    for j in range(i, len(movie_ids)):\n",
        "        sim = jaccard_score(genre_matrix[i], genre_matrix[j])\n",
        "        jaccard_content_matrix[i, j] = sim\n",
        "        jaccard_content_matrix[j, i] = sim\n",
        "\n",
        "jaccard_content_df = pd.DataFrame(jaccard_content_matrix, index=movie_ids, columns=movie_ids)\n",
        "jaccard_content_df.to_csv(\"jaccard_content_similarity.csv\")\n",
        "print(\"Saved Jaccard content-based similarity matrix.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSvefQtiLXV_",
        "outputId": "9bf790ca-4c2e-4f92-f0d9-e044f4948eb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 59029 users, 11190 movies.\n",
            "Saved cosine user-user similarity matrix.\n",
            "Computing Jaccard user-user similarity matrix...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 2/10000 [01:03<87:52:28, 31.64s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Load and Preprocess Data\n",
        "\n",
        "- Downloads smaller, pre-filtered versions of the ratings and movies datasets from GitHub.\n",
        "- These files contain fewer rows and are easier to work with in Colab (won’t crash memory).\n",
        "- pd.read_csv() loads them into DataFrames named ratings and movies."
      ],
      "metadata": {
        "id": "Oo2YhHtz5CFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load subset datasets\n",
        "!wget -q https://raw.githubusercontent.com/hawa1983/DATA-612/refs/heads/main/movies_subset.csv\n",
        "!wget -q https://raw.githubusercontent.com/hawa1983/DATA-612/refs/heads/main/ratings_subset.csv\n",
        "\n",
        "ratings = pd.read_csv(\"ratings_subset.csv\")\n",
        "movies = pd.read_csv(\"movies_subset.csv\")\n",
        "\n",
        "# Step 2: Convert genres to multi-hot encoded format\n",
        "# This block prepares genre data for content-based filtering.\n",
        "# genres_list: Converts the genre string (e.g., 'Action|Adventure') into a Python list.\n",
        "# all_genres: Builds a sorted list of all unique genres in the dataset.\n",
        "# The loop creates a new column for each genre (multi-hot encoding):\n",
        "# If a movie has that genre, it gets a 1, else 0.\n",
        "\n",
        "movies['genres'] = movies['genres'].fillna('')\n",
        "movies['genres_list'] = movies['genres'].apply(lambda x: x.split('|'))\n",
        "\n",
        "all_genres = sorted(set(genre for sublist in movies['genres_list'] for genre in sublist))\n",
        "for genre in all_genres:\n",
        "    movies[genre] = movies['genres_list'].apply(lambda x: 1 if genre in x else 0)\n",
        "\n",
        "# Step 3: Merge movie features with ratings\n",
        "# Merges the processed movies DataFrame (now with genre vectors) with ratings.\n",
        "# This results in movie_data, a dataset where each row contains:\n",
        "    ## The user ID\n",
        "    ## The movie's genre indicators (1s and 0s)\n",
        "    ## The rating the user gave that movie\n",
        "\n",
        "movie_data = pd.merge(movies.drop(columns=['genres_list']), ratings, on='movieId')\n",
        "\n",
        "print(\"Shape of merged dataset:\", movie_data.shape)\n",
        "print(movie_data.head())\n"
      ],
      "metadata": {
        "id": "KfMpudFf5HrG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff50d05d-0492-4435-d573-da2912c90eb4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of merged dataset: (100000, 26)\n",
            "   movieId             title                                       genres  \\\n",
            "0        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
            "1        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
            "2        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
            "3        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
            "4        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
            "\n",
            "   (no genres listed)  Action  Adventure  Animation  Children  Comedy  Crime  \\\n",
            "0                   0       0          1          1         1       1      0   \n",
            "1                   0       0          1          1         1       1      0   \n",
            "2                   0       0          1          1         1       1      0   \n",
            "3                   0       0          1          1         1       1      0   \n",
            "4                   0       0          1          1         1       1      0   \n",
            "\n",
            "   ...  Musical  Mystery  Romance  Sci-Fi  Thriller  War  Western  userId  \\\n",
            "0  ...        0        0        0       0         0    0        0   84906   \n",
            "1  ...        0        0        0       0         0    0        0  179275   \n",
            "2  ...        0        0        0       0         0    0        0  177578   \n",
            "3  ...        0        0        0       0         0    0        0   56009   \n",
            "4  ...        0        0        0       0         0    0        0  141567   \n",
            "\n",
            "   rating   timestamp  \n",
            "0     5.0   846267205  \n",
            "1     3.5  1222031839  \n",
            "2     4.5  1326414799  \n",
            "3     3.0  1633110299  \n",
            "4     4.0  1696811851  \n",
            "\n",
            "[5 rows x 26 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Content-Based Filtering Using Genre Vectors and Cosine Similarity\n",
        "\n",
        "This code implements a **content-based recommender system** using movie genres. Each movie is represented as a binary (multi-hot) vector based on its associated genres (e.g., Action, Comedy, Drama). The steps include:\n",
        "\n",
        "* Normalizing the genre vectors using **L2 norm** so that each vector has unit length.\n",
        "* Calculating **cosine similarity** between movie vectors to measure how similar their genre compositions are.\n",
        "* Creating a function that, given a movie title, returns the top-N most similar movies (excluding itself) based purely on genre similarity.\n",
        "\n",
        "This technique does not rely on user ratings — instead, it recommends items that are similar in content (genre) to a given movie.\n",
        "\n",
        "This code implements a **non-personalized content-based recommender system** using only movie genres. It does **not use user ratings or preferences**. Instead, it recommends movies that are **similar in genre** to a specified movie.\n",
        "\n",
        "#### How It Works:\n",
        "\n",
        "* Each movie is represented as a binary (multi-hot encoded) vector across genres (e.g., Action, Comedy, Drama).\n",
        "* These vectors are **L2-normalized** so that all movies lie on a unit hypersphere — making **cosine similarity** an effective way to measure closeness.\n",
        "* Given a movie title, the model:\n",
        "\n",
        "  * Finds its genre vector.\n",
        "  * Computes cosine similarity to all other movies.\n",
        "  * Returns the top-N most similar movies (excluding itself).\n",
        "\n",
        "#### What It Does Not Do:\n",
        "\n",
        "* It does **not use any user data** (no `userId`, no ratings).\n",
        "* There is **no personalization**. All users will get the same recommendations for a given movie.\n",
        "\n",
        "#### Best Use Case:\n",
        "\n",
        "This type of model is ideal when:\n",
        "\n",
        "* You have **no user data** (cold start).\n",
        "* You want to recommend movies **based on content alone** (e.g., genre-based similarity).\n",
        "* You’re building a basic recommender system that can later be enhanced with collaborative filtering or hybrid techniques.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KD0olH695T2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Imports ---\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import random\n",
        "\n",
        "# --- Step 1: Use unique movies for similarity computation ---\n",
        "unique_movies = movies.copy().reset_index(drop=True)\n",
        "\n",
        "# --- Step 2: Normalize genre matrix ---\n",
        "genre_cols = all_genres  # Assumes 'all_genres' is your list of genre columns\n",
        "genre_matrix = unique_movies[genre_cols].values\n",
        "genre_matrix_normalized = normalize(genre_matrix, norm='l2')\n",
        "\n",
        "# --- Step 3: Create title-to-index mapping ---\n",
        "movie_idx = pd.Series(unique_movies.index, index=unique_movies['title']).drop_duplicates()\n",
        "\n",
        "# --- Step 4: Recommendation Function Based on Genre Similarity ---\n",
        "def get_recommendations(title, topN=20):\n",
        "    if title not in movie_idx:\n",
        "        return f\"Movie '{title}' not found in dataset.\"\n",
        "\n",
        "    idx = movie_idx[title]\n",
        "    query_vector = genre_matrix_normalized[idx].reshape(1, -1)\n",
        "    sim_scores = cosine_similarity(query_vector, genre_matrix_normalized)[0]\n",
        "\n",
        "    # Rank and filter out the movie itself\n",
        "    sim_scores = list(enumerate(sim_scores))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:topN+1]\n",
        "\n",
        "    # Output as list of (title, similarity score)\n",
        "    recommendations = [(unique_movies['title'][i], score) for i, score in sim_scores]\n",
        "    return recommendations\n",
        "\n",
        "# --- Step 5: Use Fixed Target Movie ---\n",
        "target_title = 'O.J.: Made in America (2016)'\n",
        "\n",
        "# Print explanation\n",
        "print(\"\\nContent-based Recommendations using GENRE similarity (cosine distance):\")\n",
        "\n",
        "# Run recommendation\n",
        "if target_title in movie_idx:\n",
        "    print(f\"\\nTop 20 Movies Most Similar in Genre to '{target_title}':\")\n",
        "    for title, sim in get_recommendations(target_title):\n",
        "        print(f\"{title:<45} Similarity: {sim:.4f}\")\n",
        "else:\n",
        "    print(f\"Movie '{target_title}' not found in the dataset.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24cDrAHnBkhH",
        "outputId": "b3bdece5-648f-4d00-d138-c882b13a9834"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Content-based Recommendations using GENRE similarity (cosine distance):\n",
            "\n",
            "Top 20 Movies Most Similar in Genre to 'O.J.: Made in America (2016)':\n",
            "Catwalk (1996)                                Similarity: 1.0000\n",
            "Anne Frank Remembered (1995)                  Similarity: 1.0000\n",
            "Man of the Year (1995)                        Similarity: 1.0000\n",
            "Crumb (1994)                                  Similarity: 1.0000\n",
            "Unzipped (1995)                               Similarity: 1.0000\n",
            "Hoop Dreams (1994)                            Similarity: 1.0000\n",
            "Wonderful, Horrible Life of Leni Riefenstahl, The (Macht der Bilder: Leni Riefenstahl, Die) (1993) Similarity: 1.0000\n",
            "War Room, The (1993)                          Similarity: 1.0000\n",
            "Celluloid Closet, The (1995)                  Similarity: 1.0000\n",
            "Haunted World of Edward D. Wood Jr., The (1996) Similarity: 1.0000\n",
            "Maya Lin: A Strong Clear Vision (1994)        Similarity: 1.0000\n",
            "Synthetic Pleasures (1995)                    Similarity: 1.0000\n",
            "Microcosmos (Microcosmos: Le peuple de l'herbe) (1996) Similarity: 1.0000\n",
            "Line King: The Al Hirschfeld Story, The (1996) Similarity: 1.0000\n",
            "Snowriders (1996)                             Similarity: 1.0000\n",
            "When We Were Kings (1996)                     Similarity: 1.0000\n",
            "Thin Blue Line, The (1988)                    Similarity: 1.0000\n",
            "Paris Is Burning (1990)                       Similarity: 1.0000\n",
            "Koyaanisqatsi (a.k.a. Koyaanisqatsi: Life Out of Balance) (1983) Similarity: 1.0000\n",
            "Paradise Lost: The Child Murders at Robin Hood Hills (1996) Similarity: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports tools for normalizing feature vectors and computing similarity between them.\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import random\n",
        "\n",
        "# Use only unique movie rows for similarity matrix\n",
        "# Copies the movies DataFrame and resets the index to ensure each movie is uniquely indexed.\n",
        "unique_movies = movies.copy().reset_index(drop=True)\n",
        "\n",
        "# Normalize genre matrix\n",
        "# Extracts the genre vectors for each movie (multi-hot encoded).\n",
        "# Applies L2 normalization so that all genre vectors have a length of 1 (helps with cosine similarity).\n",
        "genre_cols = all_genres\n",
        "genre_matrix = unique_movies[genre_cols].values\n",
        "genre_matrix_normalized = normalize(genre_matrix, norm='l2')\n",
        "\n",
        "# Create title-to-index map for unique movies\n",
        "# Creates a dictionary-like mapping from movie titles to their corresponding row index — used to look up vector positions.\n",
        "movie_idx = pd.Series(unique_movies.index, index=unique_movies['title']).drop_duplicates()\n",
        "\n",
        "# Define function to get recommendations\n",
        "# Defines a function that takes a movie title and returns the top N most similar movies.\n",
        "def get_recommendations(title, topN=20):\n",
        "    if title not in movie_idx:\n",
        "        return f\"Movie '{title}' not found in dataset.\"\n",
        "\n",
        "    idx = movie_idx[title]\n",
        "    query_vector = genre_matrix_normalized[idx].reshape(1, -1)\n",
        "    sim_scores = cosine_similarity(query_vector, genre_matrix_normalized)[0]\n",
        "\n",
        "    # Enumerate and sort scores, excluding the movie itself\n",
        "    sim_scores = list(enumerate(sim_scores))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:topN+1]\n",
        "\n",
        "    # Format output: list of (title, similarity) tuples\n",
        "    recommendations = [(unique_movies['title'][i], score) for i, score in sim_scores]\n",
        "    return recommendations\n",
        "\n",
        "\n",
        "# Sample 20 titles\n",
        "print(\"Available sample titles:\")\n",
        "print(unique_movies['title'].sample(20, random_state=41).to_list())\n",
        "\n",
        "# Randomly select a movie title from the available titles\n",
        "random_title = random.choice(unique_movies['title'].to_list())\n",
        "\n",
        "print(f\"\\n Randomly selected movie for recommendation: '{random_title}'\")\n",
        "\n",
        "# Explanation\n",
        "print(\"\\n Content-based Recommendations are based on GENRE similarity using cosine similarity between genre vectors.\")\n",
        "\n",
        "# Get recommendations\n",
        "print(f\"\\nTop 20 Movies Most Similar in Genre to '{random_title}':\")\n",
        "for title, sim in get_recommendations(random_title):\n",
        "    print(f\"{title:<45} Similarity: {sim:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-H_FaMjJ5WPM",
        "outputId": "0fee41f0-ed2d-48a7-80eb-1b251708f890",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available sample titles:\n",
            "['Atomica (2017)', 'Adventures in Babysitting (1987)', 'Big Picture, The (1989)', 'Annabelle (2014)', 'Beau Is Afraid (2023)', 'First Blood (Rambo: First Blood) (1982)', 'The Meg (2018)', 'Little Nemo: Adventures in Slumberland (1992)', 'Amen. (2002)', 'Danger: Diabolik (Diabolik) (1968)', 'Bugsy Malone (1976)', 'The Good Dinosaur (2015)', 'Goofy Movie, A (1995)', 'Man Called Horse, A (1970)', 'Terms and Conditions May Apply (2013)', 'StageFright: Aquarius (1987)', 'Shanghai Dreams (Qing hong) (2005)', 'I, Daniel Blake (2016)', \"Amores Perros (Love's a Bitch) (2000)\", \"Cookie's Fortune (1999)\"]\n",
            "\n",
            " Randomly selected movie for recommendation: 'Brave One, The (2007)'\n",
            "\n",
            " Content-based Recommendations are based on GENRE similarity using cosine similarity between genre vectors.\n",
            "\n",
            "Top 20 Movies Most Similar in Genre to 'Brave One, The (2007)':\n",
            "Amateur (1994)                                Similarity: 1.0000\n",
            "Kiss of Death (1995)                          Similarity: 1.0000\n",
            "Fresh (1994)                                  Similarity: 1.0000\n",
            "Guilty as Sin (1993)                          Similarity: 1.0000\n",
            "Killing Zoe (1994)                            Similarity: 1.0000\n",
            "Perfect World, A (1993)                       Similarity: 1.0000\n",
            "Purple Noon (Plein soleil) (1960)             Similarity: 1.0000\n",
            "Mulholland Falls (1996)                       Similarity: 1.0000\n",
            "Cape Fear (1962)                              Similarity: 1.0000\n",
            "Blood and Wine (Blood & Wine) (1996)          Similarity: 1.0000\n",
            "Desperate Measures (1998)                     Similarity: 1.0000\n",
            "Playing God (1997)                            Similarity: 1.0000\n",
            "Jackie Brown (1997)                           Similarity: 1.0000\n",
            "Twilight (1998)                               Similarity: 1.0000\n",
            "Rope (1948)                                   Similarity: 1.0000\n",
            "Shadow of a Doubt (1943)                      Similarity: 1.0000\n",
            "Lodger: A Story of the London Fog, The (1927) Similarity: 1.0000\n",
            "Few Good Men, A (1992)                        Similarity: 1.0000\n",
            "Simple Plan, A (1998)                         Similarity: 1.0000\n",
            "Limey, The (1999)                             Similarity: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hybrid Content-Based Rating Prediction Using Genre Similarity, User Behavior, and Fallback Handling\n",
        "\n",
        "This code demonstrates a *hybrid recommendation system* that combines **content-based filtering using genre similarity** with **collaborative filtering using user-specific ratings**. The objective is to predict how much a user will like a movie they've never seen, based on the genres of that movie and their past rating behavior.\n",
        "\n",
        "The prediction process incorporates a **fallback mechanism** and **debug printouts** to gracefully handle edge cases where standard hybrid predictions aren’t possible. These cases include users with no rating history, movies not present in the similarity matrix, or when no meaningful similarity is found.\n",
        "\n",
        "#### How it Works:\n",
        "\n",
        "1. **Genre Vector Normalization**:\n",
        "\n",
        "   * The genre columns are multi-hot encoded (e.g., Action, Comedy, etc.).\n",
        "   * Each movie’s genre vector is normalized using L2 norm so that cosine similarity is well-defined and scale-invariant.\n",
        "\n",
        "2. **Genre-Based Similarity Matrix**:\n",
        "\n",
        "   * Cosine similarity is computed between all pairs of movies based on genre vectors.\n",
        "\n",
        "3. **Mapping Setup**:\n",
        "\n",
        "   * The code builds lookup maps between `movieId` and its corresponding row index in the genre matrix to allow fast access.\n",
        "\n",
        "4. **Hybrid Prediction Function**:\n",
        "\n",
        "   * For a given `user_id` and `movie_id`, the function:\n",
        "\n",
        "     * Retrieves all movies rated by the user.\n",
        "     * Finds the top-K rated movies that are most genre-similar to the target movie.\n",
        "     * Computes a **weighted average of the ratings**, where the weights are the genre similarity scores.\n",
        "     * **If no such ratings or similarities are available**, the function **falls back to the global average rating of the movie**.\n",
        "     * Each fallback trigger is logged with a `[Debug]` message.\n",
        "\n",
        "5. **Application**:\n",
        "\n",
        "   * The model is tested on a sample user and generates predicted ratings for movies that are most similar in genre to a reference movie (e.g., *Heat (1995)*).\n",
        "\n",
        "This hybrid approach offers:\n",
        "\n",
        "* Personalization from collaborative filtering.\n",
        "* Interpretability from content-based features (genres).\n",
        "* Robustness from fallback logic to handle cold-starts or sparse data situations.\n"
      ],
      "metadata": {
        "id": "p6o2lnQkoljT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Required Libraries ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.preprocessing import MultiLabelBinarizer, normalize\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# --- Step 1: Keep All Ratings (No User Filtering) ---\n",
        "ratings_filtered = ratings.copy()\n",
        "\n",
        "# Build user-movie matrix\n",
        "user_movie_matrix = ratings_filtered.pivot(index='userId', columns='movieId', values='rating')\n",
        "\n",
        "# --- Step 2: Prepare Genre Matrix ---\n",
        "# Convert genre strings to lists\n",
        "movies['genres'] = movies['genres'].apply(lambda x: x.split('|') if isinstance(x, str) else [])\n",
        "\n",
        "# Filter only movies present in ratings\n",
        "valid_movie_ids = user_movie_matrix.columns\n",
        "movies_filtered = movies[movies['movieId'].isin(valid_movie_ids)].copy()\n",
        "\n",
        "# One-hot encode genres\n",
        "mlb = MultiLabelBinarizer()\n",
        "genre_matrix = mlb.fit_transform(movies_filtered['genres'])\n",
        "genre_matrix_normalized = normalize(genre_matrix, norm='l2')\n",
        "\n",
        "# Create mappings\n",
        "unique_movies = movies_filtered.reset_index(drop=True)\n",
        "movieId_to_index = dict(zip(unique_movies['movieId'], unique_movies.index))\n",
        "index_to_movieId = dict(zip(unique_movies.index, unique_movies['movieId']))\n",
        "movie_idx = pd.Series(unique_movies.index, index=unique_movies['title']).drop_duplicates()\n",
        "\n",
        "# --- Step 3: Compute Cosine Similarity Between Genre Vectors ---\n",
        "genre_sim_matrix = cosine_similarity(genre_matrix_normalized)\n",
        "\n",
        "# --- Step 4: Hybrid Prediction Function with Fallbacks and Recommendation Message ---\n",
        "def predict_rating_genre_weighted(user_id, target_movie_id, k=10):\n",
        "    if user_id not in user_movie_matrix.index or target_movie_id not in movieId_to_index:\n",
        "        print(f\"[Debug] Invalid user_id {user_id} or movie_id {target_movie_id}. Returning NaN.\")\n",
        "        return np.nan\n",
        "\n",
        "    user_ratings = user_movie_matrix.loc[user_id].dropna()\n",
        "    if user_ratings.empty:\n",
        "        print(f\"[Fallback] User {user_id} has no ratings. Using global average for movieId {target_movie_id}.\")\n",
        "        pred = ratings_filtered[ratings_filtered['movieId'] == target_movie_id]['rating'].mean()\n",
        "        print(f\"[Recommendation] Predicted Rating: {pred:.2f} → {'Recommend' if pred >= 3.5 else 'Not Recommended'}\")\n",
        "        return pred\n",
        "\n",
        "    target_idx = movieId_to_index[target_movie_id]\n",
        "    rated_movie_indices = [movieId_to_index[mid] for mid in user_ratings.index if mid in movieId_to_index]\n",
        "\n",
        "    if not rated_movie_indices:\n",
        "        print(f\"[Fallback] Rated movies not found for user {user_id}. Using global average.\")\n",
        "        pred = ratings_filtered[ratings_filtered['movieId'] == target_movie_id]['rating'].mean()\n",
        "        print(f\"[Recommendation] Predicted Rating: {pred:.2f} → {'Recommend' if pred >= 3.5 else 'Not Recommended'}\")\n",
        "        return pred\n",
        "\n",
        "    sims = genre_sim_matrix[target_idx, rated_movie_indices]\n",
        "    sims_series = pd.Series(sims, index=[index_to_movieId[i] for i in rated_movie_indices])\n",
        "\n",
        "    top_similar = sims_series.sort_values(ascending=False).head(k)\n",
        "    top_ratings = user_ratings[top_similar.index]\n",
        "\n",
        "    # Debug logs for inspection\n",
        "    print(f\"\\n[Debug] Similarity Weights for User {user_id} on Target Movie {target_movie_id}:\")\n",
        "    print(top_similar)\n",
        "    print(\"[Debug] Corresponding Ratings:\")\n",
        "    print(top_ratings)\n",
        "\n",
        "    weighted_sum = np.dot(top_similar.values, top_ratings.values)\n",
        "    normalization = np.sum(top_similar.values)\n",
        "\n",
        "    if normalization > 0:\n",
        "        pred = weighted_sum / normalization\n",
        "        print(f\"[Prediction] Personalized prediction used for user {user_id} on movieId {target_movie_id}.\")\n",
        "        print(f\"[Recommendation] Predicted Rating: {pred:.2f} → {'Recommend' if pred >= 3.5 else 'Not Recommended'}\")\n",
        "        return pred\n",
        "    else:\n",
        "        print(f\"[Fallback] No similarity weights found. Using global average for movieId {target_movie_id}.\")\n",
        "        pred = ratings_filtered[ratings_filtered['movieId'] == target_movie_id]['rating'].mean()\n",
        "        print(f\"[Recommendation] Predicted Rating: {pred:.2f} → {'Recommend' if pred >= 3.5 else 'Not Recommended'}\")\n",
        "        return pred\n",
        "\n",
        "# --- Step 5: Run with Fixed User and Movie ---\n",
        "\n",
        "# Set static user and movie\n",
        "user_id = 174949\n",
        "target_movie = 'O.J.: Made in America (2016)'\n",
        "\n",
        "print(f\"Using user {user_id} for prediction.\")\n",
        "print(f\"Target movie exists: '{target_movie}' →\", target_movie in movie_idx)\n",
        "\n",
        "if target_movie in movie_idx:\n",
        "    idx = movie_idx[target_movie]\n",
        "    sim_scores = cosine_similarity(genre_matrix_normalized[idx].reshape(1, -1), genre_matrix_normalized)[0]\n",
        "    sim_indices = np.argsort(sim_scores)[::-1][1:11]  # Exclude the movie itself\n",
        "\n",
        "    top_similar_movie_ids = unique_movies.loc[sim_indices, 'movieId']\n",
        "    top_similar_titles = unique_movies.loc[sim_indices, 'title']\n",
        "\n",
        "    print(f\"\\nTop 10 Genre-Similar Movies to '{target_movie}':\")\n",
        "    print(top_similar_titles)\n",
        "\n",
        "    print(f\"\\nPredicted Ratings for User {user_id} Using Hybrid Genre-Based Model:\\n\")\n",
        "    for movie_id, title in zip(top_similar_movie_ids, top_similar_titles):\n",
        "        pred = predict_rating_genre_weighted(user_id=user_id, target_movie_id=movie_id, k=100)\n",
        "        print(f\"{title:<45} Predicted Rating: {pred:.2f}\")\n",
        "else:\n",
        "    print(\"Target movie not found in index.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VX0bnB3JAwCt",
        "outputId": "d24f4e40-7167-4755-9617-7ffe4dbbe49d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using user 174949 for prediction.\n",
            "Target movie exists: 'O.J.: Made in America (2016)' → True\n",
            "\n",
            "Top 10 Genre-Similar Movies to 'O.J.: Made in America (2016)':\n",
            "11172    Indiana Jones: The Search for the Lost Golden ...\n",
            "98                                          Catwalk (1996)\n",
            "104                           Anne Frank Remembered (1995)\n",
            "118                                 Man of the Year (1995)\n",
            "139                                           Crumb (1994)\n",
            "177                                        Unzipped (1995)\n",
            "213                                     Hoop Dreams (1994)\n",
            "315      Wonderful, Horrible Life of Leni Riefenstahl, ...\n",
            "480                                   War Room, The (1993)\n",
            "496                           Celluloid Closet, The (1995)\n",
            "Name: title, dtype: object\n",
            "\n",
            "Predicted Ratings for User 174949 Using Hybrid Genre-Based Model:\n",
            "\n",
            "\n",
            "[Debug] Similarity Weights for User 174949 on Target Movie 287443:\n",
            "1207    0.0\n",
            "2671    0.0\n",
            "dtype: float64\n",
            "[Debug] Corresponding Ratings:\n",
            "1207    5.0\n",
            "2671    3.0\n",
            "Name: 174949, dtype: float64\n",
            "[Fallback] No similarity weights found. Using global average for movieId 287443.\n",
            "[Recommendation] Predicted Rating: 3.50 → Recommend\n",
            "Indiana Jones: The Search for the Lost Golden Age (2021) Predicted Rating: 3.50\n",
            "\n",
            "[Debug] Similarity Weights for User 174949 on Target Movie 108:\n",
            "1207    0.0\n",
            "2671    0.0\n",
            "dtype: float64\n",
            "[Debug] Corresponding Ratings:\n",
            "1207    5.0\n",
            "2671    3.0\n",
            "Name: 174949, dtype: float64\n",
            "[Fallback] No similarity weights found. Using global average for movieId 108.\n",
            "[Recommendation] Predicted Rating: 4.00 → Recommend\n",
            "Catwalk (1996)                                Predicted Rating: 4.00\n",
            "\n",
            "[Debug] Similarity Weights for User 174949 on Target Movie 116:\n",
            "1207    0.0\n",
            "2671    0.0\n",
            "dtype: float64\n",
            "[Debug] Corresponding Ratings:\n",
            "1207    5.0\n",
            "2671    3.0\n",
            "Name: 174949, dtype: float64\n",
            "[Fallback] No similarity weights found. Using global average for movieId 116.\n",
            "[Recommendation] Predicted Rating: 4.67 → Recommend\n",
            "Anne Frank Remembered (1995)                  Predicted Rating: 4.67\n",
            "\n",
            "[Debug] Similarity Weights for User 174949 on Target Movie 137:\n",
            "1207    0.0\n",
            "2671    0.0\n",
            "dtype: float64\n",
            "[Debug] Corresponding Ratings:\n",
            "1207    5.0\n",
            "2671    3.0\n",
            "Name: 174949, dtype: float64\n",
            "[Fallback] No similarity weights found. Using global average for movieId 137.\n",
            "[Recommendation] Predicted Rating: 5.00 → Recommend\n",
            "Man of the Year (1995)                        Predicted Rating: 5.00\n",
            "\n",
            "[Debug] Similarity Weights for User 174949 on Target Movie 162:\n",
            "1207    0.0\n",
            "2671    0.0\n",
            "dtype: float64\n",
            "[Debug] Corresponding Ratings:\n",
            "1207    5.0\n",
            "2671    3.0\n",
            "Name: 174949, dtype: float64\n",
            "[Fallback] No similarity weights found. Using global average for movieId 162.\n",
            "[Recommendation] Predicted Rating: 4.03 → Recommend\n",
            "Crumb (1994)                                  Predicted Rating: 4.03\n",
            "\n",
            "[Debug] Similarity Weights for User 174949 on Target Movie 206:\n",
            "1207    0.0\n",
            "2671    0.0\n",
            "dtype: float64\n",
            "[Debug] Corresponding Ratings:\n",
            "1207    5.0\n",
            "2671    3.0\n",
            "Name: 174949, dtype: float64\n",
            "[Fallback] No similarity weights found. Using global average for movieId 206.\n",
            "[Recommendation] Predicted Rating: 3.50 → Recommend\n",
            "Unzipped (1995)                               Predicted Rating: 3.50\n",
            "\n",
            "[Debug] Similarity Weights for User 174949 on Target Movie 246:\n",
            "1207    0.0\n",
            "2671    0.0\n",
            "dtype: float64\n",
            "[Debug] Corresponding Ratings:\n",
            "1207    5.0\n",
            "2671    3.0\n",
            "Name: 174949, dtype: float64\n",
            "[Fallback] No similarity weights found. Using global average for movieId 246.\n",
            "[Recommendation] Predicted Rating: 4.12 → Recommend\n",
            "Hoop Dreams (1994)                            Predicted Rating: 4.12\n",
            "\n",
            "[Debug] Similarity Weights for User 174949 on Target Movie 363:\n",
            "1207    0.0\n",
            "2671    0.0\n",
            "dtype: float64\n",
            "[Debug] Corresponding Ratings:\n",
            "1207    5.0\n",
            "2671    3.0\n",
            "Name: 174949, dtype: float64\n",
            "[Fallback] No similarity weights found. Using global average for movieId 363.\n",
            "[Recommendation] Predicted Rating: 3.50 → Recommend\n",
            "Wonderful, Horrible Life of Leni Riefenstahl, The (Macht der Bilder: Leni Riefenstahl, Die) (1993) Predicted Rating: 3.50\n",
            "\n",
            "[Debug] Similarity Weights for User 174949 on Target Movie 556:\n",
            "1207    0.0\n",
            "2671    0.0\n",
            "dtype: float64\n",
            "[Debug] Corresponding Ratings:\n",
            "1207    5.0\n",
            "2671    3.0\n",
            "Name: 174949, dtype: float64\n",
            "[Fallback] No similarity weights found. Using global average for movieId 556.\n",
            "[Recommendation] Predicted Rating: 3.25 → Not Recommended\n",
            "War Room, The (1993)                          Predicted Rating: 3.25\n",
            "\n",
            "[Debug] Similarity Weights for User 174949 on Target Movie 581:\n",
            "1207    0.0\n",
            "2671    0.0\n",
            "dtype: float64\n",
            "[Debug] Corresponding Ratings:\n",
            "1207    5.0\n",
            "2671    3.0\n",
            "Name: 174949, dtype: float64\n",
            "[Fallback] No similarity weights found. Using global average for movieId 581.\n",
            "[Recommendation] Predicted Rating: 4.17 → Recommend\n",
            "Celluloid Closet, The (1995)                  Predicted Rating: 4.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hybrid Recommender: Genre-Weighted Collaborative Filtering**\n",
        "\n",
        "This code predicts a user's rating for a movie by combining collaborative filtering and genre-based similarity. Here's how it works:\n",
        "\n",
        "### **Step-by-Step Explanation**\n",
        "\n",
        "**1. Data Preparation**\n",
        "\n",
        "* It loads the `ratings` and `movies` datasets.\n",
        "* The user-movie ratings matrix is built using `.pivot()` (rows = users, columns = movies, values = ratings).\n",
        "* Movie genres are split and one-hot encoded using `MultiLabelBinarizer`.\n",
        "* Genre vectors are normalized to enable cosine similarity comparison.\n",
        "\n",
        "**2. Genre Similarity Calculation**\n",
        "\n",
        "* Cosine similarity is computed between normalized genre vectors of all movies.\n",
        "* This generates a matrix showing how similar each pair of movies is based on genre.\n",
        "\n",
        "**3. `hybrid_predict()` Function:**\n",
        "This is the main prediction function. Here's what it does:\n",
        "\n",
        "* **Step 1**: Skips invalid user/movie inputs.\n",
        "* **Step 2**: Loops through all other users (excluding the target user).\n",
        "* **Step 3**: For each user, checks if they rated the target movie.\n",
        "* **Step 4**: Collects that user's other rated movies and looks up genre similarity between those and the target movie.\n",
        "* **Step 5**: Uses a weighted average of the other user's ratings on similar movies, weighted by genre similarity.\n",
        "* **Step 6**: Averages all such weighted predictions from other users to generate the final prediction.\n",
        "* **Fallback**: If no useful ratings are found, it falls back to the global average rating for the movie.\n",
        "\n",
        "**4. Prediction Execution**\n",
        "\n",
        "* The code sets `user_id = 174949` and `target_movie = 'O.J.: Made in America (2016)'`.\n",
        "* It retrieves the `movieId` and runs the `hybrid_predict()` function.\n",
        "* Finally, it prints the predicted rating for that user and movie.\n",
        "\n",
        "*This approach combines user behavior (collaborative filtering) with genre-based content similarity to improve prediction accuracy, especially for sparse data or cold-start problems.*\n"
      ],
      "metadata": {
        "id": "XQMqGRzZkhcU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Vectorized NumPy Logic – Genre-Based Hybrid Prediction"
      ],
      "metadata": {
        "id": "mJupUOM_Ia4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MultiLabelBinarizer, normalize\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Step 1: Load subset datasets\n",
        "!wget -q https://raw.githubusercontent.com/hawa1983/DATA-612/refs/heads/main/movies_subset.csv\n",
        "!wget -q https://raw.githubusercontent.com/hawa1983/DATA-612/refs/heads/main/ratings_subset.csv\n",
        "\n",
        "ratings = pd.read_csv(\"ratings_subset.csv\")\n",
        "movies = pd.read_csv(\"movies_subset.csv\")\n",
        "\n",
        "# Step 1: Prepare Data\n",
        "ratings_filtered = ratings.copy()\n",
        "user_movie_matrix = ratings_filtered.pivot(index='userId', columns='movieId', values='rating')\n",
        "\n",
        "movies['genres'] = movies['genres'].apply(lambda x: x.split('|') if isinstance(x, str) else [])\n",
        "valid_movie_ids = user_movie_matrix.columns\n",
        "movies_filtered = movies[movies['movieId'].isin(valid_movie_ids)].copy()\n",
        "\n",
        "mlb = MultiLabelBinarizer()\n",
        "genre_matrix = mlb.fit_transform(movies_filtered['genres'])\n",
        "genre_matrix_normalized = normalize(genre_matrix, norm='l2')\n",
        "\n",
        "unique_movies = movies_filtered.reset_index(drop=True)\n",
        "movieId_to_index = dict(zip(unique_movies['movieId'], unique_movies.index))\n",
        "index_to_movieId = dict(zip(unique_movies.index, unique_movies['movieId']))\n",
        "movie_idx = pd.Series(unique_movies.index, index=unique_movies['title']).drop_duplicates()\n",
        "\n",
        "# Step 2: Vectorized Hybrid Prediction Function (Genre-only Weighted)\n",
        "def vectorized_hybrid_predict(user_id, target_movie_id, k=10):\n",
        "    if user_id not in user_movie_matrix.index or target_movie_id not in movieId_to_index:\n",
        "        return np.nan\n",
        "\n",
        "    target_idx = movieId_to_index[target_movie_id]\n",
        "    sim_vector = cosine_similarity(genre_matrix_normalized[target_idx].reshape(1, -1), genre_matrix_normalized)[0]\n",
        "\n",
        "    user_ratings = user_movie_matrix.loc[user_id].dropna()\n",
        "    rated_movie_ids = user_ratings.index.intersection(user_movie_matrix.columns)\n",
        "    rated_indices = [movieId_to_index[mid] for mid in rated_movie_ids if mid in movieId_to_index]\n",
        "\n",
        "    sim_scores = sim_vector[rated_indices]\n",
        "    ratings_values = user_ratings.loc[rated_movie_ids].values\n",
        "\n",
        "    if len(sim_scores) == 0 or np.sum(sim_scores) == 0:\n",
        "        return np.nan\n",
        "\n",
        "    top_k_indices = np.argsort(sim_scores)[-k:]\n",
        "    sim_top = sim_scores[top_k_indices]\n",
        "    rating_top = ratings_values[top_k_indices]\n",
        "\n",
        "    return np.dot(sim_top, rating_top) / np.sum(sim_top)\n",
        "\n",
        "# Example Usage\n",
        "# user_id = 174949\n",
        "valid_user = None\n",
        "for uid in user_movie_matrix.index:\n",
        "    rated_movies = user_movie_matrix.loc[uid].dropna().index\n",
        "    if rated_movies.intersection(movieId_to_index.keys()).any():\n",
        "        valid_user = uid\n",
        "        break  # Exit the loop immediately once a valid user is found\n",
        "\n",
        "user_id = valid_user\n",
        "\n",
        "\n",
        "target_movie = 'O.J.: Made in America (2016)'\n",
        "target_movie_id = unique_movies.loc[movie_idx[target_movie], 'movieId']\n",
        "pred = vectorized_hybrid_predict(user_id, target_movie_id, k=100)\n",
        "print(f\"Predicted rating for '{target_movie}' by user {user_id}: {pred:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpqEFAeGElOp",
        "outputId": "3cf1ab91-c533-4e94-e808-9d0ee4d9366a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted rating for 'O.J.: Made in America (2016)' by user 10: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Blended Hybrid (Genre + Collaborative Filtering) with Precomputed Hybrid Similarity"
      ],
      "metadata": {
        "id": "isnJMUbUIea3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MultiLabelBinarizer, normalize\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Step 1: Load subset datasets\n",
        "!wget -q https://raw.githubusercontent.com/hawa1983/DATA-612/refs/heads/main/movies_subset.csv\n",
        "!wget -q https://raw.githubusercontent.com/hawa1983/DATA-612/refs/heads/main/ratings_subset.csv\n",
        "\n",
        "# Step 1: Prepare Data\n",
        "ratings_filtered = ratings.copy()\n",
        "user_movie_matrix = ratings_filtered.pivot(index='userId', columns='movieId', values='rating')\n",
        "\n",
        "movies['genres'] = movies['genres'].apply(lambda x: x.split('|') if isinstance(x, str) else [])\n",
        "valid_movie_ids = user_movie_matrix.columns\n",
        "movies_filtered = movies[movies['movieId'].isin(valid_movie_ids)].copy()\n",
        "\n",
        "mlb = MultiLabelBinarizer()\n",
        "genre_matrix = mlb.fit_transform(movies_filtered['genres'])\n",
        "genre_matrix_normalized = normalize(genre_matrix, norm='l2')\n",
        "\n",
        "unique_movies = movies_filtered.reset_index(drop=True)\n",
        "movieId_to_index = dict(zip(unique_movies['movieId'], unique_movies.index))\n",
        "index_to_movieId = dict(zip(unique_movies.index, unique_movies['movieId']))\n",
        "movie_idx = pd.Series(unique_movies.index, index=unique_movies['title']).drop_duplicates()\n",
        "\n",
        "# Step 2: Compute Hybrid Similarity Matrix\n",
        "genre_sim = cosine_similarity(genre_matrix_normalized)\n",
        "user_movie_centered = user_movie_matrix.sub(user_movie_matrix.mean(axis=1), axis=0).fillna(0)\n",
        "item_sim = cosine_similarity(user_movie_centered.T.fillna(0))\n",
        "\n",
        "# Ensure both matrices are same shape\n",
        "alpha = 0.5  # genre-collab blend weight\n",
        "hybrid_sim = alpha * genre_sim + (1 - alpha) * item_sim\n",
        "\n",
        "# Step 3: Prediction Function Using Hybrid Similarity\n",
        "def blended_hybrid_predict(user_id, target_movie_id, k=10):\n",
        "    if user_id not in user_movie_matrix.index or target_movie_id not in movieId_to_index:\n",
        "        return np.nan\n",
        "\n",
        "    target_idx = movieId_to_index[target_movie_id]\n",
        "    sim_vector = hybrid_sim[target_idx]\n",
        "\n",
        "    user_ratings = user_movie_matrix.loc[user_id].dropna()\n",
        "    rated_movie_ids = user_ratings.index.intersection(user_movie_matrix.columns)\n",
        "    rated_indices = [movieId_to_index[mid] for mid in rated_movie_ids if mid in movieId_to_index]\n",
        "\n",
        "    sim_scores = sim_vector[rated_indices]\n",
        "    ratings_values = user_ratings.loc[rated_movie_ids].values\n",
        "\n",
        "    if len(sim_scores) == 0 or np.sum(sim_scores) == 0:\n",
        "        return np.nan\n",
        "\n",
        "    top_k_indices = np.argsort(sim_scores)[-k:]\n",
        "    sim_top = sim_scores[top_k_indices]\n",
        "    rating_top = ratings_values[top_k_indices]\n",
        "\n",
        "    return np.dot(sim_top, rating_top) / np.sum(sim_top)\n",
        "\n",
        "# Example Usage\n",
        "user_id = 174949\n",
        "target_movie = 'O.J.: Made in America (2016)'\n",
        "target_movie_id = unique_movies.loc[movie_idx[target_movie], 'movieId']\n",
        "pred = blended_hybrid_predict(user_id, target_movie_id, k=100)\n",
        "print(f\"Predicted rating for '{target_movie}' by user {user_id}: {pred:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "ak3yfaL-IkP_",
        "outputId": "4033a60d-ed0b-47e4-84db-3508d9b24491"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Found array with 0 feature(s) (shape=(11190, 0)) while a minimum of 1 is required by the normalize function.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-1584051649>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mmlb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiLabelBinarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mgenre_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovies_filtered\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'genres'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mgenre_matrix_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenre_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0munique_movies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmovies_filtered\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(X, norm, axis, copy, return_norm)\u001b[0m\n\u001b[1;32m   1963\u001b[0m     \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1965\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1966\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1967\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msparse_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1137\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mensure_min_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1140\u001b[0m                 \u001b[0;34m\"Found array with %d feature(s) (shape=%s) while\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 \u001b[0;34m\" a minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found array with 0 feature(s) (shape=(11190, 0)) while a minimum of 1 is required by the normalize function."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparison of Overlapping and Divergent Recommendations\n",
        "\n",
        "Both methods returned several overlapping recommendations, but also differed in meaningful ways:\n",
        "\n",
        "#### Similar Recommendations from Both Methods\n",
        "\n",
        "* **Assassins (1995)**\n",
        "* **Net, The (1995)**\n",
        "\n",
        "These consistent suggestions indicate that both the pure content-based and hybrid genre-weighted models identify core genre traits effectively.\n",
        "\n",
        "#### Recommendations Unique to Each Method\n",
        "\n",
        "**Only in Content-Based (Cosine Genre Similarity):**\n",
        "\n",
        "* *Die Hard (1988)*\n",
        "* *Batman (1989)*\n",
        "* *U.S. Marshals (1998)*\n",
        "\n",
        "**Only in Hybrid Model (Genre + Ratings Fallback):**\n",
        "\n",
        "* *Sin City: A Dame to Kill For (2014)*\n",
        "* *John Wick: Chapter Two (2017)*\n",
        "* *Transporter 2 (2005)*\n",
        "\n",
        "These differences show that the hybrid method is able to introduce newer or slightly more nuanced genre matches, even when rating data for a specific user is missing and fallback mechanisms are triggered.\n"
      ],
      "metadata": {
        "id": "Z6_Z7TyTwAhl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimized Jaccard Similarity for Content-Based Filtering\n",
        "\n",
        "This block introduces a more efficient method for computing **Jaccard similarity** between movies based on their genre information. Unlike the traditional nested-loop approach, this implementation uses the `pdist()` function from `scipy.spatial.distance` to compute all pairwise Jaccard distances in a **fully vectorized** manner. The result is a symmetric similarity matrix, which is then used to identify the most similar movies to a given title. This optimization drastically reduces computation time and is highly recommended for medium-to-large datasets.\n",
        "\n",
        "using `scipy.spatial.distance.pdist()` **does calculate all pairwise similarities**, but it does so much more efficiently than a manual loop.\n",
        "\n",
        "Here’s how it works:\n",
        "\n",
        "* `pdist(binary_matrix, metric='jaccard')` computes the **Jaccard distance** (which is `1 - Jaccard similarity`) between **all unique pairs** of rows (i.e., movies) in the binary genre matrix.\n",
        "* The output is a **condensed distance matrix** — a flat array containing the upper triangle of the full pairwise distance matrix.\n",
        "* This condensed matrix is converted back into a full square **symmetric matrix** using `squareform()`, giving us the distance between all pairs.\n",
        "* We then compute similarity as `1 - distance`.\n",
        "\n",
        "Every possible movie-to-movie similarity is calculated — but with optimized vectorized operations under the hood, which is much faster than nested Python loops.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZK-ho_H6hrOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial.distance import pdist, squareform\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Prepare genre binary matrix\n",
        "unique_movies = movies.copy().reset_index(drop=True)\n",
        "genre_cols = all_genres\n",
        "genre_matrix = unique_movies[genre_cols].astype(bool).astype(int).values  # ensure binary format\n",
        "\n",
        "# Step 2: Compute Jaccard distance (1 - similarity)\n",
        "# pdist returns a condensed distance matrix; squareform converts it to square form\n",
        "jaccard_distance = pdist(genre_matrix, metric='jaccard')  # returns 1 - Jaccard similarity\n",
        "jaccard_sim_matrix = 1 - squareform(jaccard_distance)      # convert to full similarity matrix\n",
        "\n",
        "# Step 3: Create mapping from title to matrix index\n",
        "movie_idx = pd.Series(unique_movies.index, index=unique_movies['title']).drop_duplicates()\n",
        "\n",
        "# Step 4: Define recommendation function\n",
        "def get_recommendations_jaccard(title, topN=10):\n",
        "    if title not in movie_idx:\n",
        "        return f\"Movie '{title}' not found in dataset.\"\n",
        "\n",
        "    idx = movie_idx[title]\n",
        "    sim_scores = list(enumerate(jaccard_sim_matrix[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:topN+1]  # exclude self\n",
        "    top_indices = [i[0] for i in sim_scores]\n",
        "    return unique_movies['title'].iloc[top_indices]\n",
        "\n",
        "# Step 5: Try a sample movie\n",
        "print(\"Sample titles:\", unique_movies['title'].sample(5, random_state=42).to_list())\n",
        "print(f\"\\nJaccard Recommendations for {random_title}:\")\n",
        "# print(get_recommendations_jaccard(\"Heat (1995)\"))\n",
        "print(get_recommendations_jaccard(random_title))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8l-M-JJekRl-",
        "outputId": "78ad6b33-26d9-4626-81e6-99833f9abce5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample titles: ['Murder on the Orient Express (2017)', 'Rhapsody in August (Hachi-gatsu no kyôshikyoku) (1991)', 'First Position (2011)', 'Wait Until Dark (1967)', 'Coffy (1973)']\n",
            "\n",
            "Jaccard Recommendations for Youth (2015):\n",
            "25                      Othello (1995)\n",
            "30              Dangerous Minds (1995)\n",
            "38     Cry, the Beloved Country (1995)\n",
            "41                  Restoration (1995)\n",
            "51                      Georgia (1995)\n",
            "52        Home for the Holidays (1995)\n",
            "57           Mr. Holland's Opus (1995)\n",
            "62                     Two Bits (1995)\n",
            "103           Margaret's Museum (1995)\n",
            "108    Boys of St. Vincent, The (1992)\n",
            "Name: title, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparison of Content-Based Recommendations: Cosine vs. Jaccard Similarity\n",
        "\n",
        "Both the **cosine similarity** and **Jaccard similarity** methods returned *identical top-10 movie recommendations* for the query movie **\"Heat (1995)\"**. This indicates that in the context of the MovieLens genre-based content filtering:\n",
        "\n",
        "* **Both methods effectively captured the same neighborhood of similar films**.\n",
        "* The movies recommended (e.g., *Assassins*, *Die Hard*, *The Net*, *Natural Born Killers*) suggest that the genre combinations for these titles closely match those of *Heat (1995)*.\n",
        "* While **cosine similarity** operates on normalized multi-hot vectors and measures angular proximity,\n",
        "  **Jaccard similarity** measures the overlap in genre tags directly.\n",
        "\n",
        "### Key Takeaway:\n",
        "\n",
        "Despite their different mathematical underpinnings, both methods **produced the same results** because:\n",
        "\n",
        "* The genre vectors are binary (multi-hot encoded), where normalization (in cosine) doesn’t distort information significantly.\n",
        "* The dominant factor influencing similarity is the **overlap of genre labels**, which both metrics capture well.\n",
        "\n",
        "However:\n",
        "\n",
        "* **Cosine similarity is computationally faster** and more scalable.\n",
        "* **Jaccard similarity is slower** when computed pairwise using loops, though vectorized solutions like `pdist()` improve it significantly.\n",
        "\n",
        "You can safely use either in this binary genre context, but for large-scale systems, cosine is typically preferred for efficiency.\n"
      ],
      "metadata": {
        "id": "RLrKOSN4mnK0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# User-User Collaborative Filtering with Bias Adjustment and Fallback Logic\n",
        "\n",
        "This recommender system applies a user-user collaborative filtering approach enhanced with user and item bias adjustments and robust fallback logic to ensure stable and interpretable predictions. The method is designed to make personalized movie rating predictions even in cases of sparse data.\n",
        "\n",
        "**1. Data Sampling and Matrix Construction**\n",
        "A sample of 10,000 users is drawn randomly from the full ratings dataset to manage memory and computational requirements. A user-movie matrix is constructed using these ratings, where each cell represents the rating a user has given to a movie. The system computes average ratings per user (user bias) and per movie (item bias) to help model baseline tendencies.\n",
        "\n",
        "**2. Centering and Similarity Calculation**\n",
        "To isolate users' preferences from their general rating behavior, the user-movie matrix is centered by subtracting each user's average rating. This centered matrix is then used to calculate cosine similarity between users, generating a user-user similarity matrix that quantifies how closely users' preferences align.\n",
        "\n",
        "**3. Predicting Ratings Using Top-k Neighbors**\n",
        "To predict a rating for a given user and movie, the system:\n",
        "\n",
        "* Identifies the top-k most similar users who have rated the target movie.\n",
        "* Computes the deviation of these neighbors’ ratings from their respective means.\n",
        "* Uses a weighted average of these deviations, weighted by similarity, and adds it to the target user’s mean to produce the prediction.\n",
        "\n",
        "This formula is:\n",
        "\n",
        "$$\n",
        "\\hat{r}_{u,i} = \\mu_u + \\frac{\\sum_{v \\in N(u)} \\text{sim}(u,v) \\cdot (r_{v,i} - \\mu_v)}{\\sum_{v \\in N(u)} \\text{sim}(u,v)}\n",
        "$$\n",
        "\n",
        "**4. Bias-Based Fallback Logic**\n",
        "If the user has no similar neighbors who have rated the movie, or if the similarity weights sum to zero, the system falls back to a bias-based estimate:\n",
        "\n",
        "$$\n",
        "\\hat{r}_{u,i} = \\mu_u + \\mu_i - \\mu_{global}\n",
        "$$\n",
        "\n",
        "This combines the user’s and the item’s average rating, adjusted by subtracting the global mean to avoid double-counting. If either the user or item bias is unavailable, the system defaults to the global average rating.\n",
        "\n",
        "**5. Clamping Predictions to Rating Scale**\n",
        "All final predictions are clamped to the valid rating range \\[0.5, 5.0] to ensure they remain realistic and consistent with actual rating values.\n",
        "\n",
        "**6. Fallback Testing for Cold-Start Scenarios**\n",
        "The system includes a test routine to simulate cold-start scenarios by selecting users who have not rated the target movie. This verifies that the fallback mechanism generates meaningful predictions even when minimal user-item interaction data is available.\n",
        "\n",
        "This hybrid approach ensures personalized predictions while remaining resilient in sparse data conditions, making it suitable for practical recommender systems.\n"
      ],
      "metadata": {
        "id": "lwSEuluhhOuq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sampling and Computing Cosine Similarity for User-Based Collaborative Filtering\n",
        "\n",
        "This code prepares a smaller, manageable dataset from a larger ratings file and computes a user-user cosine similarity matrix to be used in a recommender system. Each step has a clear purpose:\n",
        "\n",
        "**1. Load Full Ratings Data**\n",
        "*Purpose: To retrieve the entire dataset of user-movie ratings for processing.*\n",
        "The code loads the full ratings dataset from a remote source and reports how many unique users and movies are present.\n",
        "\n",
        "**2. Sample 10,000 Unique Users**\n",
        "*Purpose: To reduce computational load by working with a representative subset of the data.*\n",
        "The code randomly selects 10,000 unique users and filters the ratings dataset to include only those users. This sampled dataset is then saved for future use.\n",
        "\n",
        "**3. Create User-Movie Matrix**\n",
        "*Purpose: To structure the data into a matrix format suitable for similarity calculations.*\n",
        "A pivot table is created where rows are users, columns are movies, and values are the corresponding ratings. This format allows for pairwise comparisons between users.\n",
        "\n",
        "**4. Center Ratings**\n",
        "*Purpose: To normalize user behavior by removing individual rating biases.*\n",
        "The code subtracts each user's average rating from their rated movies. This centers the data around zero and ensures that similarity is based on rating patterns rather than absolute values.\n",
        "\n",
        "**5. Compute Cosine Similarity**\n",
        "*Purpose: To quantify how similar users are based on their centered rating patterns.*\n",
        "Using the centered matrix, the cosine similarity is calculated between every pair of users. This measures how aligned users are in terms of their movie preferences.\n",
        "\n",
        "**6. Save Similarity Matrix**\n",
        "*Purpose: To preserve the computed similarity matrix for use in building and testing recommendation algorithms.*\n",
        "The resulting cosine similarity matrix is converted into a labeled DataFrame and saved as a CSV file for later use in prediction models.\n",
        "\n",
        "This process builds a scalable foundation for collaborative filtering by focusing on user similarity based on normalized preferences.\n"
      ],
      "metadata": {
        "id": "BHO8ItD5Gwfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Required Libraries ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Step 1: Load full ratings data\n",
        "ratings = pd.read_csv(\"https://raw.githubusercontent.com/hawa1983/DATA-612/refs/heads/main/ratings_subset.csv\")\n",
        "print(f\"Loaded dataset with {ratings['userId'].nunique()} users and {ratings['movieId'].nunique()} movies.\")\n",
        "\n",
        "# Step 2: Sample 10,000 unique users\n",
        "sampled_user_ids = ratings['userId'].drop_duplicates().sample(n=10000, random_state=42)\n",
        "ratings_sampled = ratings[ratings['userId'].isin(sampled_user_ids)]\n",
        "ratings_sampled.to_csv(\"ratings_sampled.csv\", index=False)\n",
        "print(f\"Sampled dataset saved with {ratings_sampled['userId'].nunique()} users and {ratings_sampled['movieId'].nunique()} movies.\")\n",
        "\n",
        "# Step 3: Create user-movie matrix from sampled data\n",
        "user_movie_matrix = ratings_sampled.pivot(index='userId', columns='movieId', values='rating')\n",
        "user_means = user_movie_matrix.mean(axis=1)\n",
        "user_ids = user_movie_matrix.index.tolist()\n",
        "\n",
        "# Step 4: Center ratings\n",
        "user_movie_centered = user_movie_matrix.sub(user_means, axis=0).fillna(0)\n",
        "\n",
        "# Step 5: Compute cosine similarity\n",
        "print(\"Computing cosine similarity matrix for sampled users...\")\n",
        "cosine_sim_matrix = cosine_similarity(user_movie_centered.values)\n",
        "\n",
        "# Step 6: Convert to DataFrame and save\n",
        "cosine_sim_df = pd.DataFrame(cosine_sim_matrix, index=user_ids, columns=user_ids)\n",
        "cosine_sim_df.to_csv(\"cosine_user_similarity_sampled.csv\")\n",
        "print(\"Cosine similarity matrix saved as 'cosine_user_similarity_sampled.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kzj1U0-yLa8v",
        "outputId": "34865b84-572c-4f8b-aa2e-a283581dd113"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded dataset with 59029 users and 11190 movies.\n",
            "Sampled dataset saved with 10000 users and 4933 movies.\n",
            "Computing cosine similarity matrix for sampled users...\n",
            "Cosine similarity matrix saved as 'cosine_user_similarity_sampled.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "geZnz5ZcI7SP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Required Libraries ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics import jaccard_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Step 1: Load full ratings data\n",
        "ratings = pd.read_csv(\"https://raw.githubusercontent.com/hawa1983/DATA-612/refs/heads/main/ratings_subset.csv\")\n",
        "print(f\"Loaded dataset with {ratings['userId'].nunique()} users and {ratings['movieId'].nunique()} movies.\")\n",
        "\n",
        "# Step 2: Sample 10,000 unique users\n",
        "sampled_user_ids = ratings['userId'].drop_duplicates().sample(n=10000, random_state=42)\n",
        "ratings_sampled = ratings[ratings['userId'].isin(sampled_user_ids)]\n",
        "ratings_sampled.to_csv(\"ratings_sampled.csv\", index=False)\n",
        "print(f\"Sampled dataset saved with {ratings_sampled['userId'].nunique()} users and {ratings_sampled['movieId'].nunique()} movies.\")\n",
        "\n",
        "# Step 3: Create binary user-movie matrix (1 if rated, 0 if not)\n",
        "user_movie_matrix = ratings_sampled.pivot(index='userId', columns='movieId', values='rating')\n",
        "user_movie_binary = user_movie_matrix.notna().astype(int)\n",
        "user_ids = user_movie_binary.index.tolist()\n",
        "\n",
        "# Step 4: Compute Jaccard similarity\n",
        "print(\"Computing Jaccard similarity matrix for sampled users...\")\n",
        "\n",
        "jaccard_sim_matrix = np.zeros((len(user_ids), len(user_ids)))\n",
        "\n",
        "for i, user_i in enumerate(tqdm(user_ids)):\n",
        "    for j in range(i, len(user_ids)):\n",
        "        user_j = user_ids[j]\n",
        "        sim = jaccard_score(user_movie_binary.loc[user_i], user_movie_binary.loc[user_j])\n",
        "        jaccard_sim_matrix[i, j] = sim\n",
        "        jaccard_sim_matrix[j, i] = sim  # symmetric\n",
        "\n",
        "# Step 5: Convert to DataFrame and save\n",
        "jaccard_sim_df = pd.DataFrame(jaccard_sim_matrix, index=user_ids, columns=user_ids)\n",
        "jaccard_sim_df.to_csv(\"jaccard_user_similarity_sampled.csv\")\n",
        "print(\"Jaccard similarity matrix saved as 'jaccard_user_similarity_sampled.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "foep345RI77P",
        "outputId": "cddd825b-95c0-41af-f666-986e18c1fecf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded dataset with 59029 users and 11190 movies.\n",
            "Sampled dataset saved with 10000 users and 4933 movies.\n",
            "Computing Jaccard similarity matrix for sampled users...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 8/10000 [04:33<94:50:02, 34.17s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-443740656>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0muser_j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjaccard_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_movie_binary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_movie_binary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_j\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mjaccard_sim_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mjaccard_sim_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msim\u001b[0m  \u001b[0;31m# symmetric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mjaccard_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m    921\u001b[0m     \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0.33\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m     \"\"\"\n\u001b[0;32m--> 923\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    924\u001b[0m     \u001b[0msamplewise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"samples\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m     MCM = multilabel_confusion_matrix(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1597\u001b[0m     \u001b[0;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m     \u001b[0;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;31m# Check that we don't mix label format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0mys_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mys_types\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mys_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;31m# Check that we don't mix label format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0mys_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mys_types\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mys_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[0;34m(y, input_name, raise_unknown)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mVisibleDeprecationWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Complex data not supported\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m def check_array(\n\u001b[0m\u001b[1;32m    737\u001b[0m     \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# User-Based Collaborative Filtering with Cosine Similarity and Bias Adjustment\n",
        "\n",
        "This system predicts how a user might rate a movie they haven’t seen, using the behavior of similar users. It employs a user-based collaborative filtering approach, enhanced with cosine similarity and bias adjustment, and includes fallback logic to handle missing data. Below is a breakdown of the methodology with the purpose of each step.\n",
        "\n",
        "**1. Data Preparation**\n",
        "*Purpose: To structure the raw data into a usable format for similarity computation and rating prediction.*\n",
        "\n",
        "* Loads the movie metadata and user ratings datasets.\n",
        "* Constructs a user-movie matrix, where rows represent users and columns represent movies.\n",
        "* Calculates:\n",
        "\n",
        "  * Each user’s average rating (to normalize personal biases)\n",
        "  * Each movie’s average rating (used in fallback logic)\n",
        "  * The global average rating (used as a last-resort fallback)\n",
        "\n",
        "**2. Similarity Matrix Handling**\n",
        "*Purpose: To determine how similar each user is to every other user, based on shared rating behavior.*\n",
        "This step ensures that a valid user-user cosine similarity matrix is available by following one of three approaches:\n",
        "\n",
        "* **Check for a Local File:**\n",
        "  If the matrix already exists on the local machine, it is loaded directly for efficiency.\n",
        "\n",
        "* **Download from Cloud Storage:**\n",
        "  If the local file is missing, the system attempts to download a precomputed matrix from Google Drive.\n",
        "\n",
        "* **Compute Similarity Manually:**\n",
        "  If downloading fails:\n",
        "\n",
        "  * User ratings are centered by subtracting their individual means\n",
        "  * Missing ratings are filled with zeros to allow matrix operations\n",
        "  * Cosine similarity is computed between users\n",
        "  * The resulting matrix is saved locally for future reuse\n",
        "\n",
        "This three-step fallback ensures the system is flexible and always functional, regardless of file availability.\n",
        "\n",
        "**3. Rating Prediction with Bias Adjustment**\n",
        "*Purpose: To predict how a specific user would rate a specific movie using insights from similar users.*\n",
        "\n",
        "* Identifies users who have rated the target movie.\n",
        "* Measures similarity between the target user and those users using cosine similarity.\n",
        "* Selects the top *k* most similar users (neighbors).\n",
        "* Calculates how much each neighbor’s rating deviates from their average and weighs it by their similarity score.\n",
        "* Adjusts the target user’s mean rating by the weighted deviation to produce a prediction.\n",
        "* Applies fallback rules using movie mean or global mean if not enough neighbors are found or similarity is too low.\n",
        "* Prediction is capped between 0.5 and 5.0 to stay within valid rating bounds.\n",
        "\n",
        "**4. Random Test Pair Selection**\n",
        "*Purpose: To automatically select a valid (user, movie) pair for prediction testing.*\n",
        "\n",
        "* Randomly picks a user who has not rated a given movie.\n",
        "* Ensures that at least *k* other users have rated the movie to allow meaningful prediction.\n",
        "* Returns a user-movie pair for evaluation of the recommender system.\n",
        "\n",
        "**5. Prediction Test and Fallback Demonstration**\n",
        "*Purpose: To test and demonstrate the prediction capability and the fallback mechanism.*\n",
        "\n",
        "* Predicts a rating for the selected user-movie pair using the cosine similarity method.\n",
        "* Also tests a fallback scenario where a user has not rated the movie and may lack sufficient neighbor data.\n",
        "* This helps verify that the system can return predictions even when data is sparse.\n",
        "\n",
        "**Conclusion**\n",
        "Each step in this system is designed to make the recommender engine both accurate and resilient. The approach prioritizes reusability and speed (by checking local files first), enhances prediction quality through bias correction, and ensures coverage with intelligent fallback strategies. The result is a scalable and dependable collaborative filtering system for personalized movie recommendations.\n"
      ],
      "metadata": {
        "id": "8Faoy4mQGUwp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Required Libraries ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Step 1: Load full dataset (already sampled before upload)\n",
        "ratings = pd.read_csv(\"https://raw.githubusercontent.com/hawa1983/DATA-612/refs/heads/main/ratings_sampled.csv\")\n",
        "movies = pd.read_csv(\"https://raw.githubusercontent.com/hawa1983/DATA-612/refs/heads/main/movies_subset.csv\")\n",
        "print(\"Data loaded successfully.\")\n",
        "\n",
        "# Step 2: Use all users (no sampling)\n",
        "ratings_full = ratings.copy()\n",
        "print(f\"Using {ratings_full['userId'].nunique()} users and {ratings_full['movieId'].nunique()} movies.\")\n",
        "\n",
        "# Step 3: Create user-movie matrix\n",
        "user_movie_matrix = ratings_full.pivot(index='userId', columns='movieId', values='rating')\n",
        "user_means = user_movie_matrix.mean(axis=1)\n",
        "item_means = user_movie_matrix.mean(axis=0)\n",
        "global_mean = ratings_full['rating'].mean()\n",
        "user_ids = user_movie_matrix.index.tolist()\n",
        "\n",
        "# Step 4: Compute or load cosine similarity matrix\n",
        "try:\n",
        "    import gdown\n",
        "except ImportError:\n",
        "    import subprocess\n",
        "    subprocess.check_call([\"pip\", \"install\", \"gdown\"])\n",
        "    import gdown\n",
        "\n",
        "cosine_sim_file_local = \"cosine_user_similarity_sampled.csv\"\n",
        "cosine_file_drive_id = \"1YMOWK5Acsf9hxDfPHng4k9T0AcO0aQtn\"\n",
        "gdown_url = f\"https://drive.google.com/uc?id={cosine_file_drive_id}\"\n",
        "\n",
        "if not os.path.exists(cosine_sim_file_local):\n",
        "    print(\"Cosine similarity file not found locally. Attempting download...\")\n",
        "    try:\n",
        "        gdown.download(gdown_url, cosine_sim_file_local, quiet=False)\n",
        "    except Exception as e:\n",
        "        print(\"Download failed. Computing cosine similarity matrix...\")\n",
        "        user_movie_centered = user_movie_matrix.sub(user_means, axis=0).fillna(0)\n",
        "        cosine_sim_matrix = cosine_similarity(user_movie_centered.values)\n",
        "        cosine_sim_df = pd.DataFrame(cosine_sim_matrix, index=user_ids, columns=user_ids)\n",
        "        cosine_sim_df.to_csv(cosine_sim_file_local)\n",
        "        print(\"Cosine similarity matrix computed and saved locally.\")\n",
        "else:\n",
        "    print(\"File already exists locally.\")\n",
        "    cosine_sim_df = pd.read_csv(cosine_sim_file_local, index_col=0)\n",
        "    cosine_sim_df.columns = cosine_sim_df.columns.astype(int)\n",
        "    cosine_sim_df.index = cosine_sim_df.index.astype(int)\n",
        "\n",
        "# Load the full similarity matrix\n",
        "cosine_sim_df = pd.read_csv(cosine_sim_file_local, index_col=0)\n",
        "cosine_sim_df.columns = cosine_sim_df.columns.astype(int)\n",
        "cosine_sim_df.index = cosine_sim_df.index.astype(int)\n",
        "\n",
        "# Ensure matrix is restricted to the actual users in the data (in case of mismatches)\n",
        "cosine_sim_df = cosine_sim_df.loc[user_ids, user_ids]\n",
        "\n",
        "# Step 5: Define prediction function with bias fallback\n",
        "def predict_user_user_cosine_with_bias(user_id, movie_id, k=10):\n",
        "    if user_id not in user_movie_matrix.index or movie_id not in user_movie_matrix.columns:\n",
        "        return global_mean\n",
        "\n",
        "    user_mean = user_means[user_id]\n",
        "    sims = cosine_sim_df[user_id]\n",
        "\n",
        "    neighbors = user_movie_matrix[movie_id].dropna()\n",
        "    neighbors = neighbors[neighbors.index != user_id]\n",
        "    if neighbors.empty:\n",
        "        return user_mean + item_means.get(movie_id, global_mean) - global_mean\n",
        "\n",
        "    neighbor_sims = sims[neighbors.index]\n",
        "    neighbor_means = user_means[neighbors.index]\n",
        "    neighbor_ratings = neighbors\n",
        "\n",
        "    top_neighbors = neighbor_sims.sort_values(ascending=False).head(k)\n",
        "    top_ratings = neighbor_ratings[top_neighbors.index]\n",
        "    top_means = neighbor_means[top_neighbors.index]\n",
        "\n",
        "    deviations = top_ratings - top_means\n",
        "    weighted_sum = np.dot(top_neighbors, deviations)\n",
        "    sim_sum = np.abs(top_neighbors).sum()\n",
        "\n",
        "    if sim_sum > 0:\n",
        "        prediction = user_mean + (weighted_sum / sim_sum)\n",
        "    else:\n",
        "        prediction = user_mean + item_means.get(movie_id, global_mean) - global_mean\n",
        "\n",
        "    return max(0.5, min(prediction, 5.0))\n",
        "\n",
        "# Step 6: Find testable (user, movie) pair\n",
        "def find_random_user_movie_pair(k=10):\n",
        "    users = user_movie_matrix.index.tolist()\n",
        "    random.shuffle(users)\n",
        "\n",
        "    for user_id in users:\n",
        "        rated = user_movie_matrix.loc[user_id].dropna().index\n",
        "        unrated = user_movie_matrix.columns.difference(rated)\n",
        "        unrated = unrated.tolist()\n",
        "        random.shuffle(unrated)\n",
        "        for movie_id in unrated:\n",
        "            if user_movie_matrix[movie_id].count() > k:\n",
        "                return user_id, movie_id\n",
        "    return None, None\n",
        "\n",
        "\n",
        "# Step 7: Run prediction test\n",
        "user_id, movie_id = find_random_user_movie_pair(k=10)\n",
        "\n",
        "if user_id and movie_id:\n",
        "    pred = predict_user_user_cosine_with_bias(user_id, movie_id, k=10)\n",
        "    movie_title = movies[movies['movieId'] == movie_id]['title'].values[0]\n",
        "    print(f\"\\nPredicted rating for user {user_id} on movie '{movie_title}' (movieId {movie_id}): {pred:.2f}\")\n",
        "else:\n",
        "    print(\"No suitable user-movie pair found.\")\n",
        "\n",
        "# Step 8: Fallback test\n",
        "def test_fallback_same_movie(movie_id, k=10):\n",
        "    eligible_users = user_movie_matrix.index.difference(user_movie_matrix[movie_id].dropna().index)\n",
        "    if eligible_users.empty:\n",
        "        print(\"No eligible users for fallback.\")\n",
        "        return\n",
        "\n",
        "    random_user = random.choice(eligible_users.tolist())\n",
        "    pred = predict_user_user_cosine_with_bias(random_user, movie_id, k=k)\n",
        "    movie_title = movies[movies['movieId'] == movie_id]['title'].values[0]\n",
        "    print(f\"[Fallback] Predicted rating for random user {random_user} on movie '{movie_title}' (movieId {movie_id}): {pred:.2f}\")\n",
        "\n",
        "if movie_id:\n",
        "    test_fallback_same_movie(movie_id, k=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wS6Q_NNLBSXN",
        "outputId": "5008f87e-1885-41c9-e7b6-ed7ec59dc042"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded successfully.\n",
            "Using 10000 users and 4933 movies.\n",
            "Downloading cosine similarity matrix using gdown...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1YMOWK5Acsf9hxDfPHng4k9T0AcO0aQtn\n",
            "From (redirected): https://drive.google.com/uc?id=1YMOWK5Acsf9hxDfPHng4k9T0AcO0aQtn&confirm=t&uuid=20e4f4d7-f6c4-4fda-bfdd-6496755249a0\n",
            "To: /content/cosine_user_similarity_sampled.csv\n",
            "100%|██████████| 401M/401M [00:03<00:00, 121MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predicted rating for user 141770 on movie 'Outbreak (1995)' (movieId 292): 3.51\n",
            "[Fallback] Predicted rating for random user 197720 on movie 'Outbreak (1995)' (movieId 292): 3.05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Item-Item Collaborative Filtering Using Jaccard Similarity with Bias-Based Fallback\n",
        "\n",
        "This methodology implements a recommender system based on **item-item collaborative filtering**. It leverages **Jaccard similarity** between items and incorporates a **bias-adjusted fallback mechanism** to produce robust rating predictions in sparse or cold-start scenarios. The approach focuses on whether users have interacted with items rather than how they rated them, making it suitable when explicit feedback is limited.\n",
        "\n",
        "### 1. **Data Preparation and Sampling**\n",
        "\n",
        "To reduce memory and computational overhead, a random sample of 10,000 users is extracted from the original ratings dataset. The system then constructs a **user-movie rating matrix**, where rows represent users, columns represent movies, and values represent ratings.\n",
        "\n",
        "From this matrix, the following statistics are calculated:\n",
        "\n",
        "* **User means** – average rating per user\n",
        "* **Item means** – average rating per item\n",
        "* **Global mean** – overall average rating in the dataset\n",
        "\n",
        "These statistics serve as fallback predictors when sufficient similarity-based signals are not available.\n",
        "\n",
        "### 2. **Binary Matrix and Jaccard Similarity**\n",
        "\n",
        "A binary matrix is generated where:\n",
        "\n",
        "* A value of 1 indicates that a user rated a movie.\n",
        "* A value of 0 indicates no rating.\n",
        "\n",
        "This binary matrix is transposed to form a **movie-user matrix**, which is used to compute **Jaccard similarity** between all pairs of movies:\n",
        "\n",
        "$$\n",
        "\\text{Jaccard}(A, B) = \\frac{|A \\cap B|}{|A \\cup B|}\n",
        "$$\n",
        "\n",
        "Where:\n",
        "\n",
        "* $A$ and $B$ are sets of users who rated movies A and B, respectively.\n",
        "* The intersection represents the number of users who rated both.\n",
        "* The union represents users who rated either.\n",
        "\n",
        "To improve efficiency:\n",
        "\n",
        "* The similarity matrix is cached to a local file.\n",
        "* If the file exists or is downloadable from Google Drive, it's reused to avoid recomputation.\n",
        "\n",
        "### 3. **Item-Item Rating Prediction with Bias Adjustment**\n",
        "\n",
        "To predict a user’s rating for a movie using **item-item collaborative filtering**, the algorithm follows these steps:\n",
        "\n",
        "1. Retrieve all movies the user has rated.\n",
        "2. Compute similarity scores between the target movie and these rated movies.\n",
        "3. Select the top-k most similar movies.\n",
        "4. Take a **similarity-weighted average** of the user's ratings for those movies:\n",
        "\n",
        "$$\n",
        "\\hat{r}_{u,i} = \\frac{\\sum_{j \\in N(i)} \\text{sim}(i,j) \\cdot r_{u,j}}{\\sum_{j \\in N(i)} \\text{sim}(i,j)}\n",
        "$$\n",
        "\n",
        "If the denominator (sum of similarities) is zero, indicating no informative neighbors, the system falls back to a **bias-adjusted estimate**:\n",
        "\n",
        "$$\n",
        "\\hat{r}_{u,i} = \\mu_u + \\mu_i - \\mu_{\\text{global}}\n",
        "$$\n",
        "\n",
        "This combines the user’s average rating ($\\mu_u$) and the item’s average rating ($\\mu_i$), offset by the global average to reduce bias accumulation.\n",
        "\n",
        "All predictions are **clamped** to the valid rating range $0.5, 5.0$.\n",
        "\n",
        "### 4. **Cold-Start and Fallback Simulation**\n",
        "\n",
        "A fallback test is included to simulate **cold-start scenarios**, where a user has not rated the target movie. In such cases:\n",
        "\n",
        "* A random user who hasn’t rated the movie is selected.\n",
        "* The prediction function is run with fallback logic engaged.\n",
        "* This ensures the system remains functional even in sparse user-item interaction environments.\n",
        "\n",
        "### 5. **Conclusion**\n",
        "\n",
        "This hybrid item-item collaborative filtering system blends **Jaccard-based similarity** with **statistical bias correction**, ensuring:\n",
        "\n",
        "* Interpretability from co-engagement patterns.\n",
        "* Resilience to sparse data.\n",
        "* Compatibility with binary interaction datasets.\n",
        "\n",
        "It is well-suited for systems where users’ presence or absence (rather than rating intensity) carries the signal of interest — such as click, view, or purchase histories.\n"
      ],
      "metadata": {
        "id": "vAmNpSW9-Jra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Required Libraries ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "from sklearn.metrics import jaccard_score\n",
        "\n",
        "\n",
        "# Step 1: Load data\n",
        "ratings = pd.read_csv(\"https://raw.githubusercontent.com/hawa1983/DATA-612/refs/heads/main/ratings_subset.csv\")\n",
        "movies = pd.read_csv(\"https://raw.githubusercontent.com/hawa1983/DATA-612/refs/heads/main/movies_subset.csv\")\n",
        "print(\"Data loaded successfully.\")\n",
        "\n",
        "# Step 2: Sample 10,000 users\n",
        "sampled_user_ids = ratings['userId'].drop_duplicates().sample(n=10000, random_state=41)\n",
        "ratings_small = ratings[ratings['userId'].isin(sampled_user_ids)]\n",
        "print(f\"Using {ratings_small['userId'].nunique()} users and {ratings_small['movieId'].nunique()} movies.\")\n",
        "\n",
        "# Step 3: Create user-movie matrix\n",
        "user_movie_matrix = ratings_small.pivot(index='userId', columns='movieId', values='rating')\n",
        "user_means = user_movie_matrix.mean(axis=1)\n",
        "item_means = user_movie_matrix.mean(axis=0)\n",
        "global_mean = ratings_small['rating'].mean()\n",
        "\n",
        "# Step 4: Convert to binary matrix (rated=1, unrated=0), then transpose\n",
        "movie_user_binary = user_movie_matrix.notna().astype(int).T\n",
        "movie_ids = movie_user_binary.index.tolist()\n",
        "\n",
        "# Step 5: Load or compute Jaccard similarity matrix\n",
        "# sim_file = \"jaccard_similarity.csv\"\n",
        "\n",
        "# Step 1: Try loading Jaccard similarity matrix from Google Drive\n",
        "sim_file_drive_id = \"1z-VAYMQF9ZQSuJgkflDg3vJH9m60jwr8\"\n",
        "sim_file_drive_url = f\"https://drive.google.com/uc?export=download&id={sim_file_drive_id}\"\n",
        "sim_file_local = \"jaccard_similarity.csv\"\n",
        "\n",
        "try:\n",
        "    print(\"Trying to load Jaccard similarity matrix from Google Drive...\")\n",
        "    jaccard_sim_df = pd.read_csv(sim_file_drive_url, index_col=0)\n",
        "    jaccard_sim_df.columns = jaccard_sim_df.columns.astype(str).astype(int)\n",
        "    jaccard_sim_df.index = jaccard_sim_df.index.astype(str).astype(int)\n",
        "    print(\"Successfully loaded Jaccard similarity matrix from Google Drive.\")\n",
        "except Exception as e:\n",
        "    if os.path.exists(sim_file_local):\n",
        "        print(\"Failed to load from Drive. Loading from local file...\")\n",
        "        jaccard_sim_df = pd.read_csv(sim_file_local, index_col=0)\n",
        "        jaccard_sim_df.columns = jaccard_sim_df.columns.astype(str).astype(int)\n",
        "        jaccard_sim_df.index = jaccard_sim_df.index.astype(str).astype(int)\n",
        "    else:\n",
        "        print(\"Computing Jaccard similarity matrix...\")\n",
        "        binary_array = movie_user_binary.values.astype(bool)\n",
        "        intersection = np.dot(binary_array, binary_array.T)\n",
        "        row_sums = binary_array.sum(axis=1, keepdims=True)\n",
        "        union = row_sums + row_sums.T - intersection\n",
        "        jaccard_sim_matrix = intersection / np.maximum(union, 1)\n",
        "        jaccard_sim_df = pd.DataFrame(jaccard_sim_matrix, index=movie_ids, columns=movie_ids)\n",
        "        jaccard_sim_df.to_csv(sim_file_local)\n",
        "        print(\"Jaccard similarity matrix computed and saved locally.\")\n",
        "\n",
        "\n",
        "# if os.path.exists(sim_file):\n",
        "#     print(\"Loading Jaccard similarity matrix from file...\")\n",
        "#     jaccard_sim_df = pd.read_csv(sim_file, index_col=0)\n",
        "#     jaccard_sim_df.columns = jaccard_sim_df.columns.astype(str).astype(int)\n",
        "#     jaccard_sim_df.index = jaccard_sim_df.index.astype(str).astype(int)\n",
        "# else:\n",
        "#     print(\"Computing Jaccard similarity matrix...\")\n",
        "#     binary_array = movie_user_binary.values.astype(bool)\n",
        "#     intersection = np.dot(binary_array, binary_array.T)\n",
        "#     row_sums = binary_array.sum(axis=1, keepdims=True)\n",
        "#     union = row_sums + row_sums.T - intersection\n",
        "#     jaccard_sim_matrix = intersection / np.maximum(union, 1)\n",
        "#     jaccard_sim_df = pd.DataFrame(jaccard_sim_matrix, index=movie_ids, columns=movie_ids)\n",
        "#     jaccard_sim_df.to_csv(sim_file)\n",
        "#     print(\"Jaccard similarity matrix computed and saved to file.\")\n",
        "\n",
        "# Step 6: Define prediction function\n",
        "def predict_item_item_jaccard_with_bias(user_id, movie_id, k=10):\n",
        "    if user_id not in user_movie_matrix.index or movie_id not in user_movie_matrix.columns:\n",
        "        return global_mean\n",
        "\n",
        "    user_ratings = user_movie_matrix.loc[user_id].dropna()\n",
        "    if user_ratings.empty or movie_id not in jaccard_sim_df.index:\n",
        "        return global_mean\n",
        "\n",
        "    sims = jaccard_sim_df.loc[movie_id, user_ratings.index]\n",
        "    top_items = sims.sort_values(ascending=False).head(k)\n",
        "    top_ratings = user_ratings[top_items.index]\n",
        "\n",
        "    if top_items.sum() > 0:\n",
        "        prediction = np.dot(top_items, top_ratings) / top_items.sum()\n",
        "    else:\n",
        "        prediction = user_means.get(user_id, global_mean) + item_means.get(movie_id, 0) - global_mean\n",
        "\n",
        "    return max(0.5, min(prediction, 5.0))\n",
        "\n",
        "# Step 7: Find a predictable pair\n",
        "def find_predictable_pair(k=10):\n",
        "    for user_id in user_movie_matrix.index:\n",
        "        rated = user_movie_matrix.loc[user_id].dropna().index\n",
        "        unrated = user_movie_matrix.columns.difference(rated)\n",
        "        for movie_id in unrated:\n",
        "            if user_movie_matrix[movie_id].count() > k:\n",
        "                return user_id, movie_id\n",
        "    return None, None\n",
        "\n",
        "# Step 8: Test prediction\n",
        "user_id, movie_id = find_predictable_pair(k=10)\n",
        "if user_id and movie_id:\n",
        "    pred = predict_item_item_jaccard_with_bias(user_id, movie_id, k=10)\n",
        "    movie_title = movies[movies['movieId'] == movie_id]['title'].values[0]\n",
        "    print(f\"\\nPredicted rating for user {user_id} on movie '{movie_title}' (movieId {movie_id}): {pred:.2f}\")\n",
        "else:\n",
        "    print(\"No suitable user-movie pair found.\")\n",
        "\n",
        "# Step 9: Fallback test\n",
        "def test_bias_fallback_same_movie(movie_id, k=10):\n",
        "    eligible_users = user_movie_matrix.index.difference(user_movie_matrix[movie_id].dropna().index)\n",
        "    if eligible_users.empty:\n",
        "        print(\"No eligible users for fallback.\")\n",
        "        return\n",
        "    random_user = random.choice(eligible_users.tolist())\n",
        "    pred = predict_item_item_jaccard_with_bias(random_user, movie_id, k=k)\n",
        "    movie_title = movies[movies['movieId'] == movie_id]['title'].values[0]\n",
        "    print(f\"[Fallback] Predicted rating for random user {random_user} on movie '{movie_title}' (movieId {movie_id}): {pred:.2f}\")\n",
        "\n",
        "if movie_id:\n",
        "    test_bias_fallback_same_movie(movie_id, k=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBnUyThIvBRG",
        "outputId": "fd0b55d0-637c-470b-c3f6-e6f577a120cb"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded successfully.\n",
            "Using 10000 users and 5036 movies.\n",
            "Trying to load Jaccard similarity matrix from Google Drive...\n",
            "Successfully loaded Jaccard similarity matrix from Google Drive.\n",
            "\n",
            "Predicted rating for user 34 on movie 'Toy Story (1995)' (movieId 1): 4.09\n",
            "[Fallback] Predicted rating for random user 146618 on movie 'Toy Story (1995)' (movieId 1): 3.59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Item-Item Collaborative Filtering Using Cosine Similarity with Bias-Aware Fallback\n",
        "\n",
        "This recommender system employs item-item collaborative filtering powered by cosine similarity and enhanced with bias-aware fallback logic. It is designed to deliver personalized movie rating predictions while ensuring robustness in cases of sparse data or cold-start users.\n",
        "\n",
        "**1. Data Preparation and Sampling**\n",
        "A random sample of 10,000 users is selected from the ratings dataset to reduce computational load. A user-movie matrix is then constructed with user IDs as rows, movie IDs as columns, and rating values as the matrix entries.\n",
        "From this matrix, the following statistics are computed:\n",
        "\n",
        "* User mean: the average rating each user gives\n",
        "* Item mean: the average rating each movie receives\n",
        "* Global mean: the overall average rating across all users and movies\n",
        "\n",
        "These serve as the baseline for fallback predictions.\n",
        "\n",
        "**2. Cosine Similarity Matrix Construction**\n",
        "The user-movie matrix is transposed to obtain a movie-user matrix. Missing values are filled with zeros so that cosine similarity can be calculated between every pair of movies. Cosine similarity measures how similar two movies are based on users who rated them both, using the formula:\n",
        "\n",
        "cosine(A, B) = (A ⋅ B) / (||A|| × ||B||)\n",
        "\n",
        "Where A and B are rating vectors for two movies.\n",
        "To avoid recomputation, the similarity matrix is saved locally or loaded from a Google Drive file when available.\n",
        "\n",
        "**3. Predicting Ratings Using Top-k Similar Movies**\n",
        "To estimate how a user would rate a movie they haven’t seen, the system:\n",
        "\n",
        "* Identifies the set of movies the user has already rated\n",
        "* Retrieves cosine similarities between the target movie and those rated movies\n",
        "* Selects the top-k most similar movies\n",
        "* Calculates a weighted average of the user’s ratings for those top-k movies using their similarity scores as weights\n",
        "\n",
        "The predicted rating is computed as:\n",
        "\n",
        "r̂(u,i) = ∑ sim(i,j) × r(u,j) / ∑ sim(i,j)\n",
        "\n",
        "If the similarity weights sum to zero, the system triggers the fallback mechanism.\n",
        "\n",
        "**4. Bias-Based Fallback Strategy**\n",
        "When there are no similar movies rated by the user, or if similarity weights are zero, a bias-aware fallback formula is used:\n",
        "\n",
        "r̂(u,i) = μ\\_u + μ\\_i − μ\\_global\n",
        "\n",
        "Where:\n",
        "\n",
        "* μ\\_u is the user’s average rating\n",
        "* μ\\_i is the movie’s average rating\n",
        "* μ\\_global is the global average rating\n",
        "\n",
        "This ensures that even without similarity-based support, the model can make meaningful predictions. All predictions are clamped to the valid range \\[0.5, 5.0].\n",
        "\n",
        "**5. Cold-Start Testing and Prediction Validation**\n",
        "The system includes functionality to identify suitable user-movie pairs for prediction testing, as well as simulate cold-start conditions by selecting users who haven’t rated a specific movie. This allows for evaluation of the fallback mechanism under realistic sparse data scenarios.\n",
        "\n",
        "**Conclusion**\n",
        "This item-item collaborative filtering approach with cosine similarity provides an interpretable and resilient recommendation system. By incorporating user, item, and global bias in its fallback logic, the model remains functional and reliable even in the absence of strong similarity signals.\n"
      ],
      "metadata": {
        "id": "KI7DFfRk2SHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Required Libraries ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Step 1: Load data\n",
        "ratings = pd.read_csv(\"https://raw.githubusercontent.com/hawa1983/DATA-612/refs/heads/main/ratings_subset.csv\")\n",
        "movies = pd.read_csv(\"https://raw.githubusercontent.com/hawa1983/DATA-612/refs/heads/main/movies_subset.csv\")\n",
        "print(\"Data loaded successfully.\")\n",
        "\n",
        "# Step 2: Sample 10,000 users\n",
        "sampled_user_ids = ratings['userId'].drop_duplicates().sample(n=10000, random_state=41)\n",
        "ratings_small = ratings[ratings['userId'].isin(sampled_user_ids)]\n",
        "print(f\"Using {ratings_small['userId'].nunique()} users and {ratings_small['movieId'].nunique()} movies.\")\n",
        "\n",
        "# Step 3: Create user-movie matrix\n",
        "user_movie_matrix = ratings_small.pivot(index='userId', columns='movieId', values='rating')\n",
        "user_means = user_movie_matrix.mean(axis=1)\n",
        "item_means = user_movie_matrix.mean(axis=0)\n",
        "global_mean = ratings_small['rating'].mean()\n",
        "\n",
        "# Step 4: Transpose and fill NA with 0 for item-item similarity\n",
        "movie_user_matrix = user_movie_matrix.T.fillna(0)\n",
        "movie_ids = movie_user_matrix.index.tolist()\n",
        "\n",
        "# Step 5: Load or compute cosine similarity matrix\n",
        "# Google Drive File ID for cosine similarity matrix\n",
        "cosine_file_drive_id = \"1z-VAYMQF9ZQSuJgkflDg3vJH9m60jwr8\"\n",
        "cosine_file_drive_url = f\"https://drive.google.com/uc?export=download&id={cosine_file_drive_id}\"\n",
        "cosine_sim_file_local = \"cosine_similarity.csv\"\n",
        "\n",
        "try:\n",
        "    print(\"Trying to load cosine similarity matrix from Google Drive...\")\n",
        "    cosine_sim_df = pd.read_csv(cosine_file_drive_url, index_col=0)\n",
        "    cosine_sim_df.columns = cosine_sim_df.columns.astype(int)\n",
        "    cosine_sim_df.index = cosine_sim_df.index.astype(int)\n",
        "    print(\"Successfully loaded cosine similarity matrix from Google Drive.\")\n",
        "except Exception as e:\n",
        "    if os.path.exists(cosine_sim_file_local):\n",
        "        print(\"Failed to load from Drive. Loading from local file...\")\n",
        "        cosine_sim_df = pd.read_csv(cosine_sim_file_local, index_col=0)\n",
        "        cosine_sim_df.columns = cosine_sim_df.columns.astype(int)\n",
        "        cosine_sim_df.index = cosine_sim_df.index.astype(int)\n",
        "    else:\n",
        "        print(\"Computing cosine similarity matrix...\")\n",
        "        cosine_sim_matrix = cosine_similarity(movie_user_matrix.values)\n",
        "        cosine_sim_df = pd.DataFrame(cosine_sim_matrix, index=movie_ids, columns=movie_ids)\n",
        "        cosine_sim_df.to_csv(cosine_sim_file_local)\n",
        "        print(\"Cosine similarity matrix computed and saved locally.\")\n",
        "\n",
        "# sim_file = \"cosine_item_similarity.csv\"\n",
        "# if os.path.exists(sim_file):\n",
        "#     print(\"Loading cosine similarity matrix from file...\")\n",
        "#     cosine_sim_df = pd.read_csv(sim_file, index_col=0)\n",
        "#     cosine_sim_df.columns = cosine_sim_df.columns.astype(int)\n",
        "#     cosine_sim_df.index = cosine_sim_df.index.astype(int)\n",
        "# else:\n",
        "#     print(\"Computing cosine similarity matrix...\")\n",
        "#     cosine_sim_matrix = cosine_similarity(movie_user_matrix.values)\n",
        "#     cosine_sim_df = pd.DataFrame(cosine_sim_matrix, index=movie_ids, columns=movie_ids)\n",
        "#     cosine_sim_df.to_csv(sim_file)\n",
        "#     print(\"Cosine similarity matrix computed and saved to file.\")\n",
        "\n",
        "# Step 6: Define prediction function\n",
        "def predict_item_item_cosine_with_bias(user_id, movie_id, k=10):\n",
        "    if user_id not in user_movie_matrix.index or movie_id not in user_movie_matrix.columns:\n",
        "        return global_mean\n",
        "\n",
        "    user_ratings = user_movie_matrix.loc[user_id].dropna()\n",
        "    if user_ratings.empty or movie_id not in cosine_sim_df.index:\n",
        "        return global_mean\n",
        "\n",
        "    sims = cosine_sim_df.loc[movie_id, user_ratings.index]\n",
        "    top_items = sims.sort_values(ascending=False).head(k)\n",
        "    top_ratings = user_ratings[top_items.index]\n",
        "\n",
        "    if top_items.sum() > 0:\n",
        "        prediction = np.dot(top_items, top_ratings) / top_items.sum()\n",
        "    else:\n",
        "        prediction = user_means.get(user_id, global_mean) + item_means.get(movie_id, 0) - global_mean\n",
        "\n",
        "    return max(0.5, min(prediction, 5.0))\n",
        "\n",
        "# Step 7: Find a predictable pair\n",
        "def find_predictable_pair(k=10):\n",
        "    for user_id in user_movie_matrix.index:\n",
        "        rated = user_movie_matrix.loc[user_id].dropna().index\n",
        "        unrated = user_movie_matrix.columns.difference(rated)\n",
        "        for movie_id in unrated:\n",
        "            if user_movie_matrix[movie_id].count() > k:\n",
        "                return user_id, movie_id\n",
        "    return None, None\n",
        "\n",
        "# Step 8: Test prediction\n",
        "user_id, movie_id = find_predictable_pair(k=10)\n",
        "if user_id and movie_id:\n",
        "    pred = predict_item_item_cosine_with_bias(user_id, movie_id, k=10)\n",
        "    movie_title = movies[movies['movieId'] == movie_id]['title'].values[0]\n",
        "    print(f\"\\nPredicted rating for user {user_id} on movie '{movie_title}' (movieId {movie_id}): {pred:.2f}\")\n",
        "else:\n",
        "    print(\"No suitable user-movie pair found.\")\n",
        "\n",
        "# Step 9: Fallback test\n",
        "def test_bias_fallback_same_movie(movie_id, k=10):\n",
        "    eligible_users = user_movie_matrix.index.difference(user_movie_matrix[movie_id].dropna().index)\n",
        "    if eligible_users.empty:\n",
        "        print(\"No eligible users for fallback.\")\n",
        "        return\n",
        "    random_user = random.choice(eligible_users.tolist())\n",
        "    pred = predict_item_item_cosine_with_bias(random_user, movie_id, k=k)\n",
        "    movie_title = movies[movies['movieId'] == movie_id]['title'].values[0]\n",
        "    print(f\"[Fallback] Predicted rating for random user {random_user} on movie '{movie_title}' (movieId {movie_id}): {pred:.2f}\")\n",
        "\n",
        "if movie_id:\n",
        "    test_bias_fallback_same_movie(movie_id, k=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2IM660b2YDS",
        "outputId": "087c3233-60f5-4638-89be-6eea410cbf3e"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded successfully.\n",
            "Using 10000 users and 5036 movies.\n",
            "Trying to load cosine similarity matrix from Google Drive...\n",
            "Successfully loaded cosine similarity matrix from Google Drive.\n",
            "\n",
            "Predicted rating for user 34 on movie 'Toy Story (1995)' (movieId 1): 4.09\n",
            "[Fallback] Predicted rating for random user 110110 on movie 'Toy Story (1995)' (movieId 1): 4.09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Evaluation: RMSE Comparison"
      ],
      "metadata": {
        "id": "B31CO5UG5xCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data for evaluation\n",
        "train, test = train_test_split(ratings, test_size=0.2, random_state=42)\n",
        "\n",
        "# Predict ratings using both collaborative methods\n",
        "user_preds = test.apply(lambda row: predict_user_user(row['userId'], row['movieId']), axis=1)\n",
        "item_preds = test.apply(lambda row: predict_item_item(row['userId'], row['movieId']), axis=1)\n",
        "\n",
        "# Calculate RMSE\n",
        "user_rmse = np.sqrt(mean_squared_error(test['rating'].dropna(), user_preds.dropna()))\n",
        "item_rmse = np.sqrt(mean_squared_error(test['rating'].dropna(), item_preds.dropna()))\n",
        "\n",
        "# Plot RMSE comparison\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.bar(['User-User (Pearson)', 'Item-Item (Adjusted Cosine)'], [user_rmse, item_rmse], color=['blue', 'green'])\n",
        "plt.title(\"RMSE Comparison of Collaborative Filtering Models\")\n",
        "plt.ylabel(\"RMSE\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2KIVFVMX51_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Summary Output"
      ],
      "metadata": {
        "id": "2PLdfswj55KE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Summary ---\")\n",
        "print(f\"User-User RMSE (Pearson): {user_rmse:.4f}\")\n",
        "print(f\"Item-Item RMSE (Adjusted Cosine): {item_rmse:.4f}\")\n",
        "print(\"Content-Based filtering used L2-normalized cosine similarity on genre vectors.\")\n",
        "print(\"User-user filtering used Pearson correlation and centered ratings.\")\n",
        "print(\"Item-item filtering used adjusted cosine similarity with user-centered item vectors.\")\n"
      ],
      "metadata": {
        "id": "SCyM-ObK590E"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}