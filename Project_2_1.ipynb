{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hawa1983/DATA-612/blob/main/Project_2_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Import Required Libraries"
      ],
      "metadata": {
        "id": "_A_qwFq-455m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This section imports all necessary libraries for data processing, similarity computation, evaluation, and visualization.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity, pairwise_distances\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import normalize\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "H3xCaUKr4y-Q"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Load and Preprocess Data\n",
        "\n",
        "- Downloads smaller, pre-filtered versions of the ratings and movies datasets from GitHub.\n",
        "- These files contain fewer rows and are easier to work with in Colab (won’t crash memory).\n",
        "- pd.read_csv() loads them into DataFrames named ratings and movies."
      ],
      "metadata": {
        "id": "Oo2YhHtz5CFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load subset datasets\n",
        "!wget -q https://raw.githubusercontent.com/hawa1983/DATA-612/refs/heads/main/movies_subset.csv\n",
        "!wget -q https://raw.githubusercontent.com/hawa1983/DATA-612/refs/heads/main/ratings_subset.csv\n",
        "\n",
        "ratings = pd.read_csv(\"ratings_subset.csv\")\n",
        "movies = pd.read_csv(\"movies_subset.csv\")\n",
        "\n",
        "# Step 2: Convert genres to multi-hot encoded format\n",
        "# This block prepares genre data for content-based filtering.\n",
        "# genres_list: Converts the genre string (e.g., 'Action|Adventure') into a Python list.\n",
        "# all_genres: Builds a sorted list of all unique genres in the dataset.\n",
        "# The loop creates a new column for each genre (multi-hot encoding):\n",
        "# If a movie has that genre, it gets a 1, else 0.\n",
        "\n",
        "movies['genres'] = movies['genres'].fillna('')\n",
        "movies['genres_list'] = movies['genres'].apply(lambda x: x.split('|'))\n",
        "\n",
        "all_genres = sorted(set(genre for sublist in movies['genres_list'] for genre in sublist))\n",
        "for genre in all_genres:\n",
        "    movies[genre] = movies['genres_list'].apply(lambda x: 1 if genre in x else 0)\n",
        "\n",
        "# Step 3: Merge movie features with ratings\n",
        "# Merges the processed movies DataFrame (now with genre vectors) with ratings.\n",
        "# This results in movie_data, a dataset where each row contains:\n",
        "    ## The user ID\n",
        "    ## The movie's genre indicators (1s and 0s)\n",
        "    ## The rating the user gave that movie\n",
        "\n",
        "movie_data = pd.merge(movies.drop(columns=['genres_list']), ratings, on='movieId')\n",
        "\n",
        "print(\"Shape of merged dataset:\", movie_data.shape)\n",
        "print(movie_data.head())\n"
      ],
      "metadata": {
        "id": "KfMpudFf5HrG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff50d05d-0492-4435-d573-da2912c90eb4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of merged dataset: (100000, 26)\n",
            "   movieId             title                                       genres  \\\n",
            "0        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
            "1        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
            "2        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
            "3        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
            "4        1  Toy Story (1995)  Adventure|Animation|Children|Comedy|Fantasy   \n",
            "\n",
            "   (no genres listed)  Action  Adventure  Animation  Children  Comedy  Crime  \\\n",
            "0                   0       0          1          1         1       1      0   \n",
            "1                   0       0          1          1         1       1      0   \n",
            "2                   0       0          1          1         1       1      0   \n",
            "3                   0       0          1          1         1       1      0   \n",
            "4                   0       0          1          1         1       1      0   \n",
            "\n",
            "   ...  Musical  Mystery  Romance  Sci-Fi  Thriller  War  Western  userId  \\\n",
            "0  ...        0        0        0       0         0    0        0   84906   \n",
            "1  ...        0        0        0       0         0    0        0  179275   \n",
            "2  ...        0        0        0       0         0    0        0  177578   \n",
            "3  ...        0        0        0       0         0    0        0   56009   \n",
            "4  ...        0        0        0       0         0    0        0  141567   \n",
            "\n",
            "   rating   timestamp  \n",
            "0     5.0   846267205  \n",
            "1     3.5  1222031839  \n",
            "2     4.5  1326414799  \n",
            "3     3.0  1633110299  \n",
            "4     4.0  1696811851  \n",
            "\n",
            "[5 rows x 26 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Content-Based Filtering Using Genre Vectors and Cosine Similarity\n",
        "\n",
        "This code implements a **content-based recommender system** using movie genres. Each movie is represented as a binary (multi-hot) vector based on its associated genres (e.g., Action, Comedy, Drama). The steps include:\n",
        "\n",
        "* Normalizing the genre vectors using **L2 norm** so that each vector has unit length.\n",
        "* Calculating **cosine similarity** between movie vectors to measure how similar their genre compositions are.\n",
        "* Creating a function that, given a movie title, returns the top-N most similar movies (excluding itself) based purely on genre similarity.\n",
        "\n",
        "This technique does not rely on user ratings — instead, it recommends items that are similar in content (genre) to a given movie.\n",
        "\n",
        "This code implements a **non-personalized content-based recommender system** using only movie genres. It does **not use user ratings or preferences**. Instead, it recommends movies that are **similar in genre** to a specified movie.\n",
        "\n",
        "#### How It Works:\n",
        "\n",
        "* Each movie is represented as a binary (multi-hot encoded) vector across genres (e.g., Action, Comedy, Drama).\n",
        "* These vectors are **L2-normalized** so that all movies lie on a unit hypersphere — making **cosine similarity** an effective way to measure closeness.\n",
        "* Given a movie title, the model:\n",
        "\n",
        "  * Finds its genre vector.\n",
        "  * Computes cosine similarity to all other movies.\n",
        "  * Returns the top-N most similar movies (excluding itself).\n",
        "\n",
        "#### What It Does Not Do:\n",
        "\n",
        "* It does **not use any user data** (no `userId`, no ratings).\n",
        "* There is **no personalization**. All users will get the same recommendations for a given movie.\n",
        "\n",
        "#### Best Use Case:\n",
        "\n",
        "This type of model is ideal when:\n",
        "\n",
        "* You have **no user data** (cold start).\n",
        "* You want to recommend movies **based on content alone** (e.g., genre-based similarity).\n",
        "* You’re building a basic recommender system that can later be enhanced with collaborative filtering or hybrid techniques.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KD0olH695T2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Imports ---\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import random\n",
        "\n",
        "# --- Step 1: Use unique movies for similarity computation ---\n",
        "unique_movies = movies.copy().reset_index(drop=True)\n",
        "\n",
        "# --- Step 2: Normalize genre matrix ---\n",
        "genre_cols = all_genres  # Assumes 'all_genres' is your list of genre columns\n",
        "genre_matrix = unique_movies[genre_cols].values\n",
        "genre_matrix_normalized = normalize(genre_matrix, norm='l2')\n",
        "\n",
        "# --- Step 3: Create title-to-index mapping ---\n",
        "movie_idx = pd.Series(unique_movies.index, index=unique_movies['title']).drop_duplicates()\n",
        "\n",
        "# --- Step 4: Recommendation Function Based on Genre Similarity ---\n",
        "def get_recommendations(title, topN=20):\n",
        "    if title not in movie_idx:\n",
        "        return f\"Movie '{title}' not found in dataset.\"\n",
        "\n",
        "    idx = movie_idx[title]\n",
        "    query_vector = genre_matrix_normalized[idx].reshape(1, -1)\n",
        "    sim_scores = cosine_similarity(query_vector, genre_matrix_normalized)[0]\n",
        "\n",
        "    # Rank and filter out the movie itself\n",
        "    sim_scores = list(enumerate(sim_scores))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:topN+1]\n",
        "\n",
        "    # Output as list of (title, similarity score)\n",
        "    recommendations = [(unique_movies['title'][i], score) for i, score in sim_scores]\n",
        "    return recommendations\n",
        "\n",
        "# --- Step 5: Use Fixed Target Movie ---\n",
        "target_title = 'O.J.: Made in America (2016)'\n",
        "\n",
        "# Print explanation\n",
        "print(\"\\nContent-based Recommendations using GENRE similarity (cosine distance):\")\n",
        "\n",
        "# Run recommendation\n",
        "if target_title in movie_idx:\n",
        "    print(f\"\\nTop 20 Movies Most Similar in Genre to '{target_title}':\")\n",
        "    for title, sim in get_recommendations(target_title):\n",
        "        print(f\"{title:<45} Similarity: {sim:.4f}\")\n",
        "else:\n",
        "    print(f\"Movie '{target_title}' not found in the dataset.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24cDrAHnBkhH",
        "outputId": "b3bdece5-648f-4d00-d138-c882b13a9834"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Content-based Recommendations using GENRE similarity (cosine distance):\n",
            "\n",
            "Top 20 Movies Most Similar in Genre to 'O.J.: Made in America (2016)':\n",
            "Catwalk (1996)                                Similarity: 1.0000\n",
            "Anne Frank Remembered (1995)                  Similarity: 1.0000\n",
            "Man of the Year (1995)                        Similarity: 1.0000\n",
            "Crumb (1994)                                  Similarity: 1.0000\n",
            "Unzipped (1995)                               Similarity: 1.0000\n",
            "Hoop Dreams (1994)                            Similarity: 1.0000\n",
            "Wonderful, Horrible Life of Leni Riefenstahl, The (Macht der Bilder: Leni Riefenstahl, Die) (1993) Similarity: 1.0000\n",
            "War Room, The (1993)                          Similarity: 1.0000\n",
            "Celluloid Closet, The (1995)                  Similarity: 1.0000\n",
            "Haunted World of Edward D. Wood Jr., The (1996) Similarity: 1.0000\n",
            "Maya Lin: A Strong Clear Vision (1994)        Similarity: 1.0000\n",
            "Synthetic Pleasures (1995)                    Similarity: 1.0000\n",
            "Microcosmos (Microcosmos: Le peuple de l'herbe) (1996) Similarity: 1.0000\n",
            "Line King: The Al Hirschfeld Story, The (1996) Similarity: 1.0000\n",
            "Snowriders (1996)                             Similarity: 1.0000\n",
            "When We Were Kings (1996)                     Similarity: 1.0000\n",
            "Thin Blue Line, The (1988)                    Similarity: 1.0000\n",
            "Paris Is Burning (1990)                       Similarity: 1.0000\n",
            "Koyaanisqatsi (a.k.a. Koyaanisqatsi: Life Out of Balance) (1983) Similarity: 1.0000\n",
            "Paradise Lost: The Child Murders at Robin Hood Hills (1996) Similarity: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports tools for normalizing feature vectors and computing similarity between them.\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import random\n",
        "\n",
        "# Use only unique movie rows for similarity matrix\n",
        "# Copies the movies DataFrame and resets the index to ensure each movie is uniquely indexed.\n",
        "unique_movies = movies.copy().reset_index(drop=True)\n",
        "\n",
        "# Normalize genre matrix\n",
        "# Extracts the genre vectors for each movie (multi-hot encoded).\n",
        "# Applies L2 normalization so that all genre vectors have a length of 1 (helps with cosine similarity).\n",
        "genre_cols = all_genres\n",
        "genre_matrix = unique_movies[genre_cols].values\n",
        "genre_matrix_normalized = normalize(genre_matrix, norm='l2')\n",
        "\n",
        "# Create title-to-index map for unique movies\n",
        "# Creates a dictionary-like mapping from movie titles to their corresponding row index — used to look up vector positions.\n",
        "movie_idx = pd.Series(unique_movies.index, index=unique_movies['title']).drop_duplicates()\n",
        "\n",
        "# Define function to get recommendations\n",
        "# Defines a function that takes a movie title and returns the top N most similar movies.\n",
        "def get_recommendations(title, topN=20):\n",
        "    if title not in movie_idx:\n",
        "        return f\"Movie '{title}' not found in dataset.\"\n",
        "\n",
        "    idx = movie_idx[title]\n",
        "    query_vector = genre_matrix_normalized[idx].reshape(1, -1)\n",
        "    sim_scores = cosine_similarity(query_vector, genre_matrix_normalized)[0]\n",
        "\n",
        "    # Enumerate and sort scores, excluding the movie itself\n",
        "    sim_scores = list(enumerate(sim_scores))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:topN+1]\n",
        "\n",
        "    # Format output: list of (title, similarity) tuples\n",
        "    recommendations = [(unique_movies['title'][i], score) for i, score in sim_scores]\n",
        "    return recommendations\n",
        "\n",
        "\n",
        "# Sample 20 titles\n",
        "print(\"Available sample titles:\")\n",
        "print(unique_movies['title'].sample(20, random_state=41).to_list())\n",
        "\n",
        "# Randomly select a movie title from the available titles\n",
        "random_title = random.choice(unique_movies['title'].to_list())\n",
        "\n",
        "print(f\"\\n Randomly selected movie for recommendation: '{random_title}'\")\n",
        "\n",
        "# Explanation\n",
        "print(\"\\n Content-based Recommendations are based on GENRE similarity using cosine similarity between genre vectors.\")\n",
        "\n",
        "# Get recommendations\n",
        "print(f\"\\nTop 20 Movies Most Similar in Genre to '{random_title}':\")\n",
        "for title, sim in get_recommendations(random_title):\n",
        "    print(f\"{title:<45} Similarity: {sim:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-H_FaMjJ5WPM",
        "outputId": "0fee41f0-ed2d-48a7-80eb-1b251708f890",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available sample titles:\n",
            "['Atomica (2017)', 'Adventures in Babysitting (1987)', 'Big Picture, The (1989)', 'Annabelle (2014)', 'Beau Is Afraid (2023)', 'First Blood (Rambo: First Blood) (1982)', 'The Meg (2018)', 'Little Nemo: Adventures in Slumberland (1992)', 'Amen. (2002)', 'Danger: Diabolik (Diabolik) (1968)', 'Bugsy Malone (1976)', 'The Good Dinosaur (2015)', 'Goofy Movie, A (1995)', 'Man Called Horse, A (1970)', 'Terms and Conditions May Apply (2013)', 'StageFright: Aquarius (1987)', 'Shanghai Dreams (Qing hong) (2005)', 'I, Daniel Blake (2016)', \"Amores Perros (Love's a Bitch) (2000)\", \"Cookie's Fortune (1999)\"]\n",
            "\n",
            " Randomly selected movie for recommendation: 'Brave One, The (2007)'\n",
            "\n",
            " Content-based Recommendations are based on GENRE similarity using cosine similarity between genre vectors.\n",
            "\n",
            "Top 20 Movies Most Similar in Genre to 'Brave One, The (2007)':\n",
            "Amateur (1994)                                Similarity: 1.0000\n",
            "Kiss of Death (1995)                          Similarity: 1.0000\n",
            "Fresh (1994)                                  Similarity: 1.0000\n",
            "Guilty as Sin (1993)                          Similarity: 1.0000\n",
            "Killing Zoe (1994)                            Similarity: 1.0000\n",
            "Perfect World, A (1993)                       Similarity: 1.0000\n",
            "Purple Noon (Plein soleil) (1960)             Similarity: 1.0000\n",
            "Mulholland Falls (1996)                       Similarity: 1.0000\n",
            "Cape Fear (1962)                              Similarity: 1.0000\n",
            "Blood and Wine (Blood & Wine) (1996)          Similarity: 1.0000\n",
            "Desperate Measures (1998)                     Similarity: 1.0000\n",
            "Playing God (1997)                            Similarity: 1.0000\n",
            "Jackie Brown (1997)                           Similarity: 1.0000\n",
            "Twilight (1998)                               Similarity: 1.0000\n",
            "Rope (1948)                                   Similarity: 1.0000\n",
            "Shadow of a Doubt (1943)                      Similarity: 1.0000\n",
            "Lodger: A Story of the London Fog, The (1927) Similarity: 1.0000\n",
            "Few Good Men, A (1992)                        Similarity: 1.0000\n",
            "Simple Plan, A (1998)                         Similarity: 1.0000\n",
            "Limey, The (1999)                             Similarity: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hybrid Content-Based Rating Prediction Using Genre Similarity, User Behavior, and Fallback Handling\n",
        "\n",
        "This code demonstrates a *hybrid recommendation system* that combines **content-based filtering using genre similarity** with **collaborative filtering using user-specific ratings**. The objective is to predict how much a user will like a movie they've never seen, based on the genres of that movie and their past rating behavior.\n",
        "\n",
        "The prediction process incorporates a **fallback mechanism** and **debug printouts** to gracefully handle edge cases where standard hybrid predictions aren’t possible. These cases include users with no rating history, movies not present in the similarity matrix, or when no meaningful similarity is found.\n",
        "\n",
        "#### How it Works:\n",
        "\n",
        "1. **Genre Vector Normalization**:\n",
        "\n",
        "   * The genre columns are multi-hot encoded (e.g., Action, Comedy, etc.).\n",
        "   * Each movie’s genre vector is normalized using L2 norm so that cosine similarity is well-defined and scale-invariant.\n",
        "\n",
        "2. **Genre-Based Similarity Matrix**:\n",
        "\n",
        "   * Cosine similarity is computed between all pairs of movies based on genre vectors.\n",
        "\n",
        "3. **Mapping Setup**:\n",
        "\n",
        "   * The code builds lookup maps between `movieId` and its corresponding row index in the genre matrix to allow fast access.\n",
        "\n",
        "4. **Hybrid Prediction Function**:\n",
        "\n",
        "   * For a given `user_id` and `movie_id`, the function:\n",
        "\n",
        "     * Retrieves all movies rated by the user.\n",
        "     * Finds the top-K rated movies that are most genre-similar to the target movie.\n",
        "     * Computes a **weighted average of the ratings**, where the weights are the genre similarity scores.\n",
        "     * **If no such ratings or similarities are available**, the function **falls back to the global average rating of the movie**.\n",
        "     * Each fallback trigger is logged with a `[Debug]` message.\n",
        "\n",
        "5. **Application**:\n",
        "\n",
        "   * The model is tested on a sample user and generates predicted ratings for movies that are most similar in genre to a reference movie (e.g., *Heat (1995)*).\n",
        "\n",
        "This hybrid approach offers:\n",
        "\n",
        "* Personalization from collaborative filtering.\n",
        "* Interpretability from content-based features (genres).\n",
        "* Robustness from fallback logic to handle cold-starts or sparse data situations.\n"
      ],
      "metadata": {
        "id": "p6o2lnQkoljT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Required Libraries ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.preprocessing import MultiLabelBinarizer, normalize\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# --- Step 1: Keep All Ratings (No User Filtering) ---\n",
        "ratings_filtered = ratings.copy()\n",
        "\n",
        "# Build user-movie matrix\n",
        "user_movie_matrix = ratings_filtered.pivot(index='userId', columns='movieId', values='rating')\n",
        "\n",
        "# --- Step 2: Prepare Genre Matrix ---\n",
        "# Convert genre strings to lists\n",
        "movies['genres'] = movies['genres'].apply(lambda x: x.split('|') if isinstance(x, str) else [])\n",
        "\n",
        "# Filter only movies present in ratings\n",
        "valid_movie_ids = user_movie_matrix.columns\n",
        "movies_filtered = movies[movies['movieId'].isin(valid_movie_ids)].copy()\n",
        "\n",
        "# One-hot encode genres\n",
        "mlb = MultiLabelBinarizer()\n",
        "genre_matrix = mlb.fit_transform(movies_filtered['genres'])\n",
        "genre_matrix_normalized = normalize(genre_matrix, norm='l2')\n",
        "\n",
        "# Create mappings\n",
        "unique_movies = movies_filtered.reset_index(drop=True)\n",
        "movieId_to_index = dict(zip(unique_movies['movieId'], unique_movies.index))\n",
        "index_to_movieId = dict(zip(unique_movies.index, unique_movies['movieId']))\n",
        "movie_idx = pd.Series(unique_movies.index, index=unique_movies['title']).drop_duplicates()\n",
        "\n",
        "# --- Step 3: Compute Cosine Similarity Between Genre Vectors ---\n",
        "genre_sim_matrix = cosine_similarity(genre_matrix_normalized)\n",
        "\n",
        "# --- Step 4: Hybrid Prediction Function with Fallbacks and Recommendation Message ---\n",
        "def predict_rating_genre_weighted(user_id, target_movie_id, k=10):\n",
        "    if user_id not in user_movie_matrix.index or target_movie_id not in movieId_to_index:\n",
        "        print(f\"[Debug] Invalid user_id {user_id} or movie_id {target_movie_id}. Returning NaN.\")\n",
        "        return np.nan\n",
        "\n",
        "    user_ratings = user_movie_matrix.loc[user_id].dropna()\n",
        "    if user_ratings.empty:\n",
        "        print(f\"[Fallback] User {user_id} has no ratings. Using global average for movieId {target_movie_id}.\")\n",
        "        pred = ratings_filtered[ratings_filtered['movieId'] == target_movie_id]['rating'].mean()\n",
        "        print(f\"[Recommendation] Predicted Rating: {pred:.2f} → {'Recommend' if pred >= 3.5 else 'Not Recommended'}\")\n",
        "        return pred\n",
        "\n",
        "    target_idx = movieId_to_index[target_movie_id]\n",
        "    rated_movie_indices = [movieId_to_index[mid] for mid in user_ratings.index if mid in movieId_to_index]\n",
        "\n",
        "    if not rated_movie_indices:\n",
        "        print(f\"[Fallback] Rated movies not found for user {user_id}. Using global average.\")\n",
        "        pred = ratings_filtered[ratings_filtered['movieId'] == target_movie_id]['rating'].mean()\n",
        "        print(f\"[Recommendation] Predicted Rating: {pred:.2f} → {'Recommend' if pred >= 3.5 else 'Not Recommended'}\")\n",
        "        return pred\n",
        "\n",
        "    sims = genre_sim_matrix[target_idx, rated_movie_indices]\n",
        "    sims_series = pd.Series(sims, index=[index_to_movieId[i] for i in rated_movie_indices])\n",
        "\n",
        "    top_similar = sims_series.sort_values(ascending=False).head(k)\n",
        "    top_ratings = user_ratings[top_similar.index]\n",
        "\n",
        "    # Debug logs for inspection\n",
        "    print(f\"\\n[Debug] Similarity Weights for User {user_id} on Target Movie {target_movie_id}:\")\n",
        "    print(top_similar)\n",
        "    print(\"[Debug] Corresponding Ratings:\")\n",
        "    print(top_ratings)\n",
        "\n",
        "    weighted_sum = np.dot(top_similar.values, top_ratings.values)\n",
        "    normalization = np.sum(top_similar.values)\n",
        "\n",
        "    if normalization > 0:\n",
        "        pred = weighted_sum / normalization\n",
        "        print(f\"[Prediction] Personalized prediction used for user {user_id} on movieId {target_movie_id}.\")\n",
        "        print(f\"[Recommendation] Predicted Rating: {pred:.2f} → {'Recommend' if pred >= 3.5 else 'Not Recommended'}\")\n",
        "        return pred\n",
        "    else:\n",
        "        print(f\"[Fallback] No similarity weights found. Using global average for movieId {target_movie_id}.\")\n",
        "        pred = ratings_filtered[ratings_filtered['movieId'] == target_movie_id]['rating'].mean()\n",
        "        print(f\"[Recommendation] Predicted Rating: {pred:.2f} → {'Recommend' if pred >= 3.5 else 'Not Recommended'}\")\n",
        "        return pred\n",
        "\n",
        "# --- Step 5: Run with Fixed User and Movie ---\n",
        "\n",
        "# Set static user and movie\n",
        "user_id = 174949\n",
        "target_movie = 'O.J.: Made in America (2016)'\n",
        "\n",
        "print(f\"Using user {user_id} for prediction.\")\n",
        "print(f\"Target movie exists: '{target_movie}' →\", target_movie in movie_idx)\n",
        "\n",
        "if target_movie in movie_idx:\n",
        "    idx = movie_idx[target_movie]\n",
        "    sim_scores = cosine_similarity(genre_matrix_normalized[idx].reshape(1, -1), genre_matrix_normalized)[0]\n",
        "    sim_indices = np.argsort(sim_scores)[::-1][1:11]  # Exclude the movie itself\n",
        "\n",
        "    top_similar_movie_ids = unique_movies.loc[sim_indices, 'movieId']\n",
        "    top_similar_titles = unique_movies.loc[sim_indices, 'title']\n",
        "\n",
        "    print(f\"\\nTop 10 Genre-Similar Movies to '{target_movie}':\")\n",
        "    print(top_similar_titles)\n",
        "\n",
        "    print(f\"\\nPredicted Ratings for User {user_id} Using Hybrid Genre-Based Model:\\n\")\n",
        "    for movie_id, title in zip(top_similar_movie_ids, top_similar_titles):\n",
        "        pred = predict_rating_genre_weighted(user_id=user_id, target_movie_id=movie_id, k=100)\n",
        "        print(f\"{title:<45} Predicted Rating: {pred:.2f}\")\n",
        "else:\n",
        "    print(\"Target movie not found in index.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VX0bnB3JAwCt",
        "outputId": "d24f4e40-7167-4755-9617-7ffe4dbbe49d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using user 174949 for prediction.\n",
            "Target movie exists: 'O.J.: Made in America (2016)' → True\n",
            "\n",
            "Top 10 Genre-Similar Movies to 'O.J.: Made in America (2016)':\n",
            "11172    Indiana Jones: The Search for the Lost Golden ...\n",
            "98                                          Catwalk (1996)\n",
            "104                           Anne Frank Remembered (1995)\n",
            "118                                 Man of the Year (1995)\n",
            "139                                           Crumb (1994)\n",
            "177                                        Unzipped (1995)\n",
            "213                                     Hoop Dreams (1994)\n",
            "315      Wonderful, Horrible Life of Leni Riefenstahl, ...\n",
            "480                                   War Room, The (1993)\n",
            "496                           Celluloid Closet, The (1995)\n",
            "Name: title, dtype: object\n",
            "\n",
            "Predicted Ratings for User 174949 Using Hybrid Genre-Based Model:\n",
            "\n",
            "\n",
            "[Debug] Similarity Weights for User 174949 on Target Movie 287443:\n",
            "1207    0.0\n",
            "2671    0.0\n",
            "dtype: float64\n",
            "[Debug] Corresponding Ratings:\n",
            "1207    5.0\n",
            "2671    3.0\n",
            "Name: 174949, dtype: float64\n",
            "[Fallback] No similarity weights found. Using global average for movieId 287443.\n",
            "[Recommendation] Predicted Rating: 3.50 → Recommend\n",
            "Indiana Jones: The Search for the Lost Golden Age (2021) Predicted Rating: 3.50\n",
            "\n",
            "[Debug] Similarity Weights for User 174949 on Target Movie 108:\n",
            "1207    0.0\n",
            "2671    0.0\n",
            "dtype: float64\n",
            "[Debug] Corresponding Ratings:\n",
            "1207    5.0\n",
            "2671    3.0\n",
            "Name: 174949, dtype: float64\n",
            "[Fallback] No similarity weights found. Using global average for movieId 108.\n",
            "[Recommendation] Predicted Rating: 4.00 → Recommend\n",
            "Catwalk (1996)                                Predicted Rating: 4.00\n",
            "\n",
            "[Debug] Similarity Weights for User 174949 on Target Movie 116:\n",
            "1207    0.0\n",
            "2671    0.0\n",
            "dtype: float64\n",
            "[Debug] Corresponding Ratings:\n",
            "1207    5.0\n",
            "2671    3.0\n",
            "Name: 174949, dtype: float64\n",
            "[Fallback] No similarity weights found. Using global average for movieId 116.\n",
            "[Recommendation] Predicted Rating: 4.67 → Recommend\n",
            "Anne Frank Remembered (1995)                  Predicted Rating: 4.67\n",
            "\n",
            "[Debug] Similarity Weights for User 174949 on Target Movie 137:\n",
            "1207    0.0\n",
            "2671    0.0\n",
            "dtype: float64\n",
            "[Debug] Corresponding Ratings:\n",
            "1207    5.0\n",
            "2671    3.0\n",
            "Name: 174949, dtype: float64\n",
            "[Fallback] No similarity weights found. Using global average for movieId 137.\n",
            "[Recommendation] Predicted Rating: 5.00 → Recommend\n",
            "Man of the Year (1995)                        Predicted Rating: 5.00\n",
            "\n",
            "[Debug] Similarity Weights for User 174949 on Target Movie 162:\n",
            "1207    0.0\n",
            "2671    0.0\n",
            "dtype: float64\n",
            "[Debug] Corresponding Ratings:\n",
            "1207    5.0\n",
            "2671    3.0\n",
            "Name: 174949, dtype: float64\n",
            "[Fallback] No similarity weights found. Using global average for movieId 162.\n",
            "[Recommendation] Predicted Rating: 4.03 → Recommend\n",
            "Crumb (1994)                                  Predicted Rating: 4.03\n",
            "\n",
            "[Debug] Similarity Weights for User 174949 on Target Movie 206:\n",
            "1207    0.0\n",
            "2671    0.0\n",
            "dtype: float64\n",
            "[Debug] Corresponding Ratings:\n",
            "1207    5.0\n",
            "2671    3.0\n",
            "Name: 174949, dtype: float64\n",
            "[Fallback] No similarity weights found. Using global average for movieId 206.\n",
            "[Recommendation] Predicted Rating: 3.50 → Recommend\n",
            "Unzipped (1995)                               Predicted Rating: 3.50\n",
            "\n",
            "[Debug] Similarity Weights for User 174949 on Target Movie 246:\n",
            "1207    0.0\n",
            "2671    0.0\n",
            "dtype: float64\n",
            "[Debug] Corresponding Ratings:\n",
            "1207    5.0\n",
            "2671    3.0\n",
            "Name: 174949, dtype: float64\n",
            "[Fallback] No similarity weights found. Using global average for movieId 246.\n",
            "[Recommendation] Predicted Rating: 4.12 → Recommend\n",
            "Hoop Dreams (1994)                            Predicted Rating: 4.12\n",
            "\n",
            "[Debug] Similarity Weights for User 174949 on Target Movie 363:\n",
            "1207    0.0\n",
            "2671    0.0\n",
            "dtype: float64\n",
            "[Debug] Corresponding Ratings:\n",
            "1207    5.0\n",
            "2671    3.0\n",
            "Name: 174949, dtype: float64\n",
            "[Fallback] No similarity weights found. Using global average for movieId 363.\n",
            "[Recommendation] Predicted Rating: 3.50 → Recommend\n",
            "Wonderful, Horrible Life of Leni Riefenstahl, The (Macht der Bilder: Leni Riefenstahl, Die) (1993) Predicted Rating: 3.50\n",
            "\n",
            "[Debug] Similarity Weights for User 174949 on Target Movie 556:\n",
            "1207    0.0\n",
            "2671    0.0\n",
            "dtype: float64\n",
            "[Debug] Corresponding Ratings:\n",
            "1207    5.0\n",
            "2671    3.0\n",
            "Name: 174949, dtype: float64\n",
            "[Fallback] No similarity weights found. Using global average for movieId 556.\n",
            "[Recommendation] Predicted Rating: 3.25 → Not Recommended\n",
            "War Room, The (1993)                          Predicted Rating: 3.25\n",
            "\n",
            "[Debug] Similarity Weights for User 174949 on Target Movie 581:\n",
            "1207    0.0\n",
            "2671    0.0\n",
            "dtype: float64\n",
            "[Debug] Corresponding Ratings:\n",
            "1207    5.0\n",
            "2671    3.0\n",
            "Name: 174949, dtype: float64\n",
            "[Fallback] No similarity weights found. Using global average for movieId 581.\n",
            "[Recommendation] Predicted Rating: 4.17 → Recommend\n",
            "Celluloid Closet, The (1995)                  Predicted Rating: 4.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hybrid Recommender: Genre-Weighted Collaborative Filtering**\n",
        "\n",
        "This code predicts a user's rating for a movie by combining collaborative filtering and genre-based similarity. Here's how it works:\n",
        "\n",
        "### **Step-by-Step Explanation**\n",
        "\n",
        "**1. Data Preparation**\n",
        "\n",
        "* It loads the `ratings` and `movies` datasets.\n",
        "* The user-movie ratings matrix is built using `.pivot()` (rows = users, columns = movies, values = ratings).\n",
        "* Movie genres are split and one-hot encoded using `MultiLabelBinarizer`.\n",
        "* Genre vectors are normalized to enable cosine similarity comparison.\n",
        "\n",
        "**2. Genre Similarity Calculation**\n",
        "\n",
        "* Cosine similarity is computed between normalized genre vectors of all movies.\n",
        "* This generates a matrix showing how similar each pair of movies is based on genre.\n",
        "\n",
        "**3. `hybrid_predict()` Function:**\n",
        "This is the main prediction function. Here's what it does:\n",
        "\n",
        "* **Step 1**: Skips invalid user/movie inputs.\n",
        "* **Step 2**: Loops through all other users (excluding the target user).\n",
        "* **Step 3**: For each user, checks if they rated the target movie.\n",
        "* **Step 4**: Collects that user's other rated movies and looks up genre similarity between those and the target movie.\n",
        "* **Step 5**: Uses a weighted average of the other user's ratings on similar movies, weighted by genre similarity.\n",
        "* **Step 6**: Averages all such weighted predictions from other users to generate the final prediction.\n",
        "* **Fallback**: If no useful ratings are found, it falls back to the global average rating for the movie.\n",
        "\n",
        "**4. Prediction Execution**\n",
        "\n",
        "* The code sets `user_id = 174949` and `target_movie = 'O.J.: Made in America (2016)'`.\n",
        "* It retrieves the `movieId` and runs the `hybrid_predict()` function.\n",
        "* Finally, it prints the predicted rating for that user and movie.\n",
        "\n",
        "*This approach combines user behavior (collaborative filtering) with genre-based content similarity to improve prediction accuracy, especially for sparse data or cold-start problems.*\n"
      ],
      "metadata": {
        "id": "XQMqGRzZkhcU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Vectorized NumPy Logic – Genre-Based Hybrid Prediction"
      ],
      "metadata": {
        "id": "mJupUOM_Ia4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MultiLabelBinarizer, normalize\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Step 1: Load subset datasets\n",
        "!wget -q https://raw.githubusercontent.com/hawa1983/DATA-612/refs/heads/main/movies_subset.csv\n",
        "!wget -q https://raw.githubusercontent.com/hawa1983/DATA-612/refs/heads/main/ratings_subset.csv\n",
        "\n",
        "ratings = pd.read_csv(\"ratings_subset.csv\")\n",
        "movies = pd.read_csv(\"movies_subset.csv\")\n",
        "\n",
        "# Step 1: Prepare Data\n",
        "ratings_filtered = ratings.copy()\n",
        "user_movie_matrix = ratings_filtered.pivot(index='userId', columns='movieId', values='rating')\n",
        "\n",
        "movies['genres'] = movies['genres'].apply(lambda x: x.split('|') if isinstance(x, str) else [])\n",
        "valid_movie_ids = user_movie_matrix.columns\n",
        "movies_filtered = movies[movies['movieId'].isin(valid_movie_ids)].copy()\n",
        "\n",
        "mlb = MultiLabelBinarizer()\n",
        "genre_matrix = mlb.fit_transform(movies_filtered['genres'])\n",
        "genre_matrix_normalized = normalize(genre_matrix, norm='l2')\n",
        "\n",
        "unique_movies = movies_filtered.reset_index(drop=True)\n",
        "movieId_to_index = dict(zip(unique_movies['movieId'], unique_movies.index))\n",
        "index_to_movieId = dict(zip(unique_movies.index, unique_movies['movieId']))\n",
        "movie_idx = pd.Series(unique_movies.index, index=unique_movies['title']).drop_duplicates()\n",
        "\n",
        "# Step 2: Vectorized Hybrid Prediction Function (Genre-only Weighted)\n",
        "def vectorized_hybrid_predict(user_id, target_movie_id, k=10):\n",
        "    if user_id not in user_movie_matrix.index or target_movie_id not in movieId_to_index:\n",
        "        return np.nan\n",
        "\n",
        "    target_idx = movieId_to_index[target_movie_id]\n",
        "    sim_vector = cosine_similarity(genre_matrix_normalized[target_idx].reshape(1, -1), genre_matrix_normalized)[0]\n",
        "\n",
        "    user_ratings = user_movie_matrix.loc[user_id].dropna()\n",
        "    rated_movie_ids = user_ratings.index.intersection(user_movie_matrix.columns)\n",
        "    rated_indices = [movieId_to_index[mid] for mid in rated_movie_ids if mid in movieId_to_index]\n",
        "\n",
        "    sim_scores = sim_vector[rated_indices]\n",
        "    ratings_values = user_ratings.loc[rated_movie_ids].values\n",
        "\n",
        "    if len(sim_scores) == 0 or np.sum(sim_scores) == 0:\n",
        "        return np.nan\n",
        "\n",
        "    top_k_indices = np.argsort(sim_scores)[-k:]\n",
        "    sim_top = sim_scores[top_k_indices]\n",
        "    rating_top = ratings_values[top_k_indices]\n",
        "\n",
        "    return np.dot(sim_top, rating_top) / np.sum(sim_top)\n",
        "\n",
        "# Example Usage\n",
        "# user_id = 174949\n",
        "valid_user = None\n",
        "for uid in user_movie_matrix.index:\n",
        "    rated_movies = user_movie_matrix.loc[uid].dropna().index\n",
        "    if rated_movies.intersection(movieId_to_index.keys()).any():\n",
        "        valid_user = uid\n",
        "        break  # Exit the loop immediately once a valid user is found\n",
        "\n",
        "user_id = valid_user\n",
        "\n",
        "\n",
        "target_movie = 'O.J.: Made in America (2016)'\n",
        "target_movie_id = unique_movies.loc[movie_idx[target_movie], 'movieId']\n",
        "pred = vectorized_hybrid_predict(user_id, target_movie_id, k=100)\n",
        "print(f\"Predicted rating for '{target_movie}' by user {user_id}: {pred:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpqEFAeGElOp",
        "outputId": "3cf1ab91-c533-4e94-e808-9d0ee4d9366a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted rating for 'O.J.: Made in America (2016)' by user 10: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Blended Hybrid (Genre + Collaborative Filtering) with Precomputed Hybrid Similarity"
      ],
      "metadata": {
        "id": "isnJMUbUIea3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MultiLabelBinarizer, normalize\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Step 1: Load subset datasets\n",
        "!wget -q https://raw.githubusercontent.com/hawa1983/DATA-612/refs/heads/main/movies_subset.csv\n",
        "!wget -q https://raw.githubusercontent.com/hawa1983/DATA-612/refs/heads/main/ratings_subset.csv\n",
        "\n",
        "# Step 1: Prepare Data\n",
        "ratings_filtered = ratings.copy()\n",
        "user_movie_matrix = ratings_filtered.pivot(index='userId', columns='movieId', values='rating')\n",
        "\n",
        "movies['genres'] = movies['genres'].apply(lambda x: x.split('|') if isinstance(x, str) else [])\n",
        "valid_movie_ids = user_movie_matrix.columns\n",
        "movies_filtered = movies[movies['movieId'].isin(valid_movie_ids)].copy()\n",
        "\n",
        "mlb = MultiLabelBinarizer()\n",
        "genre_matrix = mlb.fit_transform(movies_filtered['genres'])\n",
        "genre_matrix_normalized = normalize(genre_matrix, norm='l2')\n",
        "\n",
        "unique_movies = movies_filtered.reset_index(drop=True)\n",
        "movieId_to_index = dict(zip(unique_movies['movieId'], unique_movies.index))\n",
        "index_to_movieId = dict(zip(unique_movies.index, unique_movies['movieId']))\n",
        "movie_idx = pd.Series(unique_movies.index, index=unique_movies['title']).drop_duplicates()\n",
        "\n",
        "# Step 2: Compute Hybrid Similarity Matrix\n",
        "genre_sim = cosine_similarity(genre_matrix_normalized)\n",
        "user_movie_centered = user_movie_matrix.sub(user_movie_matrix.mean(axis=1), axis=0).fillna(0)\n",
        "item_sim = cosine_similarity(user_movie_centered.T.fillna(0))\n",
        "\n",
        "# Ensure both matrices are same shape\n",
        "alpha = 0.5  # genre-collab blend weight\n",
        "hybrid_sim = alpha * genre_sim + (1 - alpha) * item_sim\n",
        "\n",
        "# Step 3: Prediction Function Using Hybrid Similarity\n",
        "def blended_hybrid_predict(user_id, target_movie_id, k=10):\n",
        "    if user_id not in user_movie_matrix.index or target_movie_id not in movieId_to_index:\n",
        "        return np.nan\n",
        "\n",
        "    target_idx = movieId_to_index[target_movie_id]\n",
        "    sim_vector = hybrid_sim[target_idx]\n",
        "\n",
        "    user_ratings = user_movie_matrix.loc[user_id].dropna()\n",
        "    rated_movie_ids = user_ratings.index.intersection(user_movie_matrix.columns)\n",
        "    rated_indices = [movieId_to_index[mid] for mid in rated_movie_ids if mid in movieId_to_index]\n",
        "\n",
        "    sim_scores = sim_vector[rated_indices]\n",
        "    ratings_values = user_ratings.loc[rated_movie_ids].values\n",
        "\n",
        "    if len(sim_scores) == 0 or np.sum(sim_scores) == 0:\n",
        "        return np.nan\n",
        "\n",
        "    top_k_indices = np.argsort(sim_scores)[-k:]\n",
        "    sim_top = sim_scores[top_k_indices]\n",
        "    rating_top = ratings_values[top_k_indices]\n",
        "\n",
        "    return np.dot(sim_top, rating_top) / np.sum(sim_top)\n",
        "\n",
        "# Example Usage\n",
        "user_id = 174949\n",
        "target_movie = 'O.J.: Made in America (2016)'\n",
        "target_movie_id = unique_movies.loc[movie_idx[target_movie], 'movieId']\n",
        "pred = blended_hybrid_predict(user_id, target_movie_id, k=100)\n",
        "print(f\"Predicted rating for '{target_movie}' by user {user_id}: {pred:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "ak3yfaL-IkP_",
        "outputId": "4033a60d-ed0b-47e4-84db-3508d9b24491"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Found array with 0 feature(s) (shape=(11190, 0)) while a minimum of 1 is required by the normalize function.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-1584051649>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mmlb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiLabelBinarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mgenre_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovies_filtered\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'genres'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mgenre_matrix_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenre_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0munique_movies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmovies_filtered\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(X, norm, axis, copy, return_norm)\u001b[0m\n\u001b[1;32m   1963\u001b[0m     \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1965\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1966\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1967\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msparse_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1137\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mensure_min_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1140\u001b[0m                 \u001b[0;34m\"Found array with %d feature(s) (shape=%s) while\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 \u001b[0;34m\" a minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found array with 0 feature(s) (shape=(11190, 0)) while a minimum of 1 is required by the normalize function."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparison of Overlapping and Divergent Recommendations\n",
        "\n",
        "Both methods returned several overlapping recommendations, but also differed in meaningful ways:\n",
        "\n",
        "#### Similar Recommendations from Both Methods\n",
        "\n",
        "* **Assassins (1995)**\n",
        "* **Net, The (1995)**\n",
        "\n",
        "These consistent suggestions indicate that both the pure content-based and hybrid genre-weighted models identify core genre traits effectively.\n",
        "\n",
        "#### Recommendations Unique to Each Method\n",
        "\n",
        "**Only in Content-Based (Cosine Genre Similarity):**\n",
        "\n",
        "* *Die Hard (1988)*\n",
        "* *Batman (1989)*\n",
        "* *U.S. Marshals (1998)*\n",
        "\n",
        "**Only in Hybrid Model (Genre + Ratings Fallback):**\n",
        "\n",
        "* *Sin City: A Dame to Kill For (2014)*\n",
        "* *John Wick: Chapter Two (2017)*\n",
        "* *Transporter 2 (2005)*\n",
        "\n",
        "These differences show that the hybrid method is able to introduce newer or slightly more nuanced genre matches, even when rating data for a specific user is missing and fallback mechanisms are triggered.\n"
      ],
      "metadata": {
        "id": "Z6_Z7TyTwAhl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimized Jaccard Similarity for Content-Based Filtering\n",
        "\n",
        "This block introduces a more efficient method for computing **Jaccard similarity** between movies based on their genre information. Unlike the traditional nested-loop approach, this implementation uses the `pdist()` function from `scipy.spatial.distance` to compute all pairwise Jaccard distances in a **fully vectorized** manner. The result is a symmetric similarity matrix, which is then used to identify the most similar movies to a given title. This optimization drastically reduces computation time and is highly recommended for medium-to-large datasets.\n",
        "\n",
        "using `scipy.spatial.distance.pdist()` **does calculate all pairwise similarities**, but it does so much more efficiently than a manual loop.\n",
        "\n",
        "Here’s how it works:\n",
        "\n",
        "* `pdist(binary_matrix, metric='jaccard')` computes the **Jaccard distance** (which is `1 - Jaccard similarity`) between **all unique pairs** of rows (i.e., movies) in the binary genre matrix.\n",
        "* The output is a **condensed distance matrix** — a flat array containing the upper triangle of the full pairwise distance matrix.\n",
        "* This condensed matrix is converted back into a full square **symmetric matrix** using `squareform()`, giving us the distance between all pairs.\n",
        "* We then compute similarity as `1 - distance`.\n",
        "\n",
        "Every possible movie-to-movie similarity is calculated — but with optimized vectorized operations under the hood, which is much faster than nested Python loops.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZK-ho_H6hrOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial.distance import pdist, squareform\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Prepare genre binary matrix\n",
        "unique_movies = movies.copy().reset_index(drop=True)\n",
        "genre_cols = all_genres\n",
        "genre_matrix = unique_movies[genre_cols].astype(bool).astype(int).values  # ensure binary format\n",
        "\n",
        "# Step 2: Compute Jaccard distance (1 - similarity)\n",
        "# pdist returns a condensed distance matrix; squareform converts it to square form\n",
        "jaccard_distance = pdist(genre_matrix, metric='jaccard')  # returns 1 - Jaccard similarity\n",
        "jaccard_sim_matrix = 1 - squareform(jaccard_distance)      # convert to full similarity matrix\n",
        "\n",
        "# Step 3: Create mapping from title to matrix index\n",
        "movie_idx = pd.Series(unique_movies.index, index=unique_movies['title']).drop_duplicates()\n",
        "\n",
        "# Step 4: Define recommendation function\n",
        "def get_recommendations_jaccard(title, topN=10):\n",
        "    if title not in movie_idx:\n",
        "        return f\"Movie '{title}' not found in dataset.\"\n",
        "\n",
        "    idx = movie_idx[title]\n",
        "    sim_scores = list(enumerate(jaccard_sim_matrix[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:topN+1]  # exclude self\n",
        "    top_indices = [i[0] for i in sim_scores]\n",
        "    return unique_movies['title'].iloc[top_indices]\n",
        "\n",
        "# Step 5: Try a sample movie\n",
        "print(\"Sample titles:\", unique_movies['title'].sample(5, random_state=42).to_list())\n",
        "print(f\"\\nJaccard Recommendations for {random_title}:\")\n",
        "# print(get_recommendations_jaccard(\"Heat (1995)\"))\n",
        "print(get_recommendations_jaccard(random_title))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8l-M-JJekRl-",
        "outputId": "78ad6b33-26d9-4626-81e6-99833f9abce5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample titles: ['Murder on the Orient Express (2017)', 'Rhapsody in August (Hachi-gatsu no kyôshikyoku) (1991)', 'First Position (2011)', 'Wait Until Dark (1967)', 'Coffy (1973)']\n",
            "\n",
            "Jaccard Recommendations for Youth (2015):\n",
            "25                      Othello (1995)\n",
            "30              Dangerous Minds (1995)\n",
            "38     Cry, the Beloved Country (1995)\n",
            "41                  Restoration (1995)\n",
            "51                      Georgia (1995)\n",
            "52        Home for the Holidays (1995)\n",
            "57           Mr. Holland's Opus (1995)\n",
            "62                     Two Bits (1995)\n",
            "103           Margaret's Museum (1995)\n",
            "108    Boys of St. Vincent, The (1992)\n",
            "Name: title, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparison of Content-Based Recommendations: Cosine vs. Jaccard Similarity\n",
        "\n",
        "Both the **cosine similarity** and **Jaccard similarity** methods returned *identical top-10 movie recommendations* for the query movie **\"Heat (1995)\"**. This indicates that in the context of the MovieLens genre-based content filtering:\n",
        "\n",
        "* **Both methods effectively captured the same neighborhood of similar films**.\n",
        "* The movies recommended (e.g., *Assassins*, *Die Hard*, *The Net*, *Natural Born Killers*) suggest that the genre combinations for these titles closely match those of *Heat (1995)*.\n",
        "* While **cosine similarity** operates on normalized multi-hot vectors and measures angular proximity,\n",
        "  **Jaccard similarity** measures the overlap in genre tags directly.\n",
        "\n",
        "### Key Takeaway:\n",
        "\n",
        "Despite their different mathematical underpinnings, both methods **produced the same results** because:\n",
        "\n",
        "* The genre vectors are binary (multi-hot encoded), where normalization (in cosine) doesn’t distort information significantly.\n",
        "* The dominant factor influencing similarity is the **overlap of genre labels**, which both metrics capture well.\n",
        "\n",
        "However:\n",
        "\n",
        "* **Cosine similarity is computationally faster** and more scalable.\n",
        "* **Jaccard similarity is slower** when computed pairwise using loops, though vectorized solutions like `pdist()` improve it significantly.\n",
        "\n",
        "You can safely use either in this binary genre context, but for large-scale systems, cosine is typically preferred for efficiency.\n"
      ],
      "metadata": {
        "id": "RLrKOSN4mnK0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. User-User Collaborative Filtering with Cosine Similarity (Memory-Efficient Version)\n",
        "\n",
        "This block implements **User-User Collaborative Filtering** while addressing memory constraints in Google Colab. It includes two major optimizations:\n",
        "\n",
        "* Limits the dataset to users with `userId <= 50,000` to keep the similarity matrix size manageable.\n",
        "* Uses **cosine similarity** (instead of Pearson correlation), which is more memory-efficient and suitable for sparse rating data.\n",
        "\n",
        "The code builds a **mean-centered user-item matrix**, computes cosine similarity between users, and defines a prediction function based on the top-k most similar users who rated a given movie. This approach estimates a target user’s rating by combining how similar users rated the same item, adjusted for their own average rating.\n"
      ],
      "metadata": {
        "id": "BY76gdFX5cQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Required Libraries ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import random\n",
        "\n",
        "# Step 1: Load subset datasets\n",
        "!wget -q https://raw.githubusercontent.com/hawa1983/DATA-612/refs/heads/main/movies_subset.csv\n",
        "!wget -q https://raw.githubusercontent.com/hawa1983/DATA-612/refs/heads/main/ratings_subset.csv\n",
        "\n",
        "ratings = pd.read_csv(\"ratings_subset.csv\")\n",
        "movies = pd.read_csv(\"movies_subset.csv\")\n",
        "print(\"Data loaded successfully.\")\n",
        "\n",
        "# Step 2: Reduce to a manageable number of users\n",
        "sampled_user_ids = ratings['userId'].drop_duplicates().sample(n=10000) #, random_state=42)\n",
        "ratings_small = ratings[ratings['userId'].isin(sampled_user_ids)]\n",
        "\n",
        "print(f\"Using {ratings_small['userId'].nunique()} users and {ratings_small['movieId'].nunique()} movies.\")\n",
        "\n",
        "# Step 3: Create user-movie matrix and normalize\n",
        "user_movie_matrix = ratings_small.pivot(index='userId', columns='movieId', values='rating')\n",
        "user_means = user_movie_matrix.mean(axis=1)\n",
        "user_movie_centered = user_movie_matrix.sub(user_means, axis=0).fillna(0)\n",
        "global_mean = ratings_small['rating'].mean()  # Fallback if user mean is unavailable\n",
        "\n",
        "# Step 4: Compute cosine similarity between users\n",
        "print(\"Computing user-user cosine similarity...\")\n",
        "user_similarity = cosine_similarity(user_movie_centered)\n",
        "user_sim_df = pd.DataFrame(user_similarity, index=user_movie_matrix.index, columns=user_movie_matrix.index)\n",
        "print(\"Similarity matrix created.\")\n",
        "\n",
        "# Step 5: Define prediction function with full fallback\n",
        "def predict_user_user(user_id, movie_id, k=10):\n",
        "    if user_id not in user_sim_df.index or movie_id not in user_movie_matrix.columns:\n",
        "        print(\"User or movie not in dataset. Returning global mean.\")\n",
        "        return global_mean  # Fallback to global average\n",
        "\n",
        "    sims = user_sim_df[user_id].drop(user_id)\n",
        "    rated_users = user_movie_matrix[movie_id].dropna()\n",
        "    sims = sims[sims.index.intersection(rated_users.index)]\n",
        "\n",
        "    if sims.empty:\n",
        "        print(\"No neighbors rated the movie. Returning user mean or global mean.\")\n",
        "        return user_means.get(user_id, global_mean)  # Fallback to user mean or global\n",
        "\n",
        "    top_users = sims.sort_values(ascending=False).head(k)\n",
        "    top_ratings = user_movie_matrix.loc[top_users.index, movie_id] - user_means[top_users.index]\n",
        "\n",
        "    if top_users.sum() > 0:\n",
        "        prediction = user_means[user_id] + np.dot(top_users, top_ratings) / top_users.sum()\n",
        "    else:\n",
        "        print(\"Top users sum is zero. Returning user mean or global mean.\")\n",
        "        prediction = user_means.get(user_id, global_mean)  # Fallback again\n",
        "\n",
        "    return prediction\n",
        "\n",
        "# Step 6: Find a suitable user-movie pair for prediction\n",
        "def find_predictable_pair(k=10):\n",
        "    for user_id in user_sim_df.index:\n",
        "        sims = user_sim_df[user_id].drop(user_id).sort_values(ascending=False).head(k)\n",
        "        neighbors = sims.index\n",
        "        unrated_movies = user_movie_matrix.columns.difference(user_movie_matrix.loc[user_id].dropna().index)\n",
        "\n",
        "        for movie_id in unrated_movies:\n",
        "            neighbor_ratings = user_movie_matrix.loc[neighbors, movie_id].dropna()\n",
        "            if len(neighbor_ratings) >= 1:\n",
        "                return user_id, movie_id\n",
        "    return None, None\n",
        "\n",
        "# Step 7: Run the full prediction\n",
        "user_id, movie_id = find_predictable_pair(k=10)\n",
        "\n",
        "if user_id is not None and movie_id is not None:\n",
        "    pred = predict_user_user(user_id, movie_id, k=10)\n",
        "    movie_title = movies[movies['movieId'] == movie_id]['title'].values[0]\n",
        "    print(f\"\\nPredicted rating for user {user_id} on movie '{movie_title}' (movieId {movie_id}): {pred:.2f}\")\n",
        "else:\n",
        "    print(\"No suitable user-movie pair found for prediction.\")\n",
        "\n",
        "# Step 8: Test fallback logic using the same movieId but with a random user\n",
        "def test_fallback_with_random_user_same_movie(movie_id, k=10):\n",
        "    # Randomly select a user who has NOT rated the movie\n",
        "    eligible_users = user_movie_matrix.index.difference(\n",
        "        user_movie_matrix[movie_id].dropna().index\n",
        "    )\n",
        "\n",
        "    if eligible_users.empty:\n",
        "        print(\"No eligible random users found for fallback test.\")\n",
        "        return\n",
        "\n",
        "    random_user = random.choice(eligible_users.tolist())\n",
        "\n",
        "    pred = predict_user_user(random_user, movie_id, k=k)\n",
        "    movie_title = movies[movies['movieId'] == movie_id]['title'].values[0]\n",
        "    print(f\"\\n[Fallback Test] Predicted rating for random user {random_user} on movie '{movie_title}' (movieId {movie_id}): {pred:.2f}\")\n",
        "\n",
        "# Call it with movie_id from Step 7\n",
        "test_fallback_with_random_user_same_movie(movie_id, k=10)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vn23jo92iOeZ",
        "outputId": "3a591e0a-ede0-46ed-a017-8915718fb438"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded successfully.\n",
            "Using 10000 users and 4997 movies.\n",
            "Computing user-user cosine similarity...\n",
            "Similarity matrix created.\n",
            "Top users sum is zero. Returning user mean or global mean.\n",
            "\n",
            "Predicted rating for user 18 on movie 'Judge Dredd (1995)' (movieId 173): 4.00\n",
            "Top users sum is zero. Returning user mean or global mean.\n",
            "\n",
            "[Fallback Test] Predicted rating for random user 145566 on movie 'Judge Dredd (1995)' (movieId 173): 3.50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. User-User Collaborative Filtering with Cosine and Genre-Weighted Ratings\n",
        "\n",
        "This block implements **User-User Collaborative Filtering** enhanced with **genre-aware weighting** to improve prediction accuracy. The design makes two major improvements over basic collaborative filtering:\n",
        "\n",
        "* **Subset Sampling**: Randomly samples 10,000 users from the full ratings dataset to ensure scalability and performance within memory-constrained environments like Google Colab.\n",
        "* **Genre-Based Weighting**: In addition to user similarity (via cosine similarity), the prediction also considers how similar the target movie is—based on genre—to movies rated by each neighbor. This reduces noise from irrelevant user ratings.\n",
        "\n",
        "The process involves:\n",
        "\n",
        "1. Building a **mean-centered user-movie matrix**.\n",
        "2. Calculating **user-user cosine similarity**.\n",
        "3. Creating a **normalized genre matrix** from the movies dataset.\n",
        "4. For each prediction, retrieving the top-k most similar users who rated the movie, then:\n",
        "\n",
        "   * Calculating how similar the movie is (by genre) to other movies each user has rated.\n",
        "   * Averaging these genre similarities to derive a genre weight.\n",
        "   * Multiplying genre weights by user similarity to weight each neighbor’s influence on the prediction.\n",
        "\n",
        "This results in **genre-weighted collaborative filtering**, which makes predictions that are both socially and semantically relevant.\n"
      ],
      "metadata": {
        "id": "3gcQbHA3fKD1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Required Libraries ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import MultiLabelBinarizer, normalize\n",
        "import random\n",
        "\n",
        "# Step 1: Load subset datasets\n",
        "!wget -q https://raw.githubusercontent.com/hawa1983/DATA-612/refs/heads/main/movies_subset.csv\n",
        "!wget -q https://raw.githubusercontent.com/hawa1983/DATA-612/refs/heads/main/ratings_subset.csv\n",
        "\n",
        "ratings = pd.read_csv(\"ratings_subset.csv\")\n",
        "movies = pd.read_csv(\"movies_subset.csv\")\n",
        "print(\"Data loaded successfully.\")\n",
        "\n",
        "# Step 2: Sample 10,000 users to reduce memory footprint and speed up similarity calculations\n",
        "sampled_user_ids = ratings['userId'].drop_duplicates().sample(n=10000) #, random_state=42)\n",
        "ratings_small = ratings[ratings['userId'].isin(sampled_user_ids)]\n",
        "print(f\"Using {ratings_small['userId'].nunique()} users and {ratings_small['movieId'].nunique()} movies.\")\n",
        "\n",
        "# Step 3: Create the user-movie rating matrix and normalize by subtracting each user's average rating\n",
        "user_movie_matrix = ratings_small.pivot(index='userId', columns='movieId', values='rating')\n",
        "user_means = user_movie_matrix.mean(axis=1)\n",
        "user_movie_centered = user_movie_matrix.sub(user_means, axis=0).fillna(0)\n",
        "\n",
        "# Step 4: Compute cosine similarity between users using the normalized matrix\n",
        "print(\"Computing user-user cosine similarity...\")\n",
        "user_similarity = cosine_similarity(user_movie_centered)\n",
        "user_sim_df = pd.DataFrame(user_similarity, index=user_movie_matrix.index, columns=user_movie_matrix.index)\n",
        "print(\"Similarity matrix created.\")\n",
        "\n",
        "# Step 5: Prepare the genre matrix from movie metadata\n",
        "movies['genres'] = movies['genres'].apply(lambda x: x.split('|') if isinstance(x, str) else [])\n",
        "movie_ids_in_matrix = user_movie_matrix.columns\n",
        "movies_filtered = movies[movies['movieId'].isin(movie_ids_in_matrix)]\n",
        "\n",
        "mlb = MultiLabelBinarizer()\n",
        "genre_matrix = mlb.fit_transform(movies_filtered['genres'])  # multi-hot encoding\n",
        "genre_matrix_normalized = normalize(genre_matrix, norm='l2')  # L2-normalized for cosine similarity\n",
        "\n",
        "movieId_to_index = dict(zip(movies_filtered['movieId'], range(len(movies_filtered))))  # fast lookup\n",
        "\n",
        "# Step 6: Define prediction function that combines user similarity and genre similarity\n",
        "def predict_user_user_genre_weighted(user_id, movie_id, k=10):\n",
        "    # Skip prediction if user or movie not in dataset\n",
        "    if user_id not in user_sim_df.index or movie_id not in user_movie_matrix.columns:\n",
        "        return np.nan\n",
        "\n",
        "    # Find similar users who have rated this movie\n",
        "    sims = user_sim_df[user_id].drop(user_id)\n",
        "    rated_users = user_movie_matrix[movie_id].dropna()\n",
        "    sims = sims[sims.index.intersection(rated_users.index)]\n",
        "\n",
        "    if sims.empty:\n",
        "        return np.nan\n",
        "\n",
        "    # Select top-k most similar users who rated the movie\n",
        "    top_users = sims.sort_values(ascending=False).head(k)\n",
        "    top_user_ids = top_users.index\n",
        "\n",
        "    # Centered ratings from top-k users\n",
        "    top_ratings = user_movie_matrix.loc[top_user_ids, movie_id] - user_means[top_user_ids]\n",
        "\n",
        "    # Retrieve normalized genre vector of the target movie\n",
        "    if movie_id not in movieId_to_index:\n",
        "        return np.nan\n",
        "    target_vec = genre_matrix_normalized[movieId_to_index[movie_id]]\n",
        "\n",
        "    genre_weights = []\n",
        "    for uid in top_user_ids:\n",
        "        # Find all movies the similar user has rated\n",
        "        user_rated_movies = user_movie_matrix.loc[uid].dropna().index\n",
        "\n",
        "        # Convert those movieIds to genre matrix indices\n",
        "        rated_indices = [movieId_to_index[mid] for mid in user_rated_movies if mid in movieId_to_index]\n",
        "\n",
        "        # Compute cosine similarity between target movie genre and each rated movie genre\n",
        "        if rated_indices:\n",
        "            user_genre_sims = cosine_similarity(target_vec.reshape(1, -1), genre_matrix_normalized[rated_indices])[0]\n",
        "            # Take the average genre similarity — this becomes the genre weight for this neighbor\n",
        "            genre_weights.append(np.mean(user_genre_sims))\n",
        "        else:\n",
        "            genre_weights.append(0)\n",
        "\n",
        "    genre_weights = np.array(genre_weights)\n",
        "\n",
        "    # Final weights = user similarity × genre similarity\n",
        "    combined_weights = top_users.values * genre_weights\n",
        "\n",
        "    # Weighted prediction calculation\n",
        "    if combined_weights.sum() > 0:\n",
        "        prediction = user_means[user_id] + np.dot(combined_weights, top_ratings.values) / combined_weights.sum()\n",
        "    else:\n",
        "        prediction = np.nan\n",
        "\n",
        "    return prediction\n",
        "\n",
        "# Step 7: Helper function to find a user-movie pair where prediction is possible\n",
        "def find_predictable_pair(k=10):\n",
        "    for user_id in user_sim_df.index:\n",
        "        sims = user_sim_df[user_id].drop(user_id).sort_values(ascending=False).head(k)\n",
        "        neighbors = sims.index\n",
        "        unrated_movies = user_movie_matrix.columns.difference(user_movie_matrix.loc[user_id].dropna().index)\n",
        "\n",
        "        for movie_id in unrated_movies:\n",
        "            neighbor_ratings = user_movie_matrix.loc[neighbors, movie_id].dropna()\n",
        "            if len(neighbor_ratings) >= 1:\n",
        "                return user_id, movie_id\n",
        "    return None, None\n",
        "\n",
        "# Step 8: Execute prediction\n",
        "user_id, movie_id = find_predictable_pair(k=10)\n",
        "\n",
        "if user_id is not None and movie_id is not None:\n",
        "    pred = predict_user_user_genre_weighted(user_id, movie_id, k=10)\n",
        "    movie_title = movies[movies['movieId'] == movie_id]['title'].values[0]\n",
        "    print(f\"\\nPredicted rating for user {user_id} on movie '{movie_title}' (movieId {movie_id}): {pred:.2f}\")\n",
        "else:\n",
        "    print(\"No suitable user-movie pair found for prediction.\")\n",
        "\n",
        "\n",
        "# Step 9: Test fallback logic using the same movieId but with a random user\n",
        "def test_genre_weighted_fallback_same_movie(movie_id, k=10):\n",
        "    # Find users who have NOT rated the selected movie\n",
        "    eligible_users = user_movie_matrix.index.difference(\n",
        "        user_movie_matrix[movie_id].dropna().index\n",
        "    )\n",
        "\n",
        "    if eligible_users.empty:\n",
        "        print(\"No eligible users found for fallback test.\")\n",
        "        return\n",
        "\n",
        "    # Pick a random eligible user\n",
        "    random_user = random.choice(eligible_users.tolist())\n",
        "\n",
        "    # Try genre-weighted prediction\n",
        "    pred = predict_user_user_genre_weighted(random_user, movie_id, k=k)\n",
        "    movie_title = movies[movies['movieId'] == movie_id]['title'].values[0]\n",
        "    print(f\"\\n[Fallback Test] Predicted rating for random user {random_user} on movie '{movie_title}' (movieId {movie_id}): {pred:.2f}\")\n",
        "\n",
        "# Call it using the movie_id from Step 8\n",
        "test_genre_weighted_fallback_same_movie(movie_id, k=10)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CQne0c8cUSG",
        "outputId": "e0460fcf-b3e7-4611-ab03-73e5f1d17a0b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded successfully.\n",
            "Using 10000 users and 4963 movies.\n",
            "Computing user-user cosine similarity...\n",
            "Similarity matrix created.\n",
            "\n",
            "Predicted rating for user 33 on movie 'Outbreak (1995)' (movieId 292): nan\n",
            "\n",
            "[Fallback Test] Predicted rating for random user 162867 on movie 'Outbreak (1995)' (movieId 292): nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Item-Item Collaborative Filtering with Adjusted Cosine Similarity\n",
        "\n",
        "This code implements **item-item collaborative filtering** using **adjusted cosine similarity**, which accounts for differences in users’ individual rating scales. The steps include:\n",
        "\n",
        "* **Transposing** the user-item matrix so that movies are represented as rows.\n",
        "* **Centering** each movie's vector by subtracting each user's mean rating — this adjustment ensures that the similarity metric reflects agreement in rating patterns, not absolute values.\n",
        "* **Computing cosine similarity** between movie vectors to identify similar items.\n",
        "* Defining a **prediction function** that estimates how a user would rate a target movie by aggregating their ratings for similar movies (weighted by similarity).\n",
        "\n",
        "This memory-efficient approach allows personalized movie recommendations by looking at how similar a target movie is to other movies the user has already rated."
      ],
      "metadata": {
        "id": "VP1qrga55qpZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create user-movie matrix (assumes user_movie_matrix is already defined earlier)\n",
        "\n",
        "# Transpose and center by user mean\n",
        "# Transposes the matrix so that:\n",
        "# Rows = movies (items)\n",
        "# Columns = users\n",
        "# This format is needed to compute item-item similarity.\n",
        "movie_user_matrix = user_movie_matrix.T\n",
        "\n",
        "# Center each row (movie) by subtracting the mean rating given by each user.\n",
        "# This is known as adjusted cosine similarity — it accounts for differences in user rating scales.\n",
        "movie_user_centered = movie_user_matrix.sub(user_movie_matrix.mean(axis=1), axis=1).fillna(0)\n",
        "\n",
        "# Compute cosine similarity between items (movies)\n",
        "# Cosine similarity is computed between each pair of movie vectors.\n",
        "# The result is a similarity matrix where:\n",
        "# Rows and columns = movieId\n",
        "# Cell (i, j) = similarity between movie i and movie j\n",
        "from sklearn.metrics import pairwise_distances\n",
        "item_similarity = 1 - pairwise_distances(movie_user_centered, metric='cosine')\n",
        "item_sim_df = pd.DataFrame(item_similarity, index=movie_user_matrix.index, columns=movie_user_matrix.index)\n",
        "\n",
        "# Define prediction function\n",
        "# Predicts how much user_id would rate movie_id using k nearest neighbors (top-k similar items).\n",
        "def predict_item_item(user_id, movie_id, k=10):\n",
        "    # If the movie is not in the matrix, return NaN\n",
        "    if movie_id not in user_movie_matrix.columns:\n",
        "        return np.nan\n",
        "\n",
        "    # Get all movies that this user has rated\n",
        "    user_ratings = user_movie_matrix.loc[user_id].dropna()\n",
        "\n",
        "    # If user has not rated any other movies, return NaN\n",
        "    if user_ratings.empty:\n",
        "        return np.nan\n",
        "\n",
        "    # Get similarity scores between the target movie and all movies the user has rated\n",
        "    sims = item_sim_df.loc[movie_id, user_ratings.index]\n",
        "\n",
        "    # Select the top-k most similar items\n",
        "    top_items = sims.sort_values(ascending=False).head(k)\n",
        "\n",
        "    # Get the user’s ratings for those items\n",
        "    top_ratings = user_ratings[top_items.index]\n",
        "\n",
        "    # Compute the weighted average rating, weighted by item similarity\n",
        "    prediction = np.dot(top_items, top_ratings) / top_items.sum() if top_items.sum() > 0 else np.nan\n",
        "    return prediction\n"
      ],
      "metadata": {
        "id": "Mc-sDJ-M5t53"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Item-Item Collaborative Filtering using Jaccard Similarity\n",
        "\n",
        "This code implements item-item collaborative filtering by measuring the similarity between movies using the Jaccard index. Jaccard similarity is a metric that compares the similarity of two sets by dividing the size of their intersection by the size of their union. In this context, it is used to compare movies based on whether users have rated them or not—ignoring the actual rating values.\n",
        "\n",
        "To apply Jaccard similarity:\n",
        "\n",
        "1. The user-item ratings matrix is converted into a binary format (1 if a user rated a movie, 0 otherwise).\n",
        "2. Each pair of movies is compared using Jaccard similarity, which is computed as the ratio of the number of users who rated both movies to the number of users who rated either movie.\n",
        "3. A prediction function is defined to estimate how much a user would rate a given movie, based on the user’s ratings for the most similar movies, weighted by Jaccard similarity.\n",
        "\n",
        "This method is particularly useful when the presence or absence of a rating is more important than the rating value itself. It also tends to be more memory-efficient in sparse datasets where many entries are missing."
      ],
      "metadata": {
        "id": "xcgIjUatbXCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Required library for Jaccard similarity\n",
        "from sklearn.metrics import jaccard_score\n",
        "\n",
        "# ---- SUBSET THE DATASET TO AVOID MEMORY ISSUES ----\n",
        "\n",
        "# Reduce to users with userId ≤ 50,000 for memory-efficient computation\n",
        "ratings_small = ratings[ratings['userId'] <= 10000]\n",
        "\n",
        "# Create user-movie matrix: rows = users, columns = movies, values = ratings\n",
        "user_movie_matrix = ratings_small.pivot(index='userId', columns='movieId', values='rating')\n",
        "\n",
        "# Step 1: Convert to Binary Rating Matrix\n",
        "# Convert to binary: 1 if user rated a movie, 0 otherwise\n",
        "# Transpose so that rows = movies, columns = users\n",
        "movie_user_binary = user_movie_matrix.notna().astype(int).T\n",
        "\n",
        "# Step 2: Compute Jaccard Similarity Matrix Between Movies\n",
        "# Initialize empty DataFrame to store Jaccard similarities\n",
        "movie_ids = movie_user_binary.index.tolist()\n",
        "jaccard_sim_df = pd.DataFrame(index=movie_ids, columns=movie_ids, dtype=float)\n",
        "\n",
        "# Compute Jaccard similarity for each pair of movies\n",
        "# This may take time depending on how many movies are present\n",
        "for i in range(len(movie_ids)):\n",
        "    for j in range(i, len(movie_ids)):\n",
        "        movie_i = movie_user_binary.loc[movie_ids[i]].values\n",
        "        movie_j = movie_user_binary.loc[movie_ids[j]].values\n",
        "        sim = jaccard_score(movie_i, movie_j)\n",
        "        jaccard_sim_df.iloc[i, j] = sim\n",
        "        jaccard_sim_df.iloc[j, i] = sim  # Ensure symmetry\n",
        "\n",
        "# Step 3: Define Prediction Function Using Jaccard Similarity\n",
        "# Predict rating for a given user and movie using top-k similar movies\n",
        "def predict_item_item_jaccard(user_id, movie_id, k=10):\n",
        "    # Check if movie exists in the matrix\n",
        "    if movie_id not in user_movie_matrix.columns:\n",
        "        return np.nan\n",
        "\n",
        "    # Get movies the user has rated\n",
        "    user_ratings = user_movie_matrix.loc[user_id].dropna()\n",
        "    if user_ratings.empty:\n",
        "        return np.nan\n",
        "\n",
        "    # Get Jaccard similarity between target movie and movies the user has rated\n",
        "    sims = jaccard_sim_df.loc[movie_id, user_ratings.index]\n",
        "\n",
        "    # Select top-k similar movies\n",
        "    top_items = sims.sort_values(ascending=False).head(k)\n",
        "    top_ratings = user_ratings[top_items.index]\n",
        "\n",
        "    # Weighted average of ratings using Jaccard similarity as weights\n",
        "    prediction = np.dot(top_items, top_ratings) / top_items.sum() if top_items.sum() > 0 else np.nan\n",
        "    return prediction\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "0e18Ov_xbka9",
        "outputId": "75e4076a-df25-4749-c8c6-6af4a18cd2b5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-3792502014>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovie_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovie_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mmovie_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmovie_user_binary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmovie_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mmovie_j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmovie_user_binary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmovie_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjaccard_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovie_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmovie_j\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_deprecated_callable_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaybe_callable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1429\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1431\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAxisInt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1379\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAxisInt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1380\u001b[0m         \u001b[0;31m# GH#5567 this will fail if the label is not present in the axis.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1381\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_lowerdim_multi_index_axis0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mxs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   4334\u001b[0m         \u001b[0;31m# this could be a view\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4335\u001b[0m         \u001b[0;31m# but only in a single-dtyped view sliceable case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4336\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4337\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_is_view\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4587\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool_t\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4588\u001b[0m         \u001b[0;34m\"\"\"Return boolean indicating if self is view of another array\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4589\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_view\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4591\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mis_view\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0;34m\"\"\"return a boolean if we are a single block and are a view\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_view\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0;31m# It is technically possible to figure out which blocks are views\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mis_view\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2575\u001b[0m     \u001b[0m__slots__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2577\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2578\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mis_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2579\u001b[0m         \u001b[0;34m\"\"\"return a boolean if I am possibly a view\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Evaluation: RMSE Comparison"
      ],
      "metadata": {
        "id": "B31CO5UG5xCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data for evaluation\n",
        "train, test = train_test_split(ratings, test_size=0.2, random_state=42)\n",
        "\n",
        "# Predict ratings using both collaborative methods\n",
        "user_preds = test.apply(lambda row: predict_user_user(row['userId'], row['movieId']), axis=1)\n",
        "item_preds = test.apply(lambda row: predict_item_item(row['userId'], row['movieId']), axis=1)\n",
        "\n",
        "# Calculate RMSE\n",
        "user_rmse = np.sqrt(mean_squared_error(test['rating'].dropna(), user_preds.dropna()))\n",
        "item_rmse = np.sqrt(mean_squared_error(test['rating'].dropna(), item_preds.dropna()))\n",
        "\n",
        "# Plot RMSE comparison\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.bar(['User-User (Pearson)', 'Item-Item (Adjusted Cosine)'], [user_rmse, item_rmse], color=['blue', 'green'])\n",
        "plt.title(\"RMSE Comparison of Collaborative Filtering Models\")\n",
        "plt.ylabel(\"RMSE\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2KIVFVMX51_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Summary Output"
      ],
      "metadata": {
        "id": "2PLdfswj55KE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Summary ---\")\n",
        "print(f\"User-User RMSE (Pearson): {user_rmse:.4f}\")\n",
        "print(f\"Item-Item RMSE (Adjusted Cosine): {item_rmse:.4f}\")\n",
        "print(\"Content-Based filtering used L2-normalized cosine similarity on genre vectors.\")\n",
        "print(\"User-user filtering used Pearson correlation and centered ratings.\")\n",
        "print(\"Item-item filtering used adjusted cosine similarity with user-centered item vectors.\")\n"
      ],
      "metadata": {
        "id": "SCyM-ObK590E"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}